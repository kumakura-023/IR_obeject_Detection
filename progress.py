# enhanced_progress_tracking.py - è©³ç´°é€²æ—è¡¨ç¤ºæ©Ÿèƒ½

import time
import torch
from datetime import datetime, timedelta

class DetailedProgressTracker:
    """è©³ç´°ãªé€²æ—è¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, total_batches, print_interval=100):
        self.total_batches = total_batches
        self.print_interval = print_interval
        self.epoch_start_time = None
        self.batch_times = []
        self.recent_losses = []
        self.best_batch_loss = float('inf')
        self.worst_batch_loss = 0.0
        
    def start_epoch(self, epoch, total_epochs):
        """ã‚¨ãƒãƒƒã‚¯é–‹å§‹"""
        self.current_epoch = epoch
        self.total_epochs = total_epochs
        self.epoch_start_time = time.time()
        self.batch_times = []
        self.recent_losses = []
        self.best_batch_loss = float('inf')
        self.worst_batch_loss = 0.0
        
    def update_batch(self, batch_idx, loss_value, current_lr):
        """ãƒãƒƒãƒæ›´æ–°"""
        current_time = time.time()
        
        # ãƒãƒƒãƒæ™‚é–“è¨˜éŒ²
        if len(self.batch_times) > 0:
            batch_time = current_time - self.last_batch_time
            self.batch_times.append(batch_time)
            
            # æœ€æ–°20ãƒãƒƒãƒã®å¹³å‡æ™‚é–“ã‚’ä¿æŒ
            if len(self.batch_times) > 20:
                self.batch_times = self.batch_times[-20:]
        
        self.last_batch_time = current_time
        
        # Lossçµ±è¨ˆæ›´æ–°
        self.recent_losses.append(loss_value)
        if len(self.recent_losses) > self.print_interval:
            self.recent_losses = self.recent_losses[-self.print_interval:]
            
        self.best_batch_loss = min(self.best_batch_loss, loss_value)
        self.worst_batch_loss = max(self.worst_batch_loss, loss_value)
        
        # é€²æ—è¡¨ç¤º
        if batch_idx % self.print_interval == 0:
            self.print_detailed_progress(batch_idx, loss_value, current_lr)
    
    def print_detailed_progress(self, batch_idx, current_loss, current_lr):
        """è©³ç´°é€²æ—è¡¨ç¤º"""
        # åŸºæœ¬æƒ…å ±
        progress_pct = (batch_idx / self.total_batches) * 100
        
        # æ™‚é–“çµ±è¨ˆ
        elapsed_time = time.time() - self.epoch_start_time
        avg_batch_time = sum(self.batch_times) / len(self.batch_times) if self.batch_times else 0
        remaining_batches = self.total_batches - batch_idx
        eta_seconds = remaining_batches * avg_batch_time if avg_batch_time > 0 else 0
        eta_time = datetime.now() + timedelta(seconds=eta_seconds)
        
        # Lossçµ±è¨ˆ
        if len(self.recent_losses) > 1:
            avg_recent_loss = sum(self.recent_losses) / len(self.recent_losses)
            loss_trend = current_loss - self.recent_losses[0] if len(self.recent_losses) > 10 else 0
        else:
            avg_recent_loss = current_loss
            loss_trend = 0
            
        # GPUæƒ…å ±
        gpu_memory = torch.cuda.memory_allocated(0) / 1024**3 if torch.cuda.is_available() else 0
        gpu_reserved = torch.cuda.memory_reserved(0) / 1024**3 if torch.cuda.is_available() else 0
        
        # é€²æ—ãƒãƒ¼ä½œæˆ
        bar_length = 20
        filled_length = int(bar_length * progress_pct / 100)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        print(f"\n" + "="*80)
        print(f"ğŸ“Š Epoch {self.current_epoch}/{self.total_epochs} - Batch Progress")
        print(f"="*80)
        
        # ãƒ¡ã‚¤ãƒ³é€²æ—æƒ…å ±
        print(f"ğŸ”„ Progress: [{bar}] {progress_pct:5.1f}% ({batch_idx:4d}/{self.total_batches})")
        print(f"â±ï¸  Time: {elapsed_time/60:5.1f}min elapsed, ETA: {eta_time.strftime('%H:%M:%S')}")
        print(f"ğŸ’¨ Speed: {avg_batch_time:5.2f}s/batch (recent avg)")
        
        # Lossæƒ…å ±
        trend_icon = "ğŸ“ˆ" if loss_trend > 0 else "ğŸ“‰" if loss_trend < 0 else "â¡ï¸"
        print(f"ğŸ“Š Loss: {current_loss:8.4f} (current) | {avg_recent_loss:8.4f} (avg) {trend_icon}")
        print(f"   Range: {self.best_batch_loss:8.4f} (best) - {self.worst_batch_loss:8.4f} (worst)")
        
        # å­¦ç¿’æƒ…å ±
        print(f"âš™ï¸  Learning Rate: {current_lr:.6f}")
        
        # GPUæƒ…å ±
        if torch.cuda.is_available():
            gpu_util_pct = (gpu_memory / 14.74) * 100  # T4ã®ç·å®¹é‡
            memory_icon = "ğŸŸ¢" if gpu_util_pct < 70 else "ğŸŸ¡" if gpu_util_pct < 90 else "ğŸ”´"
            print(f"ğŸ–¥ï¸  GPU: {gpu_memory:5.2f}GB used ({gpu_util_pct:4.1f}%) {memory_icon}")
            print(f"   Reserved: {gpu_reserved:5.2f}GB")
        
        print(f"="*80)

class MultiScaleProgressTracker(DetailedProgressTracker):
    """ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å­¦ç¿’ç”¨é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼"""
    
    def __init__(self, total_batches, print_interval=100):
        super().__init__(total_batches, print_interval)
        self.scale_losses = {'small': [], 'medium': [], 'large': []}
        
    def update_batch_multiscale(self, batch_idx, loss_value, current_lr, scale_losses=None):
        """ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œãƒãƒƒãƒæ›´æ–°"""
        # åŸºæœ¬æ›´æ–°
        self.update_batch(batch_idx, loss_value, current_lr)
        
        # ã‚¹ã‚±ãƒ¼ãƒ«åˆ¥Lossè¨˜éŒ²
        if scale_losses:
            for scale, loss_info in scale_losses.items():
                if scale in self.scale_losses:
                    self.scale_losses[scale].append(loss_info.get('total', 0))
                    # æœ€æ–°20ä»¶ã®ã¿ä¿æŒ
                    if len(self.scale_losses[scale]) > 20:
                        self.scale_losses[scale] = self.scale_losses[scale][-20:]
    
    def print_detailed_progress(self, batch_idx, current_loss, current_lr):
        """ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œè©³ç´°é€²æ—è¡¨ç¤º"""
        # åŸºæœ¬é€²æ—è¡¨ç¤º
        super().print_detailed_progress(batch_idx, current_loss, current_lr)
        
        # ã‚¹ã‚±ãƒ¼ãƒ«åˆ¥Lossè¡¨ç¤º
        if any(losses for losses in self.scale_losses.values()):
            print(f"ğŸ¯ Scale-wise Loss (recent avg):")
            for scale, losses in self.scale_losses.items():
                if losses:
                    avg_loss = sum(losses[-10:]) / len(losses[-10:])  # æœ€æ–°10ä»¶ã®å¹³å‡
                    scale_icon = "ğŸ”" if scale == 'small' else "ğŸ¯" if scale == 'medium' else "ğŸ”­"
                    print(f"   {scale_icon} {scale:6s}: {avg_loss:8.4f}")
            print(f"="*80)

def integrate_progress_tracker_to_training():
    """å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¸ã®é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼çµ±åˆä¾‹"""
    
    # train_phase3_integrated.py ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—å†…ã§ä½¿ç”¨
    code_example = '''
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—å†…ã§ã®ä½¿ç”¨ä¾‹
    
    # ã‚¨ãƒãƒƒã‚¯é–‹å§‹æ™‚
    progress_tracker = MultiScaleProgressTracker(len(train_dataloader), print_interval=100)
    progress_tracker.start_epoch(epoch + 1, cfg.num_epochs)
    
    for batch_idx, (images, targets) in enumerate(train_dataloader):
        # ... å­¦ç¿’å‡¦ç† ...
        
        # Forward & Lossè¨ˆç®—
        if architecture_type == "multiscale":
            predictions = model(images)
            loss = criterion(predictions, targets)
            
            # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«é€²æ—æ›´æ–°ï¼ˆè©³ç´°æƒ…å ±ä»˜ãï¼‰
            if hasattr(criterion, 'return_components') and batch_idx % 100 == 0:
                # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§è©³ç´°æƒ…å ±å–å¾—
                criterion.return_components = True
                _, _, scale_losses = criterion(predictions, targets)
                criterion.return_components = False
                
                progress_tracker.update_batch_multiscale(
                    batch_idx, loss.item(), current_lr, scale_losses
                )
            else:
                progress_tracker.update_batch(batch_idx, loss.item(), current_lr)
        else:
            # å¾“æ¥ç‰ˆ
            predictions, grid_size = model(images)
            loss = criterion(predictions, targets, grid_size)
            progress_tracker.update_batch(batch_idx, loss.item(), current_lr)
        
        # ... æ®‹ã‚Šã®å­¦ç¿’å‡¦ç† ...
    '''
    
    return code_example

# ãƒ†ã‚¹ãƒˆç”¨
def demo_progress_tracker():
    """é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®ãƒ‡ãƒ¢"""
    print("ğŸ§ª Progress Tracker Demo")
    
    # æ¨¡æ“¬çš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—
    total_batches = 50
    tracker = MultiScaleProgressTracker(total_batches, print_interval=10)
    tracker.start_epoch(1, 35)
    
    import random
    base_loss = 25.0
    
    for batch_idx in range(total_batches):
        # æ¨¡æ“¬Lossï¼ˆå¾ã€…ã«ä¸‹é™ï¼‰
        loss_value = base_loss * (1 - batch_idx * 0.01) + random.uniform(-2, 2)
        current_lr = 0.0008
        
        # æ¨¡æ“¬ã‚¹ã‚±ãƒ¼ãƒ«åˆ¥Loss
        scale_losses = {
            'small': {'total': loss_value * 0.3},
            'medium': {'total': loss_value * 0.4}, 
            'large': {'total': loss_value * 0.3}
        }
        
        tracker.update_batch_multiscale(batch_idx, loss_value, current_lr, scale_losses)
        
        # å°‘ã—å¾…ã¤ï¼ˆãƒªã‚¢ãƒ«ã£ã½ãï¼‰
        time.sleep(0.1)

if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    demo_progress_tracker()
