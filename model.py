# model.py - Phase2 Enhanced Architecture
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

# â˜…â˜…â˜… å…±æœ‰VersionTrackerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from version_tracker import create_version_tracker, VersionTracker

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
model_version = create_version_tracker("Model System v2.0 - Phase2 Enhanced", "model.py")
model_version.add_modification("SimpleYOLOå®Ÿè£…")
model_version.add_modification("æ¤œå‡ºãƒ˜ãƒƒãƒ‰æœ€é©åŒ–")
model_version.add_modification("Phase2: Spatial Attention + CSPæ”¹è‰¯ + æ·±ã„ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³")
model_version.add_modification("ä¿®æ­£: SimpleYOLOã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã«å˜ä¸€ã‚¢ãƒ³ã‚«ãƒ¼ã‚’ä½¿ã†ã‚ˆã†ã«ä¿®æ­£") # ã“ã‚Œã‚’è¿½åŠ ã™ã‚‹ã‚ˆï¼

# ===== Phase2: æ”¹è‰¯ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ =====

class SpatialAttentionModule(nn.Module):
    """YOLOv11ã‚¹ã‚¿ã‚¤ãƒ«ã®ç©ºé–“æ³¨æ„æ©Ÿæ§‹"""
    
    def __init__(self, in_channels):
        super().__init__()
        # ç©ºé–“æ³¨æ„: 7x7 conv ã§é‡è¦é ˜åŸŸã«æ³¨ç›®
        self.spatial_conv = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.BatchNorm2d(in_channels // 8),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels // 8, 1, 7, padding=3),
            nn.Sigmoid()
        )
        
        # ãƒãƒ£ãƒ³ãƒãƒ«æ³¨æ„: Global Average Pooling + FC
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channels, in_channels // 16, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels // 16, in_channels, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # ãƒãƒ£ãƒ³ãƒãƒ«æ³¨æ„é©ç”¨
        channel_att = self.channel_attention(x)
        x = x * channel_att
        
        # ç©ºé–“æ³¨æ„é©ç”¨
        spatial_att = self.spatial_conv(x)
        x = x * spatial_att
        
        return x

class ImprovedCSPBlock(nn.Module):
    """YOLOv11ã®C3k2ã‚¹ã‚¿ã‚¤ãƒ«æ”¹è‰¯CSPãƒ–ãƒ­ãƒƒã‚¯"""
    
    def __init__(self, in_channels, out_channels, num_blocks=1, shortcut=True):
        super().__init__()
        hidden_channels = out_channels // 2
        
        # å…¥åŠ›åˆ†å²ç”¨
        self.conv1 = nn.Conv2d(in_channels, hidden_channels, 1)
        self.conv2 = nn.Conv2d(in_channels, hidden_channels, 1)
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆã‚ˆã‚Šè»½é‡ã«ï¼‰
        self.bottlenecks = nn.Sequential(*[
            self._make_bottleneck(hidden_channels, hidden_channels, shortcut)
            for _ in range(num_blocks)
        ])
        
        # å‡ºåŠ›çµ±åˆ
        self.conv3 = nn.Conv2d(hidden_channels * 2, out_channels, 1)
        self.bn = nn.BatchNorm2d(out_channels)
        
    def _make_bottleneck(self, in_ch, out_ch, shortcut=True):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch // 2, 1),
            nn.BatchNorm2d(out_ch // 2),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv2d(out_ch // 2, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.LeakyReLU(0.1, inplace=True)
        )
    
    def forward(self, x):
        # CSPåˆ†å²
        branch1 = self.conv1(x)
        branch2 = self.bottlenecks(self.conv2(x))
        
        # çµ±åˆ
        out = torch.cat([branch1, branch2], dim=1)
        return F.leaky_relu(self.bn(self.conv3(out)), 0.1)

class SPPFBlock(nn.Module):
    """YOLOv8ã‚¹ã‚¿ã‚¤ãƒ«ã®SPPFï¼ˆé«˜é€Ÿç‰ˆSPPï¼‰"""
    
    def __init__(self, in_channels, out_channels, kernel_size=5):
        super().__init__()
        hidden_channels = in_channels // 2
        
        self.conv1 = nn.Conv2d(in_channels, hidden_channels, 1)
        self.conv2 = nn.Conv2d(hidden_channels * 4, out_channels, 1)
        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=1, padding=kernel_size // 2)
        
    def forward(self, x):
        x = self.conv1(x)
        
        # 3å›ã®MaxPoolingï¼ˆåŠ¹ç‡çš„ãªå¤šã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´æŠ½å‡ºï¼‰
        y1 = self.maxpool(x)
        y2 = self.maxpool(y1) 
        y3 = self.maxpool(y2)
        
        # å…¨ã¦çµåˆ
        return self.conv2(torch.cat([x, y1, y2, y3], dim=1))

class EnhancedDetectionHead(nn.Module):
    """Phase2: å¼·åŒ–æ¤œå‡ºãƒ˜ãƒƒãƒ‰"""
    
    def __init__(self, in_channels, num_classes, num_anchors=3):
        super().__init__()
        self.num_classes = num_classes
        self.num_anchors = num_anchors
        
        # ã‚ˆã‚Šæ·±ã„ç‰¹å¾´æŠ½å‡º
        self.feature_extractor = nn.Sequential(
            # ç¬¬1æ®µéš: åŸºæœ¬ç‰¹å¾´æŠ½å‡º
            nn.Conv2d(in_channels, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1, inplace=True),
            
            # ç¬¬2æ®µéš: ç©ºé–“æ³¨æ„ä»˜ãç‰¹å¾´å¼·åŒ–
            SpatialAttentionModule(256),
            
            # ç¬¬3æ®µéš: ã‚ˆã‚Šæ·±ã„è¡¨ç¾å­¦ç¿’
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Dropout2d(0.1),  # è»½ã„æ­£å‰‡åŒ–
            
            # ç¬¬4æ®µéš: æœ€çµ‚ç‰¹å¾´èª¿æ•´
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1, inplace=True),
        )
        
        # æ¤œå‡ºç”¨æœ€çµ‚å±¤
        self.detection_conv = nn.Conv2d(128, num_anchors * (5 + num_classes), 1)
        
        # é‡ã¿åˆæœŸåŒ–ï¼ˆé‡è¦ï¼ï¼‰
        self._initialize_weights()
    
    def _initialize_weights(self):
        """æ¤œå‡ºãƒ˜ãƒƒãƒ‰ã®é‡ã¿åˆæœŸåŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
        
        # æ¤œå‡ºå±¤ã®ãƒã‚¤ã‚¢ã‚¹åˆæœŸåŒ–ï¼ˆé‡è¦ï¼ä¿¡é ¼åº¦ã‚’ä½ã‚ã‹ã‚‰é–‹å§‹ï¼‰
        with torch.no_grad():
            bias = self.detection_conv.bias.view(self.num_anchors, -1)
            bias[:, 4].fill_(-2.0)  # ä¿¡é ¼åº¦ãƒã‚¤ã‚¢ã‚¹ï¼ˆsigmoid(-2.0) â‰ˆ 0.12ï¼‰
    
    def forward(self, x):
        # ç‰¹å¾´æŠ½å‡º
        features = self.feature_extractor(x)
        
        # æ¤œå‡ºäºˆæ¸¬
        detections = self.detection_conv(features)
        
        # ãƒªã‚·ã‚§ã‚¤ãƒ—: [B, num_anchors*(5+C), H, W] -> [B, H*W*num_anchors, 5+C]
        B, _, H, W = detections.shape
        detections = detections.view(B, self.num_anchors, 5 + self.num_classes, H, W)
        detections = detections.permute(0, 3, 4, 1, 2).contiguous()
        detections = detections.view(B, H * W * self.num_anchors, 5 + self.num_classes)
        
        return detections

# ===== Phase2: ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ« =====

class SimpleYOLO(nn.Module):
    """Phase2: å¤§å¹…å¼·åŒ–ç‰ˆSimpleYOLO"""
    
    def __init__(self, num_classes=15, use_phase2_enhancements=True):
        super().__init__()
        self.num_classes = num_classes
        self.use_phase2_enhancements = use_phase2_enhancements
        
        if use_phase2_enhancements:
            print(f"ğŸš€ Phase2 Enhanced SimpleYOLOåˆæœŸåŒ–ä¸­...")
            self.features = self._build_enhanced_backbone()
            # EnhancedDetectionHeadã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§num_anchors=3ãªã®ã§ã€ã“ã“ã§ã¯æ˜ç¤ºçš„ã«æ¸¡ã™å¿…è¦ã¯ãªã„
            self.detector = EnhancedDetectionHead(512, num_classes, num_anchors=3) # æ˜ç¤ºçš„ã«3ã¨ã™ã‚‹
            print(f"   âœ… ç©ºé–“æ³¨æ„æ©Ÿæ§‹: ON")
            print(f"   âœ… æ”¹è‰¯CSPãƒ–ãƒ­ãƒƒã‚¯: ON") 
            print(f"   âœ… SPPFæ©Ÿæ§‹: ON")
            print(f"   âœ… å¼·åŒ–æ¤œå‡ºãƒ˜ãƒƒãƒ‰: ON")
            print(f"   âœ… ã‚¢ãƒ³ã‚«ãƒ¼æ•°: 3") # è¿½åŠ 
        else:
            print(f"ğŸ“š æ¨™æº–SimpleYOLOï¼ˆäº’æ›ãƒ¢ãƒ¼ãƒ‰ï¼‰")
            self.features = self._build_standard_backbone()
            # â˜…â˜…â˜… ã“ã“ã‚’ä¿®æ­£: å˜ä¸€ã‚¢ãƒ³ã‚«ãƒ¼ã‚’æƒ³å®šã—ãŸãƒ˜ãƒƒãƒ‰ã‚’æ§‹ç¯‰ â˜…â˜…â˜…
            self.detector = self._build_standard_detector(num_anchors=1) # num_anchors=1ã‚’æ¸¡ã™
            print(f"   âœ… ã‚¢ãƒ³ã‚«ãƒ¼æ•°: 1") # è¿½åŠ 
        
        # å…¨ä½“ã®é‡ã¿åˆæœŸåŒ–
        self._initialize_weights()
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°è¡¨ç¤º
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"   ğŸ“Š ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"   ğŸ¯ å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
        
    # ... (_build_enhanced_backbone, _make_enhanced_stage ã¯å¤‰æ›´ãªã—) ...
    
    def _build_standard_backbone(self):
        """æ¨™æº–ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆPhase1äº’æ›ï¼‰"""
        return nn.Sequential(
            # 416 -> 208
            self._make_layer(1, 32, stride=2),
            # 208 -> 104
            self._make_layer(32, 64, stride=2),
            # 104 -> 52
            self._make_layer(64, 128, stride=2),
            # 52 -> 26
            self._make_layer(128, 256, stride=2),
            # 26 -> 13
            self._make_layer(256, 512, stride=2),
            # è¿½åŠ ã®ç•³ã¿è¾¼ã¿
            self._make_layer(512, 512, stride=1),
        )
    
    def _make_layer(self, in_channels, out_channels, stride):
        """æ¨™æº–ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆPhase1äº’æ›ï¼‰"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride, 1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.1, inplace=True)
        )
    
    # â˜…â˜…â˜… ã“ã“ã‚’ä¿®æ­£: num_anchorsã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ã‚ˆã†ã«ã™ã‚‹ â˜…â˜…â˜…
    def _build_standard_detector(self, num_anchors=1): # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’1ã«
        """æ¨™æº–æ¤œå‡ºå™¨ï¼ˆPhase1äº’æ›ï¼‰"""
        # ã“ã“ã§num_anchorsã‚’ä½¿ç”¨ã™ã‚‹
        detector =nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv2d(256, num_anchors * (5 + self.num_classes), 1) # num_anchorsã‚’æ›ã‘ã‚‹
        )

        final_conv_layer = detector[-1]
        

        if final_conv_layer.bias is not None:
            with torch.no_grad():
              final_conv_layer.bias[4].fill_(-2.0) 
        return detector
        

    def _initialize_weights(self):
        """é‡ã¿åˆæœŸåŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ç‰¹å¾´æŠ½å‡º
        features = self.features(x)
        
        if self.use_phase2_enhancements:
            # Phase2: å¼·åŒ–æ¤œå‡ºãƒ˜ãƒƒãƒ‰ï¼ˆã™ã§ã«ãƒªã‚·ã‚§ã‚¤ãƒ—æ¸ˆã¿ï¼‰
            detections = self.detector(features)
            
            # ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºè¨ˆç®—
            H = W = x.shape[-1] // 32  # 32å€ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            return detections, (H, W)
        else:
            # Phase1äº’æ›: æ¨™æº–æ¤œå‡ºå™¨
            detections = self.detector(features)
            
            # ãƒªã‚·ã‚§ã‚¤ãƒ—: [B, C, H, W] -> [B, H*W, C]
            B, C, H, W = detections.shape
            detections = detections.permute(0, 2, 3, 1).contiguous()
            # ã“ã“ã‚‚æ³¨æ„ã€‚num_anchors=1ã®å ´åˆã€CãŒ (5+num_classes) ã«ãªã‚‹
            # num_anchors > 1 ã®å ´åˆã¯ã€Cã‚’ num_anchors ã¨ (5+num_classes) ã«åˆ†è§£ã—ã¦ã‹ã‚‰reshapeã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
            # ã—ã‹ã—ã€_build_standard_detectorã§num_anchors=1ã¨è¨­å®šã—ãŸå ´åˆã¯ã€Cã¯ãã®ã¾ã¾ (5+num_classes) ãªã®ã§å•é¡Œãªã„ã€‚
            detections = detections.view(B, H * W, C)
            
            return detections, (H, W)

# ===== Phase2å¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«é¸æŠé–¢æ•° =====

def create_model(num_classes=15, architecture_type="auto", device="cuda"):
    """
    Phase2å¯¾å¿œãƒ¢ãƒ‡ãƒ«ä½œæˆé–¢æ•°
    
    Args:
        num_classes: ã‚¯ãƒ©ã‚¹æ•°
        architecture_type: "phase2", "phase1", "auto"
        device: ãƒ‡ãƒã‚¤ã‚¹
    """
    
    if architecture_type == "auto":
        # è‡ªå‹•é¸æŠ: GPUãƒ¡ãƒ¢ãƒªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§åˆ¤æ–­
        try:
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                if gpu_memory > 12:  # 12GBä»¥ä¸Š
                    architecture_type = "phase2"
                    print(f"ğŸš€ ååˆ†ãªGPUãƒ¡ãƒ¢ãƒª({gpu_memory:.1f}GB): Phase2æ¡ç”¨")
                else:
                    architecture_type = "phase1"
                    print(f"âš¡ é™å®šGPUãƒ¡ãƒ¢ãƒª({gpu_memory:.1f}GB): Phase1æ¡ç”¨")
            else:
                architecture_type = "phase1"
                print(f"ğŸ’» CPUç’°å¢ƒ: Phase1æ¡ç”¨")
        except:
            architecture_type = "phase1"
            print(f"ğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Phase1æ¡ç”¨")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    if architecture_type == "phase2":
        model = SimpleYOLO(num_classes=num_classes, use_phase2_enhancements=True)
        print(f"âœ¨ Phase2 Enhanced SimpleYOLOä½œæˆå®Œäº†")
    else:
        model = SimpleYOLO(num_classes=num_classes, use_phase2_enhancements=False)
        print(f"ğŸ“š Phase1 Compatible SimpleYOLOä½œæˆå®Œäº†")
    
    return model.to(device), architecture_type

# ===== ãƒ†ã‚¹ãƒˆé–¢æ•° =====

def test_phase2_model():
    """Phase2ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Phase2ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("-" * 50)
    
    # Phase2ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model_p2 = SimpleYOLO(num_classes=15, use_phase2_enhancements=True)
    
    # Phase1ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆæ¯”è¼ƒç”¨ï¼‰
    model_p1 = SimpleYOLO(num_classes=15, use_phase2_enhancements=False)
    
    # ãƒ†ã‚¹ãƒˆå…¥åŠ›
    batch_size = 2
    test_input = torch.randn(batch_size, 1, 416, 416)
    
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆè¨­å®š:")
    print(f"   å…¥åŠ›ã‚µã‚¤ã‚º: {test_input.shape}")
    print(f"   Phase2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {sum(p.numel() for p in model_p2.parameters()):,}")
    print(f"   Phase1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {sum(p.numel() for p in model_p1.parameters()):,}")
    
    # å‰å‘ãè¨ˆç®—ãƒ†ã‚¹ãƒˆ
    with torch.no_grad():
        try:
            # Phase2ãƒ†ã‚¹ãƒˆ
            output_p2, grid_p2 = model_p2(test_input)
            print(f"\nâœ… Phase2 ForwardæˆåŠŸ:")
            print(f"   å‡ºåŠ›å½¢çŠ¶: {output_p2.shape}")
            print(f"   ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º: {grid_p2}")
            
            # Phase1ãƒ†ã‚¹ãƒˆ
            output_p1, grid_p1 = model_p1(test_input)
            print(f"\nâœ… Phase1 ForwardæˆåŠŸ:")
            print(f"   å‡ºåŠ›å½¢çŠ¶: {output_p1.shape}")
            print(f"   ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º: {grid_p1}")
            
            # æ€§èƒ½æ¯”è¼ƒ
            param_ratio = sum(p.numel() for p in model_p2.parameters()) / sum(p.numel() for p in model_p1.parameters())
            print(f"\nğŸ“ˆ Phase2æ”¹å–„:")
            print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—åŠ ç‡: {param_ratio:.2f}x")
            print(f"   äºˆæƒ³æ€§èƒ½å‘ä¸Š: +3-7% mAP")
            print(f"   è¿½åŠ æ©Ÿèƒ½: ç©ºé–“æ³¨æ„ã€CSPæ”¹è‰¯ã€SPPF")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False

# ===== ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ =====

def estimate_memory_usage(batch_size=96):
    """Phase2ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š"""
    print(f"\nğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š (batch_size={batch_size})")
    
    # Phase2ãƒ¢ãƒ‡ãƒ«
    model = SimpleYOLO(num_classes=15, use_phase2_enhancements=True)
    
    # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
    model_params = sum(p.numel() for p in model.parameters())
    model_memory = model_params * 4 / 1024**2  # float32ã§4ãƒã‚¤ãƒˆ
    
    # å…¥åŠ›ãƒ¡ãƒ¢ãƒª
    input_memory = batch_size * 1 * 416 * 416 * 4 / 1024**2
    
    # å‹¾é…ãƒ¡ãƒ¢ãƒªï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨åŒç¨‹åº¦ï¼‰
    gradient_memory = model_memory
    
    # ä¸­é–“æ´»æ€§åŒ–ï¼ˆæ¦‚ç®—ï¼‰
    activation_memory = batch_size * 512 * 13 * 13 * 4 / 1024**2  # æœ€æ·±å±¤ç‰¹å¾´ãƒãƒƒãƒ—
    
    total_memory = model_memory + input_memory + gradient_memory + activation_memory
    
    print(f"   ãƒ¢ãƒ‡ãƒ«: {model_memory:.1f} MB")
    print(f"   å…¥åŠ›: {input_memory:.1f} MB") 
    print(f"   å‹¾é…: {gradient_memory:.1f} MB")
    print(f"   æ´»æ€§åŒ–: {activation_memory:.1f} MB")
    print(f"   åˆè¨ˆæ¨å®š: {total_memory:.1f} MB ({total_memory/1024:.2f} GB)")
    
    if total_memory/1024 < 10:
        print(f"   âœ… T4ãƒ¡ãƒ¢ãƒª(15GB)å†…ã§å‹•ä½œå¯èƒ½")
    else:
        print(f"   âš ï¸ ãƒ¡ãƒ¢ãƒªèª¿æ•´ãŒå¿…è¦ã‹ã‚‚")
    
    return total_memory

if __name__ == "__main__":
    # ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸš€ Phase2 Enhanced SimpleYOLO ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
    model_version.print_version_info()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success = test_phase2_model()
    
    if success:
        # ãƒ¡ãƒ¢ãƒªæ¨å®š
        estimate_memory_usage(batch_size=96)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ Phase2å®Ÿè£…å®Œäº†!")
        print("=" * 60)
        print("ğŸ“Š å®Ÿè£…ã•ã‚ŒãŸæ”¹è‰¯:")
        print("   âœ… ç©ºé–“æ³¨æ„æ©Ÿæ§‹ï¼ˆYOLOv11ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰")
        print("   âœ… æ”¹è‰¯CSPãƒ–ãƒ­ãƒƒã‚¯ï¼ˆC3k2é¢¨ï¼‰")
        print("   âœ… SPPFé«˜é€Ÿç©ºé–“ãƒ—ãƒ¼ãƒ«")
        print("   âœ… å¼·åŒ–æ¤œå‡ºãƒ˜ãƒƒãƒ‰ï¼ˆ4å±¤æ·±åŒ–ï¼‰")
        print("   âœ… é‡ã¿åˆæœŸåŒ–æœ€é©åŒ–")
        print("   âœ… Dropoutæ­£å‰‡åŒ–")
        
        print(f"\nğŸ”„ ä½¿ç”¨æ–¹æ³•:")
        print(f"   # Phase2ãƒ¢ãƒ‡ãƒ«")
        print(f"   model = SimpleYOLO(num_classes=15, use_phase2_enhancements=True)")
        print(f"   # Phase1äº’æ›ãƒ¢ãƒ¼ãƒ‰")
        print(f"   model = SimpleYOLO(num_classes=15, use_phase2_enhancements=False)")
        print(f"   # è‡ªå‹•é¸æŠ")
        print(f"   model, arch_type = create_model(num_classes=15, architecture_type='auto')")
        
        print(f"\nğŸ“ˆ æœŸå¾…åŠ¹æœ:")
        print(f"   Val Loss: 25-35% æ”¹å–„æœŸå¾…")
        print(f"   å°ç‰©ä½“æ¤œå‡º: å¤§å¹…å‘ä¸Š")
        print(f"   å­¦ç¿’å®‰å®šæ€§: æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚Šå‘ä¸Š")
        print(f"   æ±åŒ–æ€§èƒ½: æ­£å‰‡åŒ–ã«ã‚ˆã‚Šå‘ä¸Š")
        
    else:
        print("\nâŒ Phase2å®Ÿè£…ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ - ä¿®æ­£ãŒå¿…è¦")