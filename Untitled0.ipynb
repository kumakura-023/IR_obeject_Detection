{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMhOa84EavkbpHcxskZ+TZg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tUzuXgIjHRq","executionInfo":{"status":"ok","timestamp":1749191609173,"user_tz":-540,"elapsed":18459,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"d7c90020-8d90-475e-c2b6-2664a4e3445d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found checkpoints: []\n"]}],"source":["# Google Driveãƒã‚¦ãƒ³ãƒˆ\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç§»å‹•\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/new/IR_obeject_Detection')\n","\n","# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¢ºèª\n","import glob\n","checkpoints = glob.glob('saved_models/checkpoint_epoch_*.pth')\n","print(f\"Found checkpoints: {[os.path.basename(f) for f in checkpoints]}\")"]},{"cell_type":"code","source":["# ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","\n","# Google Driveã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚³ãƒ”ãƒ¼ (æ™‚é–“ã¯ã‹ã‹ã‚Šã¾ã™)\n","# ãƒ‘ã‚¹ã¯å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åˆã‚ã›ã¦ãã ã•ã„\n","!echo \"Copying training images...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!echo \"Copying training labels...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/\n","!echo \"Copy complete!\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puxvQzu4jOSX","executionInfo":{"status":"ok","timestamp":1749192046089,"user_tz":-540,"elapsed":436910,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"c57f8246-f856-4a3e-dd20-87c13e904d95"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying training images...\n","Copying training labels...\n","Copy complete!\n"]}]},{"cell_type":"code","source":["# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰\n","from efficientnet_model import test_model_creation\n","\n","model = test_model_creation()\n","if model:\n","    print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸï¼\")\n","else:\n","    print(\"âŒ ãƒ¢ãƒ‡ãƒ«ä½œæˆå¤±æ•—\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1o98TFXp9o9","executionInfo":{"status":"ok","timestamp":1749192068727,"user_tz":-540,"elapsed":22636,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"44a6e7df-985d-48fd-d745-9b0cddc1f044"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ§ª Testing model creation...\n","ğŸ—ï¸ Creating EfficientNet model (classes=15, pretrained=True)\n","ğŸš€ Creating EfficientNetDetectionModel...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.1M/30.1M [00:00<00:00, 87.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","ğŸ”§ Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","âœ… Weight initialization completed\n","âœ… EfficientNetDetectionModel created successfully\n","ğŸ“Š Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","ğŸ“¥ Input shape: torch.Size([2, 1, 640, 512])\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","ğŸ“¤ Output shape: torch.Size([2, 264960, 20])\n","âœ… Model test successful!\n","âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸï¼\n"]}]},{"cell_type":"code","source":["# æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰è‡ªå‹•å†é–‹\n","exec(open('unified_training.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtK-nEMjjPxq","outputId":"bdaa2bc9-29bd-4b88-ff22-3b95ab5363fa","executionInfo":{"status":"ok","timestamp":1749192231027,"user_tz":-540,"elapsed":95071,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Starting Unified EfficientNet Training with Comprehensive Debug\n","ğŸ“± Device: cuda\n","ğŸ¯ Target: 15 classes\n","ğŸ“ Input size: (640, 512)\n","ver 2.3 - Corrected for Latest Project Structure\n","ğŸ§ª Testing model creation...\n","ğŸ—ï¸ Creating EfficientNet model (classes=15, pretrained=True)\n","ğŸš€ Creating EfficientNetDetectionModel...\n",">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","ğŸ”§ Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","âœ… Weight initialization completed\n","âœ… EfficientNetDetectionModel created successfully\n","ğŸ“Š Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","ğŸ“¥ Input shape: torch.Size([2, 1, 640, 512])\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","ğŸ“¤ Output shape: torch.Size([2, 264960, 20])\n","âœ… Model test successful!\n","âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸï¼\n","\n","=== ğŸ“š Dataset Loading ===\n","âœ… Dataset: 10742 samples\n","\n","=== ğŸ¯ Anchor Optimization ===\n","ğŸ“Š Analyzing dataset statistics from 1000 samples...\n","   Progress: 100/1000 (10.0%) - 0.3s\n","   Progress: 200/1000 (20.0%) - 0.5s\n","   Progress: 300/1000 (30.0%) - 0.8s\n","   Progress: 400/1000 (40.0%) - 1.0s\n","   Progress: 500/1000 (50.0%) - 1.2s\n","   Progress: 600/1000 (60.0%) - 1.5s\n","   Progress: 700/1000 (70.0%) - 1.7s\n","   Progress: 800/1000 (80.0%) - 1.9s\n","   Progress: 900/1000 (90.0%) - 2.2s\n","âœ… Analysis completed: 15220 valid boxes found in 2.4s\n","\n","ğŸ“ˆ Dataset Statistics:\n","   Total boxes: 15220\n","   Avg size: 24.7 x 29.9 pixels\n","   Size distribution: Small=11854, Medium=2824, Large=542\n","\n","ğŸ”§ Generating optimized anchors...\n","ğŸ”§ Generating 9 anchors using K-means++ (max 300 iterations)...\n","ğŸ‰ Generated optimized anchors:\n","   Level 0: [(9, 10), (14, 26), (38, 26)]\n","   Level 1: [(24, 53), (74, 52), (45, 106)]\n","   Level 2: [(128, 86), (98, 219), (203, 144)]\n","âœ… Anchor optimization completed in 1.9s\n","âœ… Anchor optimization completed\n","\n","=== ğŸ“Š Anchor Comparison ===\n","\n","ğŸ†š Comparing anchor sets...\n","\n","--- Anchor Set 1 (Default) ---\n","ğŸ“ Evaluating anchor quality with 500 samples...\n","ğŸ“ˆ Evaluating anchor performance...\n","   å¹³å‡IoU: 0.5698 (Â±0.1806)\n","   50%ã‚«ãƒãƒ¬ãƒƒã‚¸: 69.82%\n","   70%ã‚«ãƒãƒ¬ãƒƒã‚¸: 23.26%\n","   90%ã‚«ãƒãƒ¬ãƒƒã‚¸: 2.63%\n","   æœªä½¿ç”¨ã‚¢ãƒ³ã‚«ãƒ¼: 0/9\n","\n","--- Anchor Set 2 (Optimized) ---\n","ğŸ“ Evaluating anchor quality with 500 samples...\n","ğŸ“ˆ Evaluating anchor performance...\n","   å¹³å‡IoU: 0.5849 (Â±0.1693)\n","   50%ã‚«ãƒãƒ¬ãƒƒã‚¸: 70.50%\n","   70%ã‚«ãƒãƒ¬ãƒƒã‚¸: 25.36%\n","   90%ã‚«ãƒãƒ¬ãƒƒã‚¸: 2.15%\n","   æœªä½¿ç”¨ã‚¢ãƒ³ã‚«ãƒ¼: 0/9\n","\n","ğŸ“Š Improvement Summary:\n","   Mean IoU: +0.0151\n","   50% Coverage: +0.68%\n","   70% Coverage: +2.10%\n","   âš ï¸ Limited improvement. Consider different strategies.\n","ğŸ“¦ Batches per epoch: 538\n","ğŸ“Š Progress will be shown every 10 batches\n","\n","=== ğŸ¤– Model Initialization ===\n","ğŸ—ï¸ Creating EfficientNet model (classes=15, pretrained=True)\n","ğŸš€ Creating EfficientNetDetectionModel...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","ğŸ”§ Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","âœ… Weight initialization completed\n","âœ… EfficientNetDetectionModel created successfully\n","ğŸ“Š Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","\n","=== ğŸ” Grid Size Detection ===\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","ğŸ“ Grid sizes: [(256, 320), (64, 80), (32, 40)]\n","\n","=== ğŸ¯ Loss Function Setup ===\n","ğŸ¯ Creating Enhanced Loss with strategy: balanced\n","ğŸ¯ Enhanced Loss initialized:\n","   Box Loss: ciou, Obj Loss: adaptive_focal, Cls Loss: label_smooth\n","   Loss Weights: Box=5.0, Obj=2.0, Cls=1.0\n","\n","=== âš™ï¸ Optimizer Setup ===\n","\n","ğŸ¬ Training Started with Debug System!\n","\n","ğŸ¯ Epoch 1/30\n","ğŸ§Š Stage: Head+Neck Only\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 0, Batch 0\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=0.000066, std=0.010005\n","     Obj biases: mean=-2.000000, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     âš ï¸ No gradients found (may be due to gradient accumulation)\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-1.975546, min=-2.421875, max=-1.478516\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.784 (1.265376)\n","       Obj: 0.002 (0.002870)\n","       Cls: 0.215 (0.346396)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.002\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 0, Batch 0\n","   Target Summary:\n","     Positive (>0.01): 1236\n","     Positive (>0.1): 986\n","     Mean positive: 0.556947\n","   Prediction Summary:\n","     Sigmoid mean: 0.122029\n","     Sigmoid std: 0.008150\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 1\n","   Loss Values:\n","     Total: 1.614642\n","     Box: 0.316344\n","     Obj: 0.000717\n","     Cls: 0.692791\n","   Manual Check:\n","     Manual focal: 0.000637\n","     Difference: 0.000080\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 0, Batch 1\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=0.000066, std=0.010005\n","     Obj biases: mean=-2.000000, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=7.333285, norm=279.331635\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 279.331635\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-1.977265, min=-2.396484, max=-1.480469\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.781 (1.248697)\n","       Obj: 0.002 (0.003165)\n","       Cls: 0.217 (0.346527)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.002\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 0, Batch 1\n","   Target Summary:\n","     Positive (>0.01): 1549\n","     Positive (>0.1): 1310\n","     Mean positive: 0.567341\n","   Prediction Summary:\n","     Sigmoid mean: 0.121865\n","     Sigmoid std: 0.008469\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 2\n","   Loss Values:\n","     Total: 1.598389\n","     Box: 0.312174\n","     Obj: 0.000791\n","     Cls: 0.693054\n","   Manual Check:\n","     Manual focal: 0.000676\n","     Difference: 0.000116\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 0, Batch 2\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=0.000066, std=0.010005\n","     Obj biases: mean=-2.000000, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=14.380919, norm=549.886658\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 549.886658\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-1.979355, min=-2.431641, max=-1.529297\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.780 (1.240672)\n","       Obj: 0.002 (0.002931)\n","       Cls: 0.218 (0.346549)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.002\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 0, Batch 2\n","   Target Summary:\n","     Positive (>0.01): 1314\n","     Positive (>0.1): 1067\n","     Mean positive: 0.549805\n","   Prediction Summary:\n","     Sigmoid mean: 0.121635\n","     Sigmoid std: 0.008330\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 3\n","   Loss Values:\n","     Total: 1.590152\n","     Box: 0.310168\n","     Obj: 0.000733\n","     Cls: 0.693099\n","   Manual Check:\n","     Manual focal: 0.000640\n","     Difference: 0.000093\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 0, Batch 3\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=0.000066, std=0.010005\n","     Obj biases: mean=-2.000000, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=21.514364, norm=821.822021\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 821.822021\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-1.976593, min=-2.460938, max=-1.520508\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.788 (1.294622)\n","       Obj: 0.002 (0.002933)\n","       Cls: 0.211 (0.346374)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.002\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 0, Batch 3\n","   Target Summary:\n","     Positive (>0.01): 1284\n","     Positive (>0.1): 1056\n","     Mean positive: 0.559948\n","   Prediction Summary:\n","     Sigmoid mean: 0.121944\n","     Sigmoid std: 0.008578\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 4\n","   Loss Values:\n","     Total: 1.643929\n","     Box: 0.323656\n","     Obj: 0.000733\n","     Cls: 0.692748\n","   Manual Check:\n","     Manual focal: 0.000644\n","     Difference: 0.000089\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 1, Batch 4\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000933, std=0.010005\n","     Obj biases: mean=-2.000980, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     âš ï¸ No gradients found (may be due to gradient accumulation)\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.908651, min=-5.062500, max=-1.714844\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.614 (0.411287)\n","       Obj: 0.003 (0.001776)\n","       Cls: 0.383 (0.256781)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 1, Batch 4\n","   Target Summary:\n","     Positive (>0.01): 1251\n","     Positive (>0.1): 1011\n","     Mean positive: 0.547909\n","   Prediction Summary:\n","     Sigmoid mean: 0.059469\n","     Sigmoid std: 0.030769\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 5\n","   Loss Values:\n","     Total: 0.669844\n","     Box: 0.102822\n","     Obj: 0.000444\n","     Cls: 0.513562\n","   Manual Check:\n","     Manual focal: 0.000320\n","     Difference: 0.000124\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 1, Batch 5\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000933, std=0.010005\n","     Obj biases: mean=-2.000980, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=9.524639, norm=915.859009\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 915.859009\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.895451, min=-5.093750, max=-1.713867\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.606 (0.391843)\n","       Obj: 0.003 (0.002098)\n","       Cls: 0.391 (0.252914)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 1, Batch 5\n","   Target Summary:\n","     Positive (>0.01): 1559\n","     Positive (>0.1): 1226\n","     Mean positive: 0.532508\n","   Prediction Summary:\n","     Sigmoid mean: 0.059718\n","     Sigmoid std: 0.030189\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 6\n","   Loss Values:\n","     Total: 0.646854\n","     Box: 0.097961\n","     Obj: 0.000524\n","     Cls: 0.505827\n","   Manual Check:\n","     Manual focal: 0.000369\n","     Difference: 0.000155\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 1, Batch 6\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000933, std=0.010005\n","     Obj biases: mean=-2.000980, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=16.421549, norm=1777.708130\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 1777.708130\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.905837, min=-5.242188, max=-1.704102\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.615 (0.418399)\n","       Obj: 0.003 (0.001894)\n","       Cls: 0.382 (0.260165)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 1, Batch 6\n","   Target Summary:\n","     Positive (>0.01): 1324\n","     Positive (>0.1): 1117\n","     Mean positive: 0.581634\n","   Prediction Summary:\n","     Sigmoid mean: 0.059483\n","     Sigmoid std: 0.030462\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 7\n","   Loss Values:\n","     Total: 0.680458\n","     Box: 0.104600\n","     Obj: 0.000474\n","     Cls: 0.520329\n","   Manual Check:\n","     Manual focal: 0.000344\n","     Difference: 0.000130\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 1, Batch 7\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000933, std=0.010005\n","     Obj biases: mean=-2.000980, std=0.000000\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=25.231903, norm=2671.687744\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 2671.687744\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.898570, min=-5.156250, max=-1.719727\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.613 (0.413812)\n","       Obj: 0.002 (0.001595)\n","       Cls: 0.384 (0.259309)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.002\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 1, Batch 7\n","   Target Summary:\n","     Positive (>0.01): 1099\n","     Positive (>0.1): 893\n","     Mean positive: 0.564122\n","   Prediction Summary:\n","     Sigmoid mean: 0.059639\n","     Sigmoid std: 0.030297\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 8\n","   Loss Values:\n","     Total: 0.674716\n","     Box: 0.103453\n","     Obj: 0.000399\n","     Cls: 0.518617\n","   Manual Check:\n","     Manual focal: 0.000296\n","     Difference: 0.000103\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 2, Batch 8\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000934, std=0.010005\n","     Obj biases: mean=-2.000983, std=0.000001\n","   ğŸ” Gradient Analysis:\n","     âš ï¸ No gradients found (may be due to gradient accumulation)\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.945110, min=-5.312500, max=-1.696289\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.613 (0.406713)\n","       Obj: 0.003 (0.002107)\n","       Cls: 0.384 (0.254344)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 2, Batch 8\n","   Target Summary:\n","     Positive (>0.01): 1514\n","     Positive (>0.1): 1247\n","     Mean positive: 0.570567\n","   Prediction Summary:\n","     Sigmoid mean: 0.057936\n","     Sigmoid std: 0.030835\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 9\n","   Loss Values:\n","     Total: 0.663165\n","     Box: 0.101678\n","     Obj: 0.000527\n","     Cls: 0.508688\n","   Manual Check:\n","     Manual focal: 0.000383\n","     Difference: 0.000144\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 2, Batch 9\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000934, std=0.010005\n","     Obj biases: mean=-2.000983, std=0.000001\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=6.680331, norm=878.318481\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 878.318481\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.910900, min=-5.109375, max=-1.716797\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.603 (0.388821)\n","       Obj: 0.003 (0.001965)\n","       Cls: 0.394 (0.253760)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 2, Batch 9\n","   Target Summary:\n","     Positive (>0.01): 1430\n","     Positive (>0.1): 1144\n","     Mean positive: 0.546672\n","   Prediction Summary:\n","     Sigmoid mean: 0.059175\n","     Sigmoid std: 0.030343\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 10\n","   Loss Values:\n","     Total: 0.644546\n","     Box: 0.097205\n","     Obj: 0.000491\n","     Cls: 0.507521\n","   Manual Check:\n","     Manual focal: 0.000352\n","     Difference: 0.000139\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 2, Batch 10\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000934, std=0.010005\n","     Obj biases: mean=-2.000983, std=0.000001\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=14.266563, norm=1735.381226\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 1735.381226\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.922834, min=-5.046875, max=-1.704102\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.605 (0.395253)\n","       Obj: 0.003 (0.002127)\n","       Cls: 0.392 (0.255789)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 2, Batch 10\n","   Target Summary:\n","     Positive (>0.01): 1525\n","     Positive (>0.1): 1254\n","     Mean positive: 0.563747\n","   Prediction Summary:\n","     Sigmoid mean: 0.058880\n","     Sigmoid std: 0.030726\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 11\n","   Loss Values:\n","     Total: 0.653169\n","     Box: 0.098813\n","     Obj: 0.000532\n","     Cls: 0.511579\n","   Manual Check:\n","     Manual focal: 0.000380\n","     Difference: 0.000152\n","\n","ğŸ”¬ [ROOT CAUSE INVESTIGATION] Step 2, Batch 11\n","   ğŸ” Model Weights Analysis:\n","     Obj weights: mean=-0.000934, std=0.010005\n","     Obj biases: mean=-2.000983, std=0.000001\n","   ğŸ” Gradient Analysis:\n","     Obj gradients: mean=21.073193, norm=2614.182617\n","     ğŸš¨ GRADIENT EXPLOSION: norm = 2614.182617\n","   ğŸ” Activation Analysis:\n","     Obj logits: mean=-2.906734, min=-5.027344, max=-1.664062\n","   ğŸ” Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.605 (0.401275)\n","       Obj: 0.003 (0.001845)\n","       Cls: 0.392 (0.260313)\n","     ğŸš¨ OBJ LOSS TOO WEAK: 0.003\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 2, Batch 11\n","   Target Summary:\n","     Positive (>0.01): 1275\n","     Positive (>0.1): 1088\n","     Mean positive: 0.583814\n","   Prediction Summary:\n","     Sigmoid mean: 0.059365\n","     Sigmoid std: 0.030304\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 12\n","   Loss Values:\n","     Total: 0.663434\n","     Box: 0.100319\n","     Obj: 0.000461\n","     Cls: 0.520626\n","   Manual Check:\n","     Manual focal: 0.000333\n","     Difference: 0.000128\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 3, Batch 12\n","   Target Summary:\n","     Positive (>0.01): 1523\n","     Positive (>0.1): 1222\n","     Mean positive: 0.559876\n","   Prediction Summary:\n","     Sigmoid mean: 0.059517\n","     Sigmoid std: 0.030269\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 13\n","   Loss Values:\n","     Total: 0.662078\n","     Box: 0.101082\n","     Obj: 0.000520\n","     Cls: 0.511340\n","   Manual Check:\n","     Manual focal: 0.000381\n","     Difference: 0.000139\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 3, Batch 13\n","   Target Summary:\n","     Positive (>0.01): 1209\n","     Positive (>0.1): 996\n","     Mean positive: 0.573710\n","   Prediction Summary:\n","     Sigmoid mean: 0.059350\n","     Sigmoid std: 0.030264\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 14\n","   Loss Values:\n","     Total: 0.689879\n","     Box: 0.107457\n","     Obj: 0.000438\n","     Cls: 0.516600\n","   Manual Check:\n","     Manual focal: 0.000322\n","     Difference: 0.000116\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 3, Batch 14\n","   Target Summary:\n","     Positive (>0.01): 1619\n","     Positive (>0.1): 1298\n","     Mean positive: 0.568042\n","   Prediction Summary:\n","     Sigmoid mean: 0.058988\n","     Sigmoid std: 0.029990\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 15\n","   Loss Values:\n","     Total: 0.661258\n","     Box: 0.101106\n","     Obj: 0.000541\n","     Cls: 0.509335\n","   Manual Check:\n","     Manual focal: 0.000402\n","     Difference: 0.000140\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 3, Batch 15\n","   Target Summary:\n","     Positive (>0.01): 1413\n","     Positive (>0.1): 1160\n","     Mean positive: 0.546629\n","   Prediction Summary:\n","     Sigmoid mean: 0.059871\n","     Sigmoid std: 0.030050\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 16\n","   Loss Values:\n","     Total: 0.668847\n","     Box: 0.102530\n","     Obj: 0.000494\n","     Cls: 0.513501\n","   Manual Check:\n","     Manual focal: 0.000345\n","     Difference: 0.000149\n","\n","ğŸ”¬ [COMPREHENSIVE DEBUG] Step 5, Batch 20\n","   Target Summary:\n","     Positive (>0.01): 1339\n","     Positive (>0.1): 1140\n","     Mean positive: 0.572302\n","   Prediction Summary:\n","     Sigmoid mean: 0.058999\n","     Sigmoid std: 0.029102\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 21\n","   Loss Values:\n","     Total: 0.656181\n","     Box: 0.100425\n","     Obj: 0.000481\n","     Cls: 0.505115\n","   Manual Check:\n","     Manual focal: 0.000341\n","     Difference: 0.000141\n","\n","âš ï¸ Training interrupted by user\n"]}]},{"cell_type":"markdown","source":["ä»¥ä¸‹ã€geminiç‰ˆ"],"metadata":{"id":"IG2BN_oHFfI-"}},{"cell_type":"code","source":["# Google Driveãƒã‚¦ãƒ³ãƒˆ\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç§»å‹•\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/gemini')\n","!nvidia-smi\n","\n","# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¢ºèª\n","import glob\n","checkpoints = glob.glob('saved_models/checkpoint_epoch_*.pth')\n","print(f\"Found checkpoints: {[os.path.basename(f) for f in checkpoints]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMxtPxkpFaM0","executionInfo":{"status":"ok","timestamp":1749184535584,"user_tz":-540,"elapsed":2221,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"cdc24a39-5851-4da5-cf0f-b0ed05cff887"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Fri Jun  6 04:35:35 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0             30W /   70W |    7012MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n","Found checkpoints: []\n"]}]},{"cell_type":"code","source":["# ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","\n","# Google Driveã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚³ãƒ”ãƒ¼ (æ™‚é–“ã¯ã‹ã‹ã‚Šã¾ã™)\n","# ãƒ‘ã‚¹ã¯å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åˆã‚ã›ã¦ãã ã•ã„\n","!echo \"Copying training images...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!echo \"Copying training labels...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/\n","!echo \"Copy complete!\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayI7EA9nFcjq","executionInfo":{"status":"ok","timestamp":1749183628688,"user_tz":-540,"elapsed":463587,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"41c22df5-d883-4caa-af6f-ad940444c694"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying training images...\n","Copying training labels...\n","Copy complete!\n"]}]},{"cell_type":"code","source":["# æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰è‡ªå‹•å†é–‹\n","exec(open('unified_training.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxszOY3VFeXK","executionInfo":{"status":"ok","timestamp":1749184545290,"user_tz":-540,"elapsed":8670,"user":{"displayName":"ã¿ã¯","userId":"00152872231100665214"}},"outputId":"7d277b96-e84d-45a2-9ca1-c62c660f3ef0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Starting Unified EfficientNet Training with Warmup (v2.3)\n","ğŸ“± Device: cuda\n","ğŸ”¥ Warmup enabled for 500 steps.\n","test\n","\n","=== ğŸ“š Dataset Loading ===\n","âœ… Dataset: 10742 samples\n","\n","=== ğŸ¯ Anchor Optimization ===\n","ğŸ“Š Analyzing dataset statistics from 1000 samples...\n","   Progress: 100/1000 (10.0%) - 0.2s\n","   Progress: 200/1000 (20.0%) - 0.4s\n","   Progress: 300/1000 (30.0%) - 0.7s\n","   Progress: 400/1000 (40.0%) - 0.9s\n","   Progress: 500/1000 (50.0%) - 1.1s\n","   Progress: 600/1000 (60.0%) - 1.3s\n","   Progress: 700/1000 (70.0%) - 1.6s\n","   Progress: 800/1000 (80.0%) - 1.8s\n","   Progress: 900/1000 (90.0%) - 2.0s\n","âœ… Analysis completed: 15220 valid boxes found in 2.3s\n","\n","ğŸ“ˆ Dataset Statistics:\n","   Total boxes: 15220\n","   Avg size: 24.7 x 29.9 pixels\n","   Size distribution: Small=11854, Medium=2824, Large=542\n","\n","ğŸ”§ Generating optimized anchors...\n","ğŸ”§ Generating 9 anchors using K-means++ (max 300 iterations)...\n","ğŸ‰ Generated optimized anchors:\n","   Level 0: [(9, 10), (14, 26), (38, 26)]\n","   Level 1: [(24, 53), (74, 52), (45, 106)]\n","   Level 2: [(128, 86), (98, 219), (203, 144)]\n","âœ… Anchor optimization completed in 0.3s\n","âœ… Anchor optimization completed\n","\n","ğŸ†š Comparing anchor sets...\n","\n","--- Anchor Set 1 (Default) ---\n","ğŸ“ Evaluating anchor quality with 500 samples...\n","ğŸ“ˆ Evaluating anchor performance...\n","   å¹³å‡IoU: 0.5698 (Â±0.1806)\n","   50%ã‚«ãƒãƒ¬ãƒƒã‚¸: 69.82%\n","   70%ã‚«ãƒãƒ¬ãƒƒã‚¸: 23.26%\n","   90%ã‚«ãƒãƒ¬ãƒƒã‚¸: 2.63%\n","   æœªä½¿ç”¨ã‚¢ãƒ³ã‚«ãƒ¼: 0/9\n","\n","--- Anchor Set 2 (Optimized) ---\n","ğŸ“ Evaluating anchor quality with 500 samples...\n","ğŸ“ˆ Evaluating anchor performance...\n","   å¹³å‡IoU: 0.5849 (Â±0.1693)\n","   50%ã‚«ãƒãƒ¬ãƒƒã‚¸: 70.50%\n","   70%ã‚«ãƒãƒ¬ãƒƒã‚¸: 25.36%\n","   90%ã‚«ãƒãƒ¬ãƒƒã‚¸: 2.15%\n","   æœªä½¿ç”¨ã‚¢ãƒ³ã‚«ãƒ¼: 0/9\n","\n","ğŸ“Š Improvement Summary:\n","   Mean IoU: +0.0151\n","   50% Coverage: +0.68%\n","   70% Coverage: +2.10%\n","   âš ï¸ Limited improvement. Consider different strategies.\n","ğŸ“¦ Batches per epoch: 538\n","\n","=== ğŸ¤– Model Initialization ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","\n","=== ğŸ” Grid Size Detection ===\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","ğŸ“ Grid sizes: [(256, 320), (64, 80), (32, 40)]\n","\n","=== ğŸ¯ Loss Function Setup ===\n","ğŸ¯ Creating Enhanced Loss with strategy: balanced\n","ğŸ¯ Enhanced Loss initialized:\n","   Box Loss: ciou, Obj Loss: adaptive_focal, Cls Loss: label_smooth\n","   Loss Weights: Box=5.0, Obj=2.0, Cls=1.0\n","\n","=== âš™ï¸ Optimizer Setup ===\n","\n","ğŸ¬ Training Started!\n","\n","ğŸ¯ Epoch 1/30 | ğŸ§Š Stage: Head+Neck Only\n","\n","âŒ Training failed: name 'cls_loss' is not defined\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"<string>\", line 812, in <module>\n","  File \"<string>\", line 749, in main\n","  File \"<string>\", line 452, in debug_loss_calculation_comprehensive\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/IR_obj_detction/gemini/unified_loss.py\", line 294, in forward\n","NameError: name 'cls_loss' is not defined\n"]}]}]}