{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMhOa84EavkbpHcxskZ+TZg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tUzuXgIjHRq","executionInfo":{"status":"ok","timestamp":1749194672189,"user_tz":-540,"elapsed":2847,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"e711b5cc-3098-4b0c-c417-ce05d7b646d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found checkpoints: []\n"]}],"source":["# Google Driveマウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 作業ディレクトリ移動\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/new/IR_obeject_Detection')\n","\n","# チェックポイント確認\n","import glob\n","checkpoints = glob.glob('saved_models/checkpoint_epoch_*.pth')\n","print(f\"Found checkpoints: {[os.path.basename(f) for f in checkpoints]}\")"]},{"cell_type":"code","source":["# ローカルに保存用ディレクトリを作成\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","\n","# Google Driveからローカルにデータセットをコピー (時間はかかります)\n","# パスは実際のプロジェクトに合わせてください\n","!echo \"Copying training images...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!echo \"Copying training labels...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/\n","!echo \"Copy complete!\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puxvQzu4jOSX","executionInfo":{"status":"ok","timestamp":1749194331918,"user_tz":-540,"elapsed":832345,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"1c96a15a-1ea7-4e97-c056-850a7ee2db26"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying training images...\n","Copying training labels...\n","Copy complete!\n"]}]},{"cell_type":"code","source":["# テスト用コード\n","from efficientnet_model import test_model_creation\n","\n","model = test_model_creation()\n","if model:\n","    print(\"✅ モデル作成成功！\")\n","else:\n","    print(\"❌ モデル作成失敗\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1o98TFXp9o9","executionInfo":{"status":"ok","timestamp":1749192068727,"user_tz":-540,"elapsed":22636,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"44a6e7df-985d-48fd-d745-9b0cddc1f044"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["🧪 Testing model creation...\n","🏗️ Creating EfficientNet model (classes=15, pretrained=True)\n","🚀 Creating EfficientNetDetectionModel...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n","100%|██████████| 30.1M/30.1M [00:00<00:00, 87.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","🔧 Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","✅ Weight initialization completed\n","✅ EfficientNetDetectionModel created successfully\n","📊 Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","📥 Input shape: torch.Size([2, 1, 640, 512])\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","📤 Output shape: torch.Size([2, 264960, 20])\n","✅ Model test successful!\n","✅ モデル作成成功！\n"]}]},{"cell_type":"code","source":["# 最新チェックポイントから自動再開\n","exec(open('unified_training.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtK-nEMjjPxq","outputId":"5340b18a-b363-47cd-b696-c8537f3b89fa","executionInfo":{"status":"ok","timestamp":1749195050825,"user_tz":-540,"elapsed":378594,"user":{"displayName":"みは","userId":"00152872231100665214"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Unified EfficientNet Training with Comprehensive Debug\n","📱 Device: cuda\n","🎯 Target: 15 classes\n","📏 Input size: (640, 512)\n","ver 1.3-gemini - Corrected for Latest Project Structure\n","🧪 Testing model creation...\n","🏗️ Creating EfficientNet model (classes=15, pretrained=True)\n","🚀 Creating EfficientNetDetectionModel...\n",">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","🔧 Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","✅ Weight initialization completed\n","✅ EfficientNetDetectionModel created successfully\n","📊 Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","📥 Input shape: torch.Size([2, 1, 640, 512])\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","📤 Output shape: torch.Size([2, 264960, 20])\n","✅ Model test successful!\n","✅ モデル作成成功！\n","\n","=== 📚 Dataset Loading ===\n","✅ Dataset: 10742 samples\n","\n","=== 🎯 Anchor Optimization ===\n","📊 Analyzing dataset statistics from 1000 samples...\n","   Progress: 100/1000 (10.0%) - 0.2s\n","   Progress: 200/1000 (20.0%) - 0.5s\n","   Progress: 300/1000 (30.0%) - 0.7s\n","   Progress: 400/1000 (40.0%) - 0.9s\n","   Progress: 500/1000 (50.0%) - 1.2s\n","   Progress: 600/1000 (60.0%) - 1.4s\n","   Progress: 700/1000 (70.0%) - 1.7s\n","   Progress: 800/1000 (80.0%) - 1.9s\n","   Progress: 900/1000 (90.0%) - 2.2s\n","✅ Analysis completed: 15220 valid boxes found in 2.5s\n","\n","📈 Dataset Statistics:\n","   Total boxes: 15220\n","   Avg size: 24.7 x 29.9 pixels\n","   Size distribution: Small=11854, Medium=2824, Large=542\n","\n","🔧 Generating optimized anchors...\n","🔧 Generating 9 anchors using K-means++ (max 300 iterations)...\n","🎉 Generated optimized anchors:\n","   Level 0: [(9, 10), (14, 26), (38, 26)]\n","   Level 1: [(24, 53), (74, 52), (45, 106)]\n","   Level 2: [(128, 86), (98, 219), (203, 144)]\n","✅ Anchor optimization completed in 0.3s\n","✅ Anchor optimization completed\n","\n","=== 📊 Anchor Comparison ===\n","\n","🆚 Comparing anchor sets...\n","\n","--- Anchor Set 1 (Default) ---\n","📏 Evaluating anchor quality with 500 samples...\n","📈 Evaluating anchor performance...\n","   平均IoU: 0.5698 (±0.1806)\n","   50%カバレッジ: 69.82%\n","   70%カバレッジ: 23.26%\n","   90%カバレッジ: 2.63%\n","   未使用アンカー: 0/9\n","\n","--- Anchor Set 2 (Optimized) ---\n","📏 Evaluating anchor quality with 500 samples...\n","📈 Evaluating anchor performance...\n","   平均IoU: 0.5849 (±0.1693)\n","   50%カバレッジ: 70.50%\n","   70%カバレッジ: 25.36%\n","   90%カバレッジ: 2.15%\n","   未使用アンカー: 0/9\n","\n","📊 Improvement Summary:\n","   Mean IoU: +0.0151\n","   50% Coverage: +0.68%\n","   70% Coverage: +2.10%\n","   ⚠️ Limited improvement. Consider different strategies.\n","📦 Batches per epoch: 538\n","📊 Progress will be shown every 10 batches\n","\n","=== 🤖 Model Initialization ===\n","🏗️ Creating EfficientNet model (classes=15, pretrained=True)\n","🚀 Creating EfficientNetDetectionModel...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","🔧 Initializing SafeDetectionHead weights...\n","   Setting objectness bias to -4.0 for 3 anchors\n","✅ Weight initialization completed\n","✅ EfficientNetDetectionModel created successfully\n","📊 Model Statistics:\n","   Total parameters: 9,514,012\n","   Trainable parameters: 9,514,012\n","   vs ResNet50 (~25M): 0.4x\n","\n","=== 🔍 Grid Size Detection ===\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","📐 Grid sizes: [(256, 320), (64, 80), (32, 40)]\n","\n","=== 🎯 Loss Function Setup ===\n","🎯 Creating Enhanced Loss with strategy: balanced\n","🎯 Enhanced Loss initialized:\n","   Box Loss: ciou, Obj Loss: adaptive_focal, Cls Loss: label_smooth\n","   Loss Weights: Box=5.0, Obj=2.0, Cls=1.0\n","\n","=== ⚙️ Optimizer Setup ===\n","\n","🎬 Training Started with Debug System!\n","\n","🎯 Epoch 1/30\n","🧊 Stage: Head+Neck Only\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 0, Batch 0\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=0.000138, std=0.010233\n","     Obj biases: mean=-2.000000, std=0.000000\n","   🔍 Gradient Analysis:\n","     ⚠️ No gradients found (may be due to gradient accumulation)\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-1.987495, min=-2.425781, max=-1.451172\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.795 (1.358596)\n","       Obj: 0.002 (0.002903)\n","       Cls: 0.203 (0.347292)\n","     🚨 OBJ LOSS TOO WEAK: 0.002\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 0, Batch 0\n","   Target Summary:\n","     Positive (>0.01): 1283\n","     Positive (>0.1): 1064\n","     Mean positive: 0.561480\n","   Prediction Summary:\n","     Sigmoid mean: 0.120823\n","     Sigmoid std: 0.009213\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 1\n","   Loss Values:\n","     Total: 1.708790\n","     Box: 0.339649\n","     Obj: 0.000726\n","     Cls: 0.694584\n","   Manual Check:\n","     Manual focal: 0.000632\n","     Difference: 0.000094\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 0, Batch 1\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=0.000138, std=0.010233\n","     Obj biases: mean=-2.000000, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=7.609099, norm=268.428101\n","     🚨 GRADIENT EXPLOSION: norm = 268.428101\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-1.986994, min=-2.445312, max=-1.380859\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.800 (1.401252)\n","       Obj: 0.002 (0.002873)\n","       Cls: 0.198 (0.347262)\n","     🚨 OBJ LOSS TOO WEAK: 0.002\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 0, Batch 1\n","   Target Summary:\n","     Positive (>0.01): 1273\n","     Positive (>0.1): 1036\n","     Mean positive: 0.560726\n","   Prediction Summary:\n","     Sigmoid mean: 0.120853\n","     Sigmoid std: 0.008863\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 2\n","   Loss Values:\n","     Total: 1.751387\n","     Box: 0.350313\n","     Obj: 0.000718\n","     Cls: 0.694523\n","   Manual Check:\n","     Manual focal: 0.000631\n","     Difference: 0.000087\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 0, Batch 2\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=0.000138, std=0.010233\n","     Obj biases: mean=-2.000000, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=15.179728, norm=535.361938\n","     🚨 GRADIENT EXPLOSION: norm = 535.361938\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-1.985901, min=-2.445312, max=-1.353516\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.793 (1.342071)\n","       Obj: 0.002 (0.003097)\n","       Cls: 0.205 (0.347216)\n","     🚨 OBJ LOSS TOO WEAK: 0.002\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 0, Batch 2\n","   Target Summary:\n","     Positive (>0.01): 1535\n","     Positive (>0.1): 1268\n","     Mean positive: 0.573103\n","   Prediction Summary:\n","     Sigmoid mean: 0.120994\n","     Sigmoid std: 0.009258\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 3\n","   Loss Values:\n","     Total: 1.692384\n","     Box: 0.335518\n","     Obj: 0.000774\n","     Cls: 0.694432\n","   Manual Check:\n","     Manual focal: 0.000670\n","     Difference: 0.000105\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 0, Batch 3\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=0.000138, std=0.010233\n","     Obj biases: mean=-2.000000, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=22.653366, norm=799.535950\n","     🚨 GRADIENT EXPLOSION: norm = 799.535950\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-1.986117, min=-2.457031, max=-1.416016\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.796 (1.364868)\n","       Obj: 0.002 (0.002831)\n","       Cls: 0.203 (0.347288)\n","     🚨 OBJ LOSS TOO WEAK: 0.002\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 0, Batch 3\n","   Target Summary:\n","     Positive (>0.01): 1175\n","     Positive (>0.1): 984\n","     Mean positive: 0.564029\n","   Prediction Summary:\n","     Sigmoid mean: 0.120967\n","     Sigmoid std: 0.009197\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 4\n","   Loss Values:\n","     Total: 1.714987\n","     Box: 0.341217\n","     Obj: 0.000708\n","     Cls: 0.694575\n","   Manual Check:\n","     Manual focal: 0.000621\n","     Difference: 0.000087\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 1, Batch 4\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000862, std=0.010233\n","     Obj biases: mean=-2.000980, std=0.000000\n","   🔍 Gradient Analysis:\n","     ⚠️ No gradients found (may be due to gradient accumulation)\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.305567, min=-5.015625, max=0.335938\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.611 (0.452126)\n","       Obj: 0.009 (0.006742)\n","       Cls: 0.380 (0.280708)\n","     🚨 OBJ LOSS TOO WEAK: 0.009\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 1, Batch 4\n","   Target Summary:\n","     Positive (>0.01): 1292\n","     Positive (>0.1): 1057\n","     Mean positive: 0.555909\n","   Prediction Summary:\n","     Sigmoid mean: 0.117757\n","     Sigmoid std: 0.087416\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 5\n","   Loss Values:\n","     Total: 0.739577\n","     Box: 0.113032\n","     Obj: 0.001686\n","     Cls: 0.561416\n","   Manual Check:\n","     Manual focal: 0.001581\n","     Difference: 0.000105\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 1, Batch 5\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000862, std=0.010233\n","     Obj biases: mean=-2.000980, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=162.988220, norm=11807.378906\n","     🚨 GRADIENT EXPLOSION: norm = 11807.378906\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.298929, min=-5.472656, max=0.445312\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.604 (0.434712)\n","       Obj: 0.010 (0.006918)\n","       Cls: 0.386 (0.277688)\n","     🚨 OBJ LOSS TOO WEAK: 0.010\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 1, Batch 5\n","   Target Summary:\n","     Positive (>0.01): 1442\n","     Positive (>0.1): 1164\n","     Mean positive: 0.554887\n","   Prediction Summary:\n","     Sigmoid mean: 0.118121\n","     Sigmoid std: 0.087499\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 6\n","   Loss Values:\n","     Total: 0.719318\n","     Box: 0.108678\n","     Obj: 0.001729\n","     Cls: 0.555376\n","   Manual Check:\n","     Manual focal: 0.001616\n","     Difference: 0.000113\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 1, Batch 6\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000862, std=0.010233\n","     Obj biases: mean=-2.000980, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=326.665405, norm=23700.345703\n","     🚨 GRADIENT EXPLOSION: norm = 23700.345703\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.301798, min=-4.910156, max=-0.017578\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.616 (0.462200)\n","       Obj: 0.010 (0.007148)\n","       Cls: 0.375 (0.281566)\n","     🚨 OBJ LOSS TOO WEAK: 0.010\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 1, Batch 6\n","   Target Summary:\n","     Positive (>0.01): 1742\n","     Positive (>0.1): 1479\n","     Mean positive: 0.584421\n","   Prediction Summary:\n","     Sigmoid mean: 0.118024\n","     Sigmoid std: 0.087176\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 7\n","   Loss Values:\n","     Total: 0.750915\n","     Box: 0.115550\n","     Obj: 0.001787\n","     Cls: 0.563132\n","   Manual Check:\n","     Manual focal: 0.001644\n","     Difference: 0.000143\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 1, Batch 7\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000862, std=0.010233\n","     Obj biases: mean=-2.000980, std=0.000000\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=485.565765, norm=35300.328125\n","     🚨 GRADIENT EXPLOSION: norm = 35300.328125\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.296930, min=-5.164062, max=0.167969\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.611 (0.448584)\n","       Obj: 0.009 (0.006573)\n","       Cls: 0.380 (0.279374)\n","     🚨 OBJ LOSS TOO WEAK: 0.009\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 1, Batch 7\n","   Target Summary:\n","     Positive (>0.01): 1275\n","     Positive (>0.1): 1031\n","     Mean positive: 0.565021\n","   Prediction Summary:\n","     Sigmoid mean: 0.117679\n","     Sigmoid std: 0.086164\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 8\n","   Loss Values:\n","     Total: 0.734531\n","     Box: 0.112146\n","     Obj: 0.001643\n","     Cls: 0.558747\n","   Manual Check:\n","     Manual focal: 0.001548\n","     Difference: 0.000095\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 2, Batch 8\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000864, std=0.010232\n","     Obj biases: mean=-2.000983, std=0.000001\n","   🔍 Gradient Analysis:\n","     ⚠️ No gradients found (may be due to gradient accumulation)\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.313176, min=-4.777344, max=0.013672\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.601 (0.427706)\n","       Obj: 0.010 (0.007088)\n","       Cls: 0.389 (0.276523)\n","     🚨 OBJ LOSS TOO WEAK: 0.010\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 2, Batch 8\n","   Target Summary:\n","     Positive (>0.01): 1370\n","     Positive (>0.1): 1103\n","     Mean positive: 0.558865\n","   Prediction Summary:\n","     Sigmoid mean: 0.118541\n","     Sigmoid std: 0.089907\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 9\n","   Loss Values:\n","     Total: 0.711316\n","     Box: 0.106926\n","     Obj: 0.001772\n","     Cls: 0.553045\n","   Manual Check:\n","     Manual focal: 0.001667\n","     Difference: 0.000105\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 2, Batch 9\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000864, std=0.010232\n","     Obj biases: mean=-2.000983, std=0.000001\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=175.650986, norm=12768.936523\n","     🚨 GRADIENT EXPLOSION: norm = 12768.936523\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.299154, min=-5.187500, max=0.144531\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.613 (0.454421)\n","       Obj: 0.009 (0.006621)\n","       Cls: 0.378 (0.280176)\n","     🚨 OBJ LOSS TOO WEAK: 0.009\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 2, Batch 9\n","   Target Summary:\n","     Positive (>0.01): 1163\n","     Positive (>0.1): 968\n","     Mean positive: 0.568338\n","   Prediction Summary:\n","     Sigmoid mean: 0.117770\n","     Sigmoid std: 0.086877\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 10\n","   Loss Values:\n","     Total: 0.741218\n","     Box: 0.113605\n","     Obj: 0.001655\n","     Cls: 0.560352\n","   Manual Check:\n","     Manual focal: 0.001557\n","     Difference: 0.000098\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 2, Batch 10\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000864, std=0.010232\n","     Obj biases: mean=-2.000983, std=0.000001\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=338.631287, norm=24542.722656\n","     🚨 GRADIENT EXPLOSION: norm = 24542.722656\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.304840, min=-6.007812, max=0.654297\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.600 (0.429018)\n","       Obj: 0.010 (0.006815)\n","       Cls: 0.390 (0.279129)\n","     🚨 OBJ LOSS TOO WEAK: 0.010\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 2, Batch 10\n","   Target Summary:\n","     Positive (>0.01): 1292\n","     Positive (>0.1): 1048\n","     Mean positive: 0.570606\n","   Prediction Summary:\n","     Sigmoid mean: 0.117947\n","     Sigmoid std: 0.087816\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 11\n","   Loss Values:\n","     Total: 0.714961\n","     Box: 0.107254\n","     Obj: 0.001704\n","     Cls: 0.558258\n","   Manual Check:\n","     Manual focal: 0.001608\n","     Difference: 0.000095\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 2, Batch 11\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000864, std=0.010232\n","     Obj biases: mean=-2.000983, std=0.000001\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=505.139740, norm=36608.882812\n","     🚨 GRADIENT EXPLOSION: norm = 36608.882812\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.300014, min=-5.171875, max=0.445312\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.623 (0.476171)\n","       Obj: 0.008 (0.006289)\n","       Cls: 0.369 (0.281704)\n","     🚨 OBJ LOSS TOO WEAK: 0.008\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 2, Batch 11\n","   Target Summary:\n","     Positive (>0.01): 955\n","     Positive (>0.1): 809\n","     Mean positive: 0.568811\n","   Prediction Summary:\n","     Sigmoid mean: 0.117224\n","     Sigmoid std: 0.085779\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 12\n","   Loss Values:\n","     Total: 0.764164\n","     Box: 0.119043\n","     Obj: 0.001572\n","     Cls: 0.563408\n","   Manual Check:\n","     Manual focal: 0.001491\n","     Difference: 0.000081\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 3, Batch 12\n","   Target Summary:\n","     Positive (>0.01): 1218\n","     Positive (>0.1): 1025\n","     Mean positive: 0.573134\n","   Prediction Summary:\n","     Sigmoid mean: 0.118679\n","     Sigmoid std: 0.092361\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 13\n","   Loss Values:\n","     Total: 0.727382\n","     Box: 0.110742\n","     Obj: 0.001829\n","     Cls: 0.554195\n","   Manual Check:\n","     Manual focal: 0.001725\n","     Difference: 0.000104\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 3, Batch 13\n","   Target Summary:\n","     Positive (>0.01): 1027\n","     Positive (>0.1): 843\n","     Mean positive: 0.546422\n","   Prediction Summary:\n","     Sigmoid mean: 0.117727\n","     Sigmoid std: 0.089222\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 14\n","   Loss Values:\n","     Total: 0.711884\n","     Box: 0.107453\n","     Obj: 0.001667\n","     Cls: 0.550816\n","   Manual Check:\n","     Manual focal: 0.001576\n","     Difference: 0.000090\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 3, Batch 14\n","   Target Summary:\n","     Positive (>0.01): 1492\n","     Positive (>0.1): 1246\n","     Mean positive: 0.569780\n","   Prediction Summary:\n","     Sigmoid mean: 0.117651\n","     Sigmoid std: 0.089164\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 15\n","   Loss Values:\n","     Total: 0.748606\n","     Box: 0.115443\n","     Obj: 0.001774\n","     Cls: 0.559477\n","   Manual Check:\n","     Manual focal: 0.001648\n","     Difference: 0.000126\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 3, Batch 15\n","   Target Summary:\n","     Positive (>0.01): 1612\n","     Positive (>0.1): 1297\n","     Mean positive: 0.553739\n","   Prediction Summary:\n","     Sigmoid mean: 0.117910\n","     Sigmoid std: 0.089823\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 16\n","   Loss Values:\n","     Total: 0.722738\n","     Box: 0.109560\n","     Obj: 0.001823\n","     Cls: 0.554413\n","   Manual Check:\n","     Manual focal: 0.001694\n","     Difference: 0.000129\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 5, Batch 20\n","   Target Summary:\n","     Positive (>0.01): 1372\n","     Positive (>0.1): 1134\n","     Mean positive: 0.568688\n","   Prediction Summary:\n","     Sigmoid mean: 0.115887\n","     Sigmoid std: 0.089074\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 21\n","   Loss Values:\n","     Total: 0.720102\n","     Box: 0.110152\n","     Obj: 0.001712\n","     Cls: 0.545290\n","   Manual Check:\n","     Manual focal: 0.001598\n","     Difference: 0.000114\n","\n","🔬 [COMPREHENSIVE DEBUG] Step 7, Batch 30\n","   Target Summary:\n","     Positive (>0.01): 1435\n","     Positive (>0.1): 1169\n","     Mean positive: 0.563640\n","   Prediction Summary:\n","     Sigmoid mean: 0.112187\n","     Sigmoid std: 0.086468\n","   Focal Loss State:\n","     Gamma: 2.0\n","     Alpha: 0.75\n","     Internal step: 31\n","   Loss Values:\n","     Total: 0.699339\n","     Box: 0.106061\n","     Obj: 0.001601\n","     Cls: 0.537383\n","   Manual Check:\n","     Manual focal: 0.001481\n","     Difference: 0.000121\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 10, Batch 40\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000896, std=0.010227\n","     Obj biases: mean=-2.001032, std=0.000080\n","   🔍 Gradient Analysis:\n","     ⚠️ No gradients found (may be due to gradient accumulation)\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.478022, min=-5.671875, max=-0.302734\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.616 (0.416495)\n","       Obj: 0.007 (0.004818)\n","       Cls: 0.376 (0.254393)\n","     🚨 OBJ LOSS TOO WEAK: 0.007\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 10, Batch 41\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000896, std=0.010227\n","     Obj biases: mean=-2.001032, std=0.000080\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=131.136276, norm=9574.916016\n","     🚨 GRADIENT EXPLOSION: norm = 9574.916016\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.482318, min=-5.957031, max=-0.147461\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.601 (0.399737)\n","       Obj: 0.008 (0.005113)\n","       Cls: 0.391 (0.259769)\n","     🚨 OBJ LOSS TOO WEAK: 0.008\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 10, Batch 42\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000896, std=0.010227\n","     Obj biases: mean=-2.001032, std=0.000080\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=264.998138, norm=19412.189453\n","     🚨 GRADIENT EXPLOSION: norm = 19412.189453\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.487983, min=-5.445312, max=-0.169922\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.609 (0.405061)\n","       Obj: 0.008 (0.005199)\n","       Cls: 0.383 (0.254905)\n","     🚨 OBJ LOSS TOO WEAK: 0.008\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 10, Batch 43\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000896, std=0.010227\n","     Obj biases: mean=-2.001032, std=0.000080\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=396.357269, norm=29121.341797\n","     🚨 GRADIENT EXPLOSION: norm = 29121.341797\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.486478, min=-5.546875, max=-0.172852\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.611 (0.412357)\n","       Obj: 0.007 (0.004882)\n","       Cls: 0.381 (0.257350)\n","     🚨 OBJ LOSS TOO WEAK: 0.007\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 20, Batch 80\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000940, std=0.010213\n","     Obj biases: mean=-2.001091, std=0.000357\n","   🔍 Gradient Analysis:\n","     ⚠️ No gradients found (may be due to gradient accumulation)\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.899290, min=-5.656250, max=-1.378906\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.635 (0.346071)\n","       Obj: 0.005 (0.002534)\n","       Cls: 0.361 (0.196649)\n","     🚨 OBJ LOSS TOO WEAK: 0.005\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 20, Batch 81\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000940, std=0.010213\n","     Obj biases: mean=-2.001091, std=0.000357\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=17.113235, norm=1886.527222\n","     🚨 GRADIENT EXPLOSION: norm = 1886.527222\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.918596, min=-5.914062, max=-1.279297\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.639 (0.350116)\n","       Obj: 0.004 (0.002091)\n","       Cls: 0.357 (0.195741)\n","     🚨 OBJ LOSS TOO WEAK: 0.004\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 20, Batch 82\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000940, std=0.010213\n","     Obj biases: mean=-2.001091, std=0.000357\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=37.729362, norm=3852.035889\n","     🚨 GRADIENT EXPLOSION: norm = 3852.035889\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.867196, min=-5.699219, max=-1.328125\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.624 (0.332932)\n","       Obj: 0.004 (0.002051)\n","       Cls: 0.372 (0.198689)\n","     🚨 OBJ LOSS TOO WEAK: 0.004\n","\n","🔬 [ROOT CAUSE INVESTIGATION] Step 20, Batch 83\n","   🔍 Model Weights Analysis:\n","     Obj weights: mean=-0.000940, std=0.010213\n","     Obj biases: mean=-2.001091, std=0.000357\n","   🔍 Gradient Analysis:\n","     Obj gradients: mean=58.916313, norm=5788.627930\n","     🚨 GRADIENT EXPLOSION: norm = 5788.627930\n","   🔍 Activation Analysis:\n","     Obj logits: mean=-2.948874, min=-5.851562, max=-1.387695\n","   🔍 Loss Component Analysis:\n","     Loss contributions:\n","       Box: 0.632 (0.341446)\n","       Obj: 0.005 (0.002465)\n","       Cls: 0.364 (0.196745)\n","     🚨 OBJ LOSS TOO WEAK: 0.005\n","\n","⚠️ Training interrupted by user\n"]}]},{"cell_type":"markdown","source":["以下、gemini版"],"metadata":{"id":"IG2BN_oHFfI-"}},{"cell_type":"code","source":["# Google Driveマウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 作業ディレクトリ移動\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/gemini')\n","!nvidia-smi\n","\n","# チェックポイント確認\n","import glob\n","checkpoints = glob.glob('saved_models/checkpoint_epoch_*.pth')\n","print(f\"Found checkpoints: {[os.path.basename(f) for f in checkpoints]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMxtPxkpFaM0","executionInfo":{"status":"ok","timestamp":1749184535584,"user_tz":-540,"elapsed":2221,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"cdc24a39-5851-4da5-cf0f-b0ed05cff887"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Fri Jun  6 04:35:35 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0             30W /   70W |    7012MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n","Found checkpoints: []\n"]}]},{"cell_type":"code","source":["# ローカルに保存用ディレクトリを作成\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","\n","# Google Driveからローカルにデータセットをコピー (時間はかかります)\n","# パスは実際のプロジェクトに合わせてください\n","!echo \"Copying training images...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!echo \"Copying training labels...\"\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/\n","!echo \"Copy complete!\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayI7EA9nFcjq","executionInfo":{"status":"ok","timestamp":1749183628688,"user_tz":-540,"elapsed":463587,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"41c22df5-d883-4caa-af6f-ad940444c694"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying training images...\n","Copying training labels...\n","Copy complete!\n"]}]},{"cell_type":"code","source":["# 最新チェックポイントから自動再開\n","exec(open('unified_training.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxszOY3VFeXK","executionInfo":{"status":"ok","timestamp":1749184545290,"user_tz":-540,"elapsed":8670,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"7d277b96-e84d-45a2-9ca1-c62c660f3ef0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Unified EfficientNet Training with Warmup (v2.3)\n","📱 Device: cuda\n","🔥 Warmup enabled for 500 steps.\n","test\n","\n","=== 📚 Dataset Loading ===\n","✅ Dataset: 10742 samples\n","\n","=== 🎯 Anchor Optimization ===\n","📊 Analyzing dataset statistics from 1000 samples...\n","   Progress: 100/1000 (10.0%) - 0.2s\n","   Progress: 200/1000 (20.0%) - 0.4s\n","   Progress: 300/1000 (30.0%) - 0.7s\n","   Progress: 400/1000 (40.0%) - 0.9s\n","   Progress: 500/1000 (50.0%) - 1.1s\n","   Progress: 600/1000 (60.0%) - 1.3s\n","   Progress: 700/1000 (70.0%) - 1.6s\n","   Progress: 800/1000 (80.0%) - 1.8s\n","   Progress: 900/1000 (90.0%) - 2.0s\n","✅ Analysis completed: 15220 valid boxes found in 2.3s\n","\n","📈 Dataset Statistics:\n","   Total boxes: 15220\n","   Avg size: 24.7 x 29.9 pixels\n","   Size distribution: Small=11854, Medium=2824, Large=542\n","\n","🔧 Generating optimized anchors...\n","🔧 Generating 9 anchors using K-means++ (max 300 iterations)...\n","🎉 Generated optimized anchors:\n","   Level 0: [(9, 10), (14, 26), (38, 26)]\n","   Level 1: [(24, 53), (74, 52), (45, 106)]\n","   Level 2: [(128, 86), (98, 219), (203, 144)]\n","✅ Anchor optimization completed in 0.3s\n","✅ Anchor optimization completed\n","\n","🆚 Comparing anchor sets...\n","\n","--- Anchor Set 1 (Default) ---\n","📏 Evaluating anchor quality with 500 samples...\n","📈 Evaluating anchor performance...\n","   平均IoU: 0.5698 (±0.1806)\n","   50%カバレッジ: 69.82%\n","   70%カバレッジ: 23.26%\n","   90%カバレッジ: 2.63%\n","   未使用アンカー: 0/9\n","\n","--- Anchor Set 2 (Optimized) ---\n","📏 Evaluating anchor quality with 500 samples...\n","📈 Evaluating anchor performance...\n","   平均IoU: 0.5849 (±0.1693)\n","   50%カバレッジ: 70.50%\n","   70%カバレッジ: 25.36%\n","   90%カバレッジ: 2.15%\n","   未使用アンカー: 0/9\n","\n","📊 Improvement Summary:\n","   Mean IoU: +0.0151\n","   50% Coverage: +0.68%\n","   70% Coverage: +2.10%\n","   ⚠️ Limited improvement. Consider different strategies.\n","📦 Batches per epoch: 538\n","\n","=== 🤖 Model Initialization ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[">> EfficientNet-B1 backbone initialized\n","\n","=== EfficientNet-B1 Layer Structure ===\n","Layer 0: Conv2dNormActivation -> output shape: torch.Size([1, 32, 320, 256])\n","Layer 1: Sequential -> output shape: torch.Size([1, 16, 320, 256])\n","Layer 2: Sequential -> output shape: torch.Size([1, 24, 160, 128])\n","Layer 3: Sequential -> output shape: torch.Size([1, 40, 80, 64])\n","Layer 4: Sequential -> output shape: torch.Size([1, 80, 40, 32])\n","Layer 5: Sequential -> output shape: torch.Size([1, 112, 40, 32])\n","Layer 6: Sequential -> output shape: torch.Size([1, 192, 20, 16])\n","Layer 7: Sequential -> output shape: torch.Size([1, 320, 20, 16])\n","Layer 8: Conv2dNormActivation -> output shape: torch.Size([1, 1280, 20, 16])\n",">> AdaptiveFPN initialized for channels: [16, 40, 80]\n","\n","=== 🔍 Grid Size Detection ===\n",">> Adjusting FPN for actual channels: [16, 40, 112]\n","📐 Grid sizes: [(256, 320), (64, 80), (32, 40)]\n","\n","=== 🎯 Loss Function Setup ===\n","🎯 Creating Enhanced Loss with strategy: balanced\n","🎯 Enhanced Loss initialized:\n","   Box Loss: ciou, Obj Loss: adaptive_focal, Cls Loss: label_smooth\n","   Loss Weights: Box=5.0, Obj=2.0, Cls=1.0\n","\n","=== ⚙️ Optimizer Setup ===\n","\n","🎬 Training Started!\n","\n","🎯 Epoch 1/30 | 🧊 Stage: Head+Neck Only\n","\n","❌ Training failed: name 'cls_loss' is not defined\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"<string>\", line 812, in <module>\n","  File \"<string>\", line 749, in main\n","  File \"<string>\", line 452, in debug_loss_calculation_comprehensive\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/IR_obj_detction/gemini/unified_loss.py\", line 294, in forward\n","NameError: name 'cls_loss' is not defined\n"]}]}]}