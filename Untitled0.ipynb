{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMEEXpQ7GmK5aRLvLy0j+dX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSqu4K-oUAd0","executionInfo":{"status":"ok","timestamp":1749537629453,"user_tz":-540,"elapsed":468632,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"424970a1-e97a-4dcb-958c-391b56edd3c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# セル1: マウントとデータ準備\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# データをローカルにコピー（高速化のため）\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/"]},{"cell_type":"code","source":["# 作業ディレクトリ移動\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/new/IR_obeject_Detection')\n","\n","# セル2: train_minimal.py を保存して実行\n","# 上記の train_minimal.py の内容をコピペして保存\n","# または直接実行：\n","exec(open('train.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"drjLjGNxUCZe","executionInfo":{"status":"error","timestamp":1749537829280,"user_tz":-540,"elapsed":199829,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"32840986-62bc-4142-ff9e-5ac6c4c088bf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Modular YOLO Training\n","\n","================================================================================\n","📋 プロジェクト全体バージョン確認\n","================================================================================\n","\n","================================================================================\n","🚀 プロジェクト全体バージョン情報\n","⏰ 表示時刻: 2025-06-10 06:40:36\n","📊 管理対象ファイル数: 4\n","================================================================================\n","\n","1. 📄 Dataset System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 06:40:35\n","   🔗 Hash: e688c8cf\n","   📝 Latest: 06:40:35 - collate_fn実装\n","   📋 Total modifications: 2\n","\n","2. 📄 Model System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 06:40:35\n","   🔗 Hash: a8468646\n","   📝 Latest: 06:40:36 - 検出ヘッド最適化\n","   📋 Total modifications: 2\n","\n","3. 📄 Loss System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 06:40:36\n","   🔗 Hash: 58687c6a\n","   📝 Latest: 06:40:36 - 座標損失改善\n","   📋 Total modifications: 2\n","\n","4. 📄 Training System v1.1\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 06:40:36\n","   🔗 Hash: 06be62c2\n","   📝 Latest: 06:40:36 - gpu未使用原因の追究\n","   📋 Total modifications: 3\n","\n","================================================================================\n","🎉 バージョン情報表示完了\n","================================================================================\n","\n","\n","🔍 GPU環境詳細チェック\n","============================================================\n","1. CUDA available: True\n","   CUDA version: 12.4\n","   GPU count: 1\n","   Current device: 0\n","   Device name: Tesla T4\n","   GPU memory - Allocated: 0.00GB, Reserved: 0.00GB\n","2. PyTorch version: 2.6.0+cu124\n","3. Selected device: cuda\n","\n","📋 学習設定:\n","   Device: cuda\n","   Batch size: 8\n","   Image size: 416\n","   Classes: 15\n","\n","📊 Loading dataset...\n","   Dataset: 10742 images\n","   Batches: 1343\n","   DataLoader: workers=2, pin_memory=True\n","\n","🤖 Creating and setting up model...\n","   Moving model to cuda...\n","   Model parameters: 1,580,244\n","   Model device confirmed: cuda:0\n","\n","🔍 GPU学習セットアップをデバッグ中...\n","\n","🚀 学習セットアップ完全デバッグ\n","============================================================\n","\n","🔍 GPU環境詳細チェック\n","============================================================\n","1. CUDA available: True\n","   CUDA version: 12.4\n","   GPU count: 1\n","   Current device: 0\n","   Device name: Tesla T4\n","   GPU memory - Allocated: 0.01GB, Reserved: 0.02GB\n","2. PyTorch version: 2.6.0+cu124\n","3. Selected device: cuda\n","\n","🔍 モデルデバイス確認\n","----------------------------------------\n","Model device: cuda:0\n","GPU上のレイヤー: 22/22\n","✅ モデル全体がGPU上にあります\n","\n","🔍 GPU使用率テスト\n","----------------------------------------\n","大きなテンソル操作を実行中...\n","First operation result device: cuda:0\n","GPU計算時間: 0.15秒\n","同じ計算をCPUで実行中...\n","CPU計算時間: 34.97秒\n","テスト後のGPUメモリ - Allocated: 0.30GB, Reserved: 0.40GB\n","\n","🔍 DataLoader効率性チェック\n","----------------------------------------\n","Batch 0: Load 0.001s, GPU transfer 0.001s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","Batch 1: Load 0.001s, GPU transfer 0.001s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","Batch 2: Load 0.001s, GPU transfer 0.001s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","\n","平均読み込み時間: 0.001s\n","平均GPU転送時間: 0.001s\n","⚠️ GPU転送が遅い可能性があります\n","   対策: pin_memory=True, non_blocking=True を試してください\n","\n","🔍 実際の学習ステップをテスト中...\n","\n","🔍 データデバイス確認\n","----------------------------------------\n","Images device: cuda:0\n","Images shape: torch.Size([8, 1, 416, 416])\n","Images dtype: torch.float32\n","Targets[0] device: cpu\n","Targets[0] shape: torch.Size([31, 5])\n","\n","🔍 学習ステップモニタリング\n","----------------------------------------\n","Forward pass: 0.758s (+0.16GB)\n","Loss calculation: 0.684s (+0.00GB)\n","Backward pass: 0.671s (+-0.16GB)\n","Optimizer step: 0.161s (+0.01GB)\n","Total memory used: 0.04GB\n","Predictions device: cuda:0\n","Loss device: cuda:0\n","✅ デバッグ完了 - 学習を開始します\n","\n","🎯 Starting training on cuda...\n","\n","📊 初回バッチでGPU使用率確認...\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.559s, Loss: 20.8136\n","Batch [0/1343] Loss: 20.8136 LR: 0.001000\n","   Batch 1: 0.261s, Loss: 16.8071\n","   Batch 2: 0.224s, Loss: 11.8449\n","   Batch 3: 0.182s, Loss: 15.6658\n","   Batch 4: 0.235s, Loss: 11.2934\n","Batch [50/1343] Loss: 5.7259 LR: 0.001000\n","Batch [100/1343] Loss: 5.6061 LR: 0.001000\n","Batch [150/1343] Loss: 4.1926 LR: 0.001000\n","Batch [200/1343] Loss: 4.6684 LR: 0.001000\n","Batch [250/1343] Loss: 5.0154 LR: 0.001000\n","Batch [300/1343] Loss: 5.0268 LR: 0.001000\n","Batch [350/1343] Loss: 4.0837 LR: 0.001000\n","Batch [400/1343] Loss: 4.0400 LR: 0.001000\n","Batch [450/1343] Loss: 3.6166 LR: 0.001000\n","Batch [500/1343] Loss: 4.6195 LR: 0.001000\n","Batch [550/1343] Loss: 3.7946 LR: 0.001000\n","Batch [600/1343] Loss: 4.0712 LR: 0.001000\n","Batch [650/1343] Loss: 3.7186 LR: 0.001000\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f04d0795aa12>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 上記の train_minimal.py の内容をコピペして保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# または直接実行：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36mtrain_one_epoch_optimized\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/IR_obj_detction/new/IR_obeject_Detection/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predictions, targets, grid_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 xy_loss = F.mse_loss(pred[gi, :2].sigmoid(), \n\u001b[0m\u001b[1;32m     65\u001b[0m                                     torch.tensor([tx, ty], device=device))\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}