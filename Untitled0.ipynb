{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMEEXpQ7GmK5aRLvLy0j+dX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSqu4K-oUAd0","executionInfo":{"status":"ok","timestamp":1749540060944,"user_tz":-540,"elapsed":214246,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"50d8f3b7-1cc4-499f-b245-49b92b9b2dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# セル1: マウントとデータ準備\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# データをローカルにコピー（高速化のため）\n","!mkdir -p /content/FLIR_YOLO_local/images/train\n","!mkdir -p /content/FLIR_YOLO_local/labels/train\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/images/train/* /content/FLIR_YOLO_local/images/train/\n","!cp -r /content/drive/MyDrive/old/EfficientNet_Project/data/FLIR_YOLO/labels/train/* /content/FLIR_YOLO_local/labels/train/"]},{"cell_type":"code","source":["# 作業ディレクトリ移動\n","import os\n","os.chdir('/content/drive/MyDrive/IR_obj_detction/new/IR_obeject_Detection')\n","\n","# セル2: train_minimal.py を保存して実行\n","# 上記の train_minimal.py の内容をコピペして保存\n","# または直接実行：\n","exec(open('train.py').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"drjLjGNxUCZe","executionInfo":{"status":"error","timestamp":1749547147959,"user_tz":-540,"elapsed":7087018,"user":{"displayName":"みは","userId":"00152872231100665214"}},"outputId":"84fd31e6-b1c4-434b-bf90-8473b8219d72"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Modular YOLO Training\n","\n","================================================================================\n","📋 プロジェクト全体バージョン確認\n","================================================================================\n","\n","================================================================================\n","🚀 プロジェクト全体バージョン情報\n","⏰ 表示時刻: 2025-06-10 07:21:04\n","📊 管理対象ファイル数: 4\n","================================================================================\n","\n","1. 📄 Dataset System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 07:21:04\n","   🔗 Hash: 3b88545d\n","   📝 Latest: 07:21:04 - データ拡張機能を追加 (Phase 2)\n","   📋 Total modifications: 3\n","\n","2. 📄 Model System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 07:21:04\n","   🔗 Hash: a8468646\n","   📝 Latest: 07:21:04 - 検出ヘッド最適化\n","   📋 Total modifications: 2\n","\n","3. 📄 Loss System v1.0\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 07:21:04\n","   🔗 Hash: 58687c6a\n","   📝 Latest: 07:21:04 - 座標損失改善\n","   📋 Total modifications: 2\n","\n","4. 📄 Training System v1.1\n","   📌 Version: 1.0.0\n","   ⏰ Loaded: 07:21:04\n","   🔗 Hash: 06be62c2\n","   📝 Latest: 07:21:04 - gpu未使用原因の追究\n","   📋 Total modifications: 3\n","\n","================================================================================\n","🎉 バージョン情報表示完了\n","================================================================================\n","\n","\n","🔍 GPU環境詳細チェック\n","============================================================\n","1. CUDA available: True\n","   CUDA version: 12.4\n","   GPU count: 1\n","   Current device: 0\n","   Device name: Tesla T4\n","   GPU memory - Allocated: 0.00GB, Reserved: 0.00GB\n","2. PyTorch version: 2.6.0+cu124\n","3. Selected device: cuda\n","\n","📋 学習設定:\n","   Device: cuda\n","   Batch size: 8\n","   Image size: 416\n","   Classes: 15\n","\n","📊 Loading dataset...\n","   Dataset: 10742 images\n","   Batches: 1343\n","   DataLoader: workers=2, pin_memory=True\n","\n","🤖 Creating and setting up model...\n","   Moving model to cuda...\n","   Model parameters: 1,580,244\n","   Model device confirmed: cuda:0\n","\n","🔍 GPU学習セットアップをデバッグ中...\n","\n","🚀 学習セットアップ完全デバッグ\n","============================================================\n","\n","🔍 GPU環境詳細チェック\n","============================================================\n","1. CUDA available: True\n","   CUDA version: 12.4\n","   GPU count: 1\n","   Current device: 0\n","   Device name: Tesla T4\n","   GPU memory - Allocated: 0.01GB, Reserved: 0.02GB\n","2. PyTorch version: 2.6.0+cu124\n","3. Selected device: cuda\n","\n","🔍 モデルデバイス確認\n","----------------------------------------\n","Model device: cuda:0\n","GPU上のレイヤー: 22/22\n","✅ モデル全体がGPU上にあります\n","\n","🔍 GPU使用率テスト\n","----------------------------------------\n","大きなテンソル操作を実行中...\n","First operation result device: cuda:0\n","GPU計算時間: 0.03秒\n","同じ計算をCPUで実行中...\n","CPU計算時間: 35.71秒\n","テスト後のGPUメモリ - Allocated: 0.30GB, Reserved: 0.40GB\n","\n","🔍 DataLoader効率性チェック\n","----------------------------------------\n","Batch 0: Load 0.001s, GPU transfer 0.001s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","Batch 1: Load 0.006s, GPU transfer 0.006s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","Batch 2: Load 0.001s, GPU transfer 0.001s\n","   Images shape: torch.Size([8, 1, 416, 416]), device: cuda:0\n","\n","平均読み込み時間: 0.002s\n","平均GPU転送時間: 0.002s\n","⚠️ GPU転送が遅い可能性があります\n","   対策: pin_memory=True, non_blocking=True を試してください\n","\n","🔍 実際の学習ステップをテスト中...\n","\n","🔍 データデバイス確認\n","----------------------------------------\n","Images device: cuda:0\n","Images shape: torch.Size([8, 1, 416, 416])\n","Images dtype: torch.float32\n","Targets[0] device: cpu\n","Targets[0] shape: torch.Size([0, 5])\n","\n","🔍 学習ステップモニタリング\n","----------------------------------------\n","Forward pass: 0.236s (+0.16GB)\n","Loss calculation: 0.223s (+0.00GB)\n","Backward pass: 0.256s (+-0.16GB)\n","Optimizer step: 0.056s (+0.01GB)\n","Total memory used: 0.04GB\n","Predictions device: cuda:0\n","Loss device: cuda:0\n","✅ デバッグ完了 - 学習を開始します\n","\n","🎯 Starting training on cuda...\n","\n","📊 初回バッチでGPU使用率確認...\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.274s, Loss: 22.0866\n","Batch [0/1343] Loss: 22.0866 LR: 0.001000\n","   Batch 1: 0.219s, Loss: 21.0927\n","   Batch 2: 0.212s, Loss: 15.9443\n","   Batch 3: 0.213s, Loss: 14.9882\n","   Batch 4: 0.195s, Loss: 15.2913\n","Batch [50/1343] Loss: 6.8784 LR: 0.001000\n","Batch [100/1343] Loss: 5.6133 LR: 0.001000\n","Batch [150/1343] Loss: 5.3805 LR: 0.001000\n","Batch [200/1343] Loss: 4.5303 LR: 0.001000\n","Batch [250/1343] Loss: 4.5639 LR: 0.001000\n","Batch [300/1343] Loss: 3.6017 LR: 0.001000\n","Batch [350/1343] Loss: 4.9864 LR: 0.001000\n","Batch [400/1343] Loss: 3.7600 LR: 0.001000\n","Batch [450/1343] Loss: 4.4163 LR: 0.001000\n","Batch [500/1343] Loss: 3.9838 LR: 0.001000\n","Batch [550/1343] Loss: 4.1834 LR: 0.001000\n","Batch [600/1343] Loss: 3.4280 LR: 0.001000\n","Batch [650/1343] Loss: 3.2491 LR: 0.001000\n","Batch [700/1343] Loss: 4.5679 LR: 0.001000\n","Batch [750/1343] Loss: 4.4239 LR: 0.001000\n","Batch [800/1343] Loss: 2.8581 LR: 0.001000\n","Batch [850/1343] Loss: 3.9255 LR: 0.001000\n","Batch [900/1343] Loss: 3.6582 LR: 0.001000\n","Batch [950/1343] Loss: 4.4379 LR: 0.001000\n","Batch [1000/1343] Loss: 4.4257 LR: 0.001000\n","Batch [1050/1343] Loss: 3.9407 LR: 0.001000\n","Batch [1100/1343] Loss: 3.7503 LR: 0.001000\n","Batch [1150/1343] Loss: 4.5588 LR: 0.001000\n","Batch [1200/1343] Loss: 2.9578 LR: 0.001000\n","Batch [1250/1343] Loss: 3.1880 LR: 0.001000\n","Batch [1300/1343] Loss: 4.2390 LR: 0.001000\n","\n","Epoch [1/50] Loss: 4.4382 Time: 302.0s\n","   GPU Memory: 0.03GB allocated, 0.34GB reserved\n","💾 Best model saved (loss: 4.4382)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.369s, Loss: 4.4397\n","Batch [0/1343] Loss: 4.4397 LR: 0.001000\n","   Batch 1: 0.315s, Loss: 3.4871\n","   Batch 2: 0.207s, Loss: 4.1459\n","   Batch 3: 0.361s, Loss: 3.2084\n","   Batch 4: 0.360s, Loss: 3.5404\n","Batch [50/1343] Loss: 4.0181 LR: 0.001000\n","Batch [100/1343] Loss: 3.1641 LR: 0.001000\n","Batch [150/1343] Loss: 3.6363 LR: 0.001000\n","Batch [200/1343] Loss: 3.1989 LR: 0.001000\n","Batch [250/1343] Loss: 3.3362 LR: 0.001000\n","Batch [300/1343] Loss: 3.3273 LR: 0.001000\n","Batch [350/1343] Loss: 3.4986 LR: 0.001000\n","Batch [400/1343] Loss: 2.5448 LR: 0.001000\n","Batch [450/1343] Loss: 3.2547 LR: 0.001000\n","Batch [500/1343] Loss: 3.2188 LR: 0.001000\n","Batch [550/1343] Loss: 3.6270 LR: 0.001000\n","Batch [600/1343] Loss: 2.5626 LR: 0.001000\n","Batch [650/1343] Loss: 4.2080 LR: 0.001000\n","Batch [700/1343] Loss: 4.3223 LR: 0.001000\n","Batch [750/1343] Loss: 2.8963 LR: 0.001000\n","Batch [800/1343] Loss: 3.0315 LR: 0.001000\n","Batch [850/1343] Loss: 3.2549 LR: 0.001000\n","Batch [900/1343] Loss: 2.7117 LR: 0.001000\n","Batch [950/1343] Loss: 2.1833 LR: 0.001000\n","Batch [1000/1343] Loss: 3.1837 LR: 0.001000\n","Batch [1050/1343] Loss: 2.8550 LR: 0.001000\n","Batch [1100/1343] Loss: 2.9706 LR: 0.001000\n","Batch [1150/1343] Loss: 2.8780 LR: 0.001000\n","Batch [1200/1343] Loss: 2.8710 LR: 0.001000\n","Batch [1250/1343] Loss: 3.2596 LR: 0.001000\n","Batch [1300/1343] Loss: 2.4585 LR: 0.001000\n","\n","Epoch [2/50] Loss: 3.4683 Time: 303.6s\n","   GPU Memory: 0.03GB allocated, 0.33GB reserved\n","💾 Best model saved (loss: 3.4683)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.381s, Loss: 2.6305\n","Batch [0/1343] Loss: 2.6305 LR: 0.001000\n","   Batch 1: 0.228s, Loss: 2.6583\n","   Batch 2: 0.215s, Loss: 3.2380\n","   Batch 3: 0.230s, Loss: 2.9108\n","   Batch 4: 0.239s, Loss: 2.5466\n","Batch [50/1343] Loss: 4.2701 LR: 0.001000\n","Batch [100/1343] Loss: 2.7763 LR: 0.001000\n","Batch [150/1343] Loss: 2.7771 LR: 0.001000\n","Batch [200/1343] Loss: 2.9142 LR: 0.001000\n","Batch [250/1343] Loss: 2.9022 LR: 0.001000\n","Batch [300/1343] Loss: 2.6686 LR: 0.001000\n","Batch [350/1343] Loss: 2.3363 LR: 0.001000\n","Batch [400/1343] Loss: 3.7817 LR: 0.001000\n","Batch [450/1343] Loss: 3.3171 LR: 0.001000\n","Batch [500/1343] Loss: 3.3563 LR: 0.001000\n","Batch [550/1343] Loss: 3.0844 LR: 0.001000\n","Batch [600/1343] Loss: 3.0282 LR: 0.001000\n","Batch [650/1343] Loss: 3.3862 LR: 0.001000\n","Batch [700/1343] Loss: 3.0202 LR: 0.001000\n","Batch [750/1343] Loss: 3.0813 LR: 0.001000\n","Batch [800/1343] Loss: 3.3740 LR: 0.001000\n","Batch [850/1343] Loss: 3.7840 LR: 0.001000\n","Batch [900/1343] Loss: 4.0085 LR: 0.001000\n","Batch [950/1343] Loss: 2.9483 LR: 0.001000\n","Batch [1000/1343] Loss: 3.2085 LR: 0.001000\n","Batch [1050/1343] Loss: 2.8818 LR: 0.001000\n","Batch [1100/1343] Loss: 3.3508 LR: 0.001000\n","Batch [1150/1343] Loss: 2.9746 LR: 0.001000\n","Batch [1200/1343] Loss: 2.3792 LR: 0.001000\n","Batch [1250/1343] Loss: 3.4425 LR: 0.001000\n","Batch [1300/1343] Loss: 3.4993 LR: 0.001000\n","\n","Epoch [3/50] Loss: 3.1551 Time: 302.8s\n","   GPU Memory: 0.03GB allocated, 0.35GB reserved\n","💾 Best model saved (loss: 3.1551)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.225s, Loss: 3.3900\n","Batch [0/1343] Loss: 3.3900 LR: 0.001000\n","   Batch 1: 0.172s, Loss: 3.0492\n","   Batch 2: 0.170s, Loss: 2.3130\n","   Batch 3: 0.160s, Loss: 2.6157\n","   Batch 4: 0.253s, Loss: 2.5970\n","Batch [50/1343] Loss: 2.5297 LR: 0.001000\n","Batch [100/1343] Loss: 2.2887 LR: 0.001000\n","Batch [150/1343] Loss: 3.1414 LR: 0.001000\n","Batch [200/1343] Loss: 2.5782 LR: 0.001000\n","Batch [250/1343] Loss: 2.7177 LR: 0.001000\n","Batch [300/1343] Loss: 2.7426 LR: 0.001000\n","Batch [350/1343] Loss: 2.9363 LR: 0.001000\n","Batch [400/1343] Loss: 3.2479 LR: 0.001000\n","Batch [450/1343] Loss: 3.2467 LR: 0.001000\n","Batch [500/1343] Loss: 3.8857 LR: 0.001000\n","Batch [550/1343] Loss: 3.2058 LR: 0.001000\n","Batch [600/1343] Loss: 2.5001 LR: 0.001000\n","Batch [650/1343] Loss: 2.6487 LR: 0.001000\n","Batch [700/1343] Loss: 2.9724 LR: 0.001000\n","Batch [750/1343] Loss: 3.0466 LR: 0.001000\n","Batch [800/1343] Loss: 3.2214 LR: 0.001000\n","Batch [850/1343] Loss: 2.7617 LR: 0.001000\n","Batch [900/1343] Loss: 3.2285 LR: 0.001000\n","Batch [950/1343] Loss: 2.6964 LR: 0.001000\n","Batch [1000/1343] Loss: 2.6243 LR: 0.001000\n","Batch [1050/1343] Loss: 2.7840 LR: 0.001000\n","Batch [1100/1343] Loss: 2.7354 LR: 0.001000\n","Batch [1150/1343] Loss: 2.3049 LR: 0.001000\n","Batch [1200/1343] Loss: 2.6056 LR: 0.001000\n","Batch [1250/1343] Loss: 2.7280 LR: 0.001000\n","Batch [1300/1343] Loss: 3.0320 LR: 0.001000\n","\n","Epoch [4/50] Loss: 2.9215 Time: 302.0s\n","💾 Best model saved (loss: 2.9215)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.284s, Loss: 2.4313\n","Batch [0/1343] Loss: 2.4313 LR: 0.001000\n","   Batch 1: 0.221s, Loss: 3.0075\n","   Batch 2: 0.278s, Loss: 3.4484\n","   Batch 3: 0.182s, Loss: 2.6938\n","   Batch 4: 0.199s, Loss: 2.1019\n","Batch [50/1343] Loss: 2.3817 LR: 0.001000\n","Batch [100/1343] Loss: 2.3025 LR: 0.001000\n","Batch [150/1343] Loss: 2.6997 LR: 0.001000\n","Batch [200/1343] Loss: 2.7217 LR: 0.001000\n","Batch [250/1343] Loss: 2.3795 LR: 0.001000\n","Batch [300/1343] Loss: 3.2186 LR: 0.001000\n","Batch [350/1343] Loss: 2.9062 LR: 0.001000\n","Batch [400/1343] Loss: 2.8949 LR: 0.001000\n","Batch [450/1343] Loss: 3.1564 LR: 0.001000\n","Batch [500/1343] Loss: 2.9231 LR: 0.001000\n","Batch [550/1343] Loss: 1.9067 LR: 0.001000\n","Batch [600/1343] Loss: 2.2585 LR: 0.001000\n","Batch [650/1343] Loss: 3.1194 LR: 0.001000\n","Batch [700/1343] Loss: 2.2319 LR: 0.001000\n","Batch [750/1343] Loss: 2.5687 LR: 0.001000\n","Batch [800/1343] Loss: 2.1215 LR: 0.001000\n","Batch [850/1343] Loss: 2.3290 LR: 0.001000\n","Batch [900/1343] Loss: 2.4113 LR: 0.001000\n","Batch [950/1343] Loss: 2.2645 LR: 0.001000\n","Batch [1000/1343] Loss: 2.6391 LR: 0.001000\n","Batch [1050/1343] Loss: 3.2710 LR: 0.001000\n","Batch [1100/1343] Loss: 1.8228 LR: 0.001000\n","Batch [1150/1343] Loss: 2.2117 LR: 0.001000\n","Batch [1200/1343] Loss: 3.1992 LR: 0.001000\n","Batch [1250/1343] Loss: 3.6569 LR: 0.001000\n","Batch [1300/1343] Loss: 2.8649 LR: 0.001000\n","\n","Epoch [5/50] Loss: 2.7115 Time: 301.1s\n","💾 Best model saved (loss: 2.7115)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.207s, Loss: 2.2130\n","Batch [0/1343] Loss: 2.2130 LR: 0.001000\n","   Batch 1: 0.236s, Loss: 2.2696\n","   Batch 2: 0.166s, Loss: 2.2378\n","   Batch 3: 0.179s, Loss: 3.0219\n","   Batch 4: 0.184s, Loss: 2.2898\n","Batch [50/1343] Loss: 2.9081 LR: 0.001000\n","Batch [100/1343] Loss: 2.3211 LR: 0.001000\n","Batch [150/1343] Loss: 2.3182 LR: 0.001000\n","Batch [200/1343] Loss: 2.2849 LR: 0.001000\n","Batch [250/1343] Loss: 2.6113 LR: 0.001000\n","Batch [300/1343] Loss: 2.4915 LR: 0.001000\n","Batch [350/1343] Loss: 2.5239 LR: 0.001000\n","Batch [400/1343] Loss: 2.5548 LR: 0.001000\n","Batch [450/1343] Loss: 1.9632 LR: 0.001000\n","Batch [500/1343] Loss: 2.8150 LR: 0.001000\n","Batch [550/1343] Loss: 1.9787 LR: 0.001000\n","Batch [600/1343] Loss: 2.7552 LR: 0.001000\n","Batch [650/1343] Loss: 2.6332 LR: 0.001000\n","Batch [700/1343] Loss: 2.4424 LR: 0.001000\n","Batch [750/1343] Loss: 2.3267 LR: 0.001000\n","Batch [800/1343] Loss: 2.7945 LR: 0.001000\n","Batch [850/1343] Loss: 3.3349 LR: 0.001000\n","Batch [900/1343] Loss: 2.5856 LR: 0.001000\n","Batch [950/1343] Loss: 1.7352 LR: 0.001000\n","Batch [1000/1343] Loss: 2.7046 LR: 0.001000\n","Batch [1050/1343] Loss: 2.8479 LR: 0.001000\n","Batch [1100/1343] Loss: 2.2230 LR: 0.001000\n","Batch [1150/1343] Loss: 1.9105 LR: 0.001000\n","Batch [1200/1343] Loss: 2.0409 LR: 0.001000\n","Batch [1250/1343] Loss: 2.5265 LR: 0.001000\n","Batch [1300/1343] Loss: 2.2883 LR: 0.001000\n","\n","Epoch [6/50] Loss: 2.5097 Time: 299.5s\n","💾 Best model saved (loss: 2.5097)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.204s, Loss: 2.1646\n","Batch [0/1343] Loss: 2.1646 LR: 0.001000\n","   Batch 1: 0.271s, Loss: 2.1270\n","   Batch 2: 0.211s, Loss: 1.9497\n","   Batch 3: 0.168s, Loss: 1.9344\n","   Batch 4: 0.202s, Loss: 1.9499\n","Batch [50/1343] Loss: 2.3613 LR: 0.001000\n","Batch [100/1343] Loss: 2.8304 LR: 0.001000\n","Batch [150/1343] Loss: 1.9811 LR: 0.001000\n","Batch [200/1343] Loss: 2.2156 LR: 0.001000\n","Batch [250/1343] Loss: 2.1394 LR: 0.001000\n","Batch [300/1343] Loss: 2.4543 LR: 0.001000\n","Batch [350/1343] Loss: 2.6180 LR: 0.001000\n","Batch [400/1343] Loss: 2.0175 LR: 0.001000\n","Batch [450/1343] Loss: 2.3858 LR: 0.001000\n","Batch [500/1343] Loss: 2.4891 LR: 0.001000\n","Batch [550/1343] Loss: 2.0106 LR: 0.001000\n","Batch [600/1343] Loss: 3.0294 LR: 0.001000\n","Batch [650/1343] Loss: 2.2789 LR: 0.001000\n","Batch [700/1343] Loss: 1.7153 LR: 0.001000\n","Batch [750/1343] Loss: 2.5238 LR: 0.001000\n","Batch [800/1343] Loss: 2.2963 LR: 0.001000\n","Batch [850/1343] Loss: 2.2436 LR: 0.001000\n","Batch [900/1343] Loss: 2.3243 LR: 0.001000\n","Batch [950/1343] Loss: 2.4803 LR: 0.001000\n","Batch [1000/1343] Loss: 1.8982 LR: 0.001000\n","Batch [1050/1343] Loss: 1.7357 LR: 0.001000\n","Batch [1100/1343] Loss: 2.2256 LR: 0.001000\n","Batch [1150/1343] Loss: 2.9406 LR: 0.001000\n","Batch [1200/1343] Loss: 2.0937 LR: 0.001000\n","Batch [1250/1343] Loss: 2.4338 LR: 0.001000\n","Batch [1300/1343] Loss: 2.6531 LR: 0.001000\n","\n","Epoch [7/50] Loss: 2.3309 Time: 304.4s\n","💾 Best model saved (loss: 2.3309)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.387s, Loss: 2.2359\n","Batch [0/1343] Loss: 2.2359 LR: 0.001000\n","   Batch 1: 0.229s, Loss: 2.0928\n","   Batch 2: 0.254s, Loss: 1.8164\n","   Batch 3: 0.317s, Loss: 2.0638\n","   Batch 4: 0.251s, Loss: 2.3820\n","Batch [50/1343] Loss: 1.8354 LR: 0.001000\n","Batch [100/1343] Loss: 1.9534 LR: 0.001000\n","Batch [150/1343] Loss: 2.5938 LR: 0.001000\n","Batch [200/1343] Loss: 2.0559 LR: 0.001000\n","Batch [250/1343] Loss: 2.4697 LR: 0.001000\n","Batch [300/1343] Loss: 1.4987 LR: 0.001000\n","Batch [350/1343] Loss: 2.7660 LR: 0.001000\n","Batch [400/1343] Loss: 1.7413 LR: 0.001000\n","Batch [450/1343] Loss: 2.0526 LR: 0.001000\n","Batch [500/1343] Loss: 2.3303 LR: 0.001000\n","Batch [550/1343] Loss: 1.9123 LR: 0.001000\n","Batch [600/1343] Loss: 2.1703 LR: 0.001000\n","Batch [650/1343] Loss: 3.7048 LR: 0.001000\n","Batch [700/1343] Loss: 2.2195 LR: 0.001000\n","Batch [750/1343] Loss: 2.5334 LR: 0.001000\n","Batch [800/1343] Loss: 2.3527 LR: 0.001000\n","Batch [850/1343] Loss: 1.7777 LR: 0.001000\n","Batch [900/1343] Loss: 1.7517 LR: 0.001000\n","Batch [950/1343] Loss: 2.1783 LR: 0.001000\n","Batch [1000/1343] Loss: 2.4107 LR: 0.001000\n","Batch [1050/1343] Loss: 2.1390 LR: 0.001000\n","Batch [1100/1343] Loss: 2.1598 LR: 0.001000\n","Batch [1150/1343] Loss: 2.2966 LR: 0.001000\n","Batch [1200/1343] Loss: 2.4283 LR: 0.001000\n","Batch [1250/1343] Loss: 2.2021 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5468 LR: 0.001000\n","\n","Epoch [8/50] Loss: 2.1599 Time: 301.9s\n","💾 Best model saved (loss: 2.1599)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.208s, Loss: 1.8318\n","Batch [0/1343] Loss: 1.8318 LR: 0.001000\n","   Batch 1: 0.272s, Loss: 1.7125\n","   Batch 2: 0.306s, Loss: 2.6403\n","   Batch 3: 0.223s, Loss: 2.5908\n","   Batch 4: 0.274s, Loss: 2.2759\n","Batch [50/1343] Loss: 2.2900 LR: 0.001000\n","Batch [100/1343] Loss: 2.3044 LR: 0.001000\n","Batch [150/1343] Loss: 2.0127 LR: 0.001000\n","Batch [200/1343] Loss: 1.8375 LR: 0.001000\n","Batch [250/1343] Loss: 2.5948 LR: 0.001000\n","Batch [300/1343] Loss: 1.7305 LR: 0.001000\n","Batch [350/1343] Loss: 1.5330 LR: 0.001000\n","Batch [400/1343] Loss: 2.4558 LR: 0.001000\n","Batch [450/1343] Loss: 2.1305 LR: 0.001000\n","Batch [500/1343] Loss: 2.0844 LR: 0.001000\n","Batch [550/1343] Loss: 1.7930 LR: 0.001000\n","Batch [600/1343] Loss: 2.5569 LR: 0.001000\n","Batch [650/1343] Loss: 2.1291 LR: 0.001000\n","Batch [700/1343] Loss: 1.8016 LR: 0.001000\n","Batch [750/1343] Loss: 1.8377 LR: 0.001000\n","Batch [800/1343] Loss: 2.3100 LR: 0.001000\n","Batch [850/1343] Loss: 1.6835 LR: 0.001000\n","Batch [900/1343] Loss: 1.8863 LR: 0.001000\n","Batch [950/1343] Loss: 2.4537 LR: 0.001000\n","Batch [1000/1343] Loss: 2.0225 LR: 0.001000\n","Batch [1050/1343] Loss: 1.6895 LR: 0.001000\n","Batch [1100/1343] Loss: 2.0213 LR: 0.001000\n","Batch [1150/1343] Loss: 1.8716 LR: 0.001000\n","Batch [1200/1343] Loss: 1.9819 LR: 0.001000\n","Batch [1250/1343] Loss: 1.8672 LR: 0.001000\n","Batch [1300/1343] Loss: 2.0446 LR: 0.001000\n","\n","Epoch [9/50] Loss: 2.0110 Time: 301.3s\n","💾 Best model saved (loss: 2.0110)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.242s, Loss: 1.7642\n","Batch [0/1343] Loss: 1.7642 LR: 0.001000\n","   Batch 1: 0.220s, Loss: 1.7256\n","   Batch 2: 0.258s, Loss: 1.9303\n","   Batch 3: 0.262s, Loss: 1.9527\n","   Batch 4: 0.152s, Loss: 2.8968\n","Batch [50/1343] Loss: 1.7440 LR: 0.001000\n","Batch [100/1343] Loss: 1.8556 LR: 0.001000\n","Batch [150/1343] Loss: 1.9687 LR: 0.001000\n","Batch [200/1343] Loss: 2.1120 LR: 0.001000\n","Batch [250/1343] Loss: 2.1864 LR: 0.001000\n","Batch [300/1343] Loss: 1.5011 LR: 0.001000\n","Batch [350/1343] Loss: 1.8827 LR: 0.001000\n","Batch [400/1343] Loss: 2.1248 LR: 0.001000\n","Batch [450/1343] Loss: 1.7389 LR: 0.001000\n","Batch [500/1343] Loss: 1.9120 LR: 0.001000\n","Batch [550/1343] Loss: 1.6795 LR: 0.001000\n","Batch [600/1343] Loss: 1.9914 LR: 0.001000\n","Batch [650/1343] Loss: 2.1140 LR: 0.001000\n","Batch [700/1343] Loss: 1.7452 LR: 0.001000\n","Batch [750/1343] Loss: 1.8394 LR: 0.001000\n","Batch [800/1343] Loss: 1.9824 LR: 0.001000\n","Batch [850/1343] Loss: 1.6784 LR: 0.001000\n","Batch [900/1343] Loss: 1.9836 LR: 0.001000\n","Batch [950/1343] Loss: 1.9861 LR: 0.001000\n","Batch [1000/1343] Loss: 2.6532 LR: 0.001000\n","Batch [1050/1343] Loss: 2.1796 LR: 0.001000\n","Batch [1100/1343] Loss: 2.2779 LR: 0.001000\n","Batch [1150/1343] Loss: 1.4879 LR: 0.001000\n","Batch [1200/1343] Loss: 2.2605 LR: 0.001000\n","Batch [1250/1343] Loss: 1.8557 LR: 0.001000\n","Batch [1300/1343] Loss: 1.7049 LR: 0.001000\n","\n","Epoch [10/50] Loss: 1.8689 Time: 302.4s\n","💾 Best model saved (loss: 1.8689)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.249s, Loss: 1.8657\n","Batch [0/1343] Loss: 1.8657 LR: 0.001000\n","   Batch 1: 0.192s, Loss: 1.5856\n","   Batch 2: 0.193s, Loss: 1.8600\n","   Batch 3: 0.197s, Loss: 1.8107\n","   Batch 4: 0.209s, Loss: 1.9088\n","Batch [50/1343] Loss: 1.2833 LR: 0.001000\n","Batch [100/1343] Loss: 1.8292 LR: 0.001000\n","Batch [150/1343] Loss: 1.7846 LR: 0.001000\n","Batch [200/1343] Loss: 1.7777 LR: 0.001000\n","Batch [250/1343] Loss: 1.5721 LR: 0.001000\n","Batch [300/1343] Loss: 1.5514 LR: 0.001000\n","Batch [350/1343] Loss: 1.5587 LR: 0.001000\n","Batch [400/1343] Loss: 1.5454 LR: 0.001000\n","Batch [450/1343] Loss: 1.4157 LR: 0.001000\n","Batch [500/1343] Loss: 1.6664 LR: 0.001000\n","Batch [550/1343] Loss: 1.9756 LR: 0.001000\n","Batch [600/1343] Loss: 1.7017 LR: 0.001000\n","Batch [650/1343] Loss: 1.9481 LR: 0.001000\n","Batch [700/1343] Loss: 1.6357 LR: 0.001000\n","Batch [750/1343] Loss: 1.8900 LR: 0.001000\n","Batch [800/1343] Loss: 1.6241 LR: 0.001000\n","Batch [850/1343] Loss: 2.3513 LR: 0.001000\n","Batch [900/1343] Loss: 2.1145 LR: 0.001000\n","Batch [950/1343] Loss: 1.5749 LR: 0.001000\n","Batch [1000/1343] Loss: 1.8748 LR: 0.001000\n","Batch [1050/1343] Loss: 1.5450 LR: 0.001000\n","Batch [1100/1343] Loss: 1.6113 LR: 0.001000\n","Batch [1150/1343] Loss: 1.9197 LR: 0.001000\n","Batch [1200/1343] Loss: 2.0165 LR: 0.001000\n","Batch [1250/1343] Loss: 1.7649 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5140 LR: 0.001000\n","\n","Epoch [11/50] Loss: 1.7423 Time: 301.5s\n","💾 Best model saved (loss: 1.7423)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.251s, Loss: 1.9975\n","Batch [0/1343] Loss: 1.9975 LR: 0.001000\n","   Batch 1: 0.216s, Loss: 1.5448\n","   Batch 2: 0.245s, Loss: 1.4775\n","   Batch 3: 0.234s, Loss: 1.5292\n","   Batch 4: 0.216s, Loss: 1.3280\n","Batch [50/1343] Loss: 1.3909 LR: 0.001000\n","Batch [100/1343] Loss: 1.7331 LR: 0.001000\n","Batch [150/1343] Loss: 1.1917 LR: 0.001000\n","Batch [200/1343] Loss: 1.5879 LR: 0.001000\n","Batch [250/1343] Loss: 1.3500 LR: 0.001000\n","Batch [300/1343] Loss: 1.6272 LR: 0.001000\n","Batch [350/1343] Loss: 1.7820 LR: 0.001000\n","Batch [400/1343] Loss: 1.3992 LR: 0.001000\n","Batch [450/1343] Loss: 1.5452 LR: 0.001000\n","Batch [500/1343] Loss: 2.0544 LR: 0.001000\n","Batch [550/1343] Loss: 1.5598 LR: 0.001000\n","Batch [600/1343] Loss: 1.8426 LR: 0.001000\n","Batch [650/1343] Loss: 2.0027 LR: 0.001000\n","Batch [700/1343] Loss: 1.9135 LR: 0.001000\n","Batch [750/1343] Loss: 1.6996 LR: 0.001000\n","Batch [800/1343] Loss: 1.4330 LR: 0.001000\n","Batch [850/1343] Loss: 1.8382 LR: 0.001000\n","Batch [900/1343] Loss: 1.4750 LR: 0.001000\n","Batch [950/1343] Loss: 1.3357 LR: 0.001000\n","Batch [1000/1343] Loss: 1.6928 LR: 0.001000\n","Batch [1050/1343] Loss: 1.2322 LR: 0.001000\n","Batch [1100/1343] Loss: 1.6183 LR: 0.001000\n","Batch [1150/1343] Loss: 1.3624 LR: 0.001000\n","Batch [1200/1343] Loss: 1.3928 LR: 0.001000\n","Batch [1250/1343] Loss: 1.9815 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5017 LR: 0.001000\n","\n","Epoch [12/50] Loss: 1.6329 Time: 301.8s\n","💾 Best model saved (loss: 1.6329)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.238s, Loss: 1.5200\n","Batch [0/1343] Loss: 1.5200 LR: 0.001000\n","   Batch 1: 0.253s, Loss: 1.3878\n","   Batch 2: 0.248s, Loss: 1.3461\n","   Batch 3: 0.183s, Loss: 1.1810\n","   Batch 4: 0.194s, Loss: 1.2639\n","Batch [50/1343] Loss: 1.3793 LR: 0.001000\n","Batch [100/1343] Loss: 1.5016 LR: 0.001000\n","Batch [150/1343] Loss: 1.6415 LR: 0.001000\n","Batch [200/1343] Loss: 1.3131 LR: 0.001000\n","Batch [250/1343] Loss: 1.6229 LR: 0.001000\n","Batch [300/1343] Loss: 1.3146 LR: 0.001000\n","Batch [350/1343] Loss: 1.5285 LR: 0.001000\n","Batch [400/1343] Loss: 1.8082 LR: 0.001000\n","Batch [450/1343] Loss: 1.8754 LR: 0.001000\n","Batch [500/1343] Loss: 1.6573 LR: 0.001000\n","Batch [550/1343] Loss: 1.6288 LR: 0.001000\n","Batch [600/1343] Loss: 1.3305 LR: 0.001000\n","Batch [650/1343] Loss: 1.4955 LR: 0.001000\n","Batch [700/1343] Loss: 1.4737 LR: 0.001000\n","Batch [750/1343] Loss: 1.5219 LR: 0.001000\n","Batch [800/1343] Loss: 1.9615 LR: 0.001000\n","Batch [850/1343] Loss: 1.5993 LR: 0.001000\n","Batch [900/1343] Loss: 2.1455 LR: 0.001000\n","Batch [950/1343] Loss: 1.5833 LR: 0.001000\n","Batch [1000/1343] Loss: 1.2576 LR: 0.001000\n","Batch [1050/1343] Loss: 1.5556 LR: 0.001000\n","Batch [1100/1343] Loss: 1.4933 LR: 0.001000\n","Batch [1150/1343] Loss: 1.2940 LR: 0.001000\n","Batch [1200/1343] Loss: 1.8127 LR: 0.001000\n","Batch [1250/1343] Loss: 1.7018 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5301 LR: 0.001000\n","\n","Epoch [13/50] Loss: 1.5449 Time: 300.9s\n","💾 Best model saved (loss: 1.5449)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.403s, Loss: 1.2340\n","Batch [0/1343] Loss: 1.2340 LR: 0.001000\n","   Batch 1: 0.191s, Loss: 1.1245\n","   Batch 2: 0.373s, Loss: 1.3764\n","   Batch 3: 0.323s, Loss: 1.3998\n","   Batch 4: 0.249s, Loss: 1.8432\n","Batch [50/1343] Loss: 1.3584 LR: 0.001000\n","Batch [100/1343] Loss: 1.5065 LR: 0.001000\n","Batch [150/1343] Loss: 1.4765 LR: 0.001000\n","Batch [200/1343] Loss: 1.4319 LR: 0.001000\n","Batch [250/1343] Loss: 1.3400 LR: 0.001000\n","Batch [300/1343] Loss: 1.9268 LR: 0.001000\n","Batch [350/1343] Loss: 1.3987 LR: 0.001000\n","Batch [400/1343] Loss: 1.3563 LR: 0.001000\n","Batch [450/1343] Loss: 1.4966 LR: 0.001000\n","Batch [500/1343] Loss: 1.5843 LR: 0.001000\n","Batch [550/1343] Loss: 1.6621 LR: 0.001000\n","Batch [600/1343] Loss: 1.3183 LR: 0.001000\n","Batch [650/1343] Loss: 1.3299 LR: 0.001000\n","Batch [700/1343] Loss: 1.5271 LR: 0.001000\n","Batch [750/1343] Loss: 1.6856 LR: 0.001000\n","Batch [800/1343] Loss: 1.7594 LR: 0.001000\n","Batch [850/1343] Loss: 1.7672 LR: 0.001000\n","Batch [900/1343] Loss: 1.4537 LR: 0.001000\n","Batch [950/1343] Loss: 1.5746 LR: 0.001000\n","Batch [1000/1343] Loss: 1.2920 LR: 0.001000\n","Batch [1050/1343] Loss: 1.7158 LR: 0.001000\n","Batch [1100/1343] Loss: 1.3135 LR: 0.001000\n","Batch [1150/1343] Loss: 1.7188 LR: 0.001000\n","Batch [1200/1343] Loss: 1.3437 LR: 0.001000\n","Batch [1250/1343] Loss: 1.6682 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5204 LR: 0.001000\n","\n","Epoch [14/50] Loss: 1.4657 Time: 302.0s\n","💾 Best model saved (loss: 1.4657)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.215s, Loss: 1.1884\n","Batch [0/1343] Loss: 1.1884 LR: 0.001000\n","   Batch 1: 0.236s, Loss: 0.9618\n","   Batch 2: 0.237s, Loss: 1.6018\n","   Batch 3: 0.268s, Loss: 1.2496\n","   Batch 4: 0.258s, Loss: 1.4526\n","Batch [50/1343] Loss: 1.4803 LR: 0.001000\n","Batch [100/1343] Loss: 1.4015 LR: 0.001000\n","Batch [150/1343] Loss: 1.1174 LR: 0.001000\n","Batch [200/1343] Loss: 1.4465 LR: 0.001000\n","Batch [250/1343] Loss: 1.3748 LR: 0.001000\n","Batch [300/1343] Loss: 1.2258 LR: 0.001000\n","Batch [350/1343] Loss: 1.3010 LR: 0.001000\n","Batch [400/1343] Loss: 1.5482 LR: 0.001000\n","Batch [450/1343] Loss: 1.1941 LR: 0.001000\n","Batch [500/1343] Loss: 1.7655 LR: 0.001000\n","Batch [550/1343] Loss: 1.4100 LR: 0.001000\n","Batch [600/1343] Loss: 1.5256 LR: 0.001000\n","Batch [650/1343] Loss: 1.6417 LR: 0.001000\n","Batch [700/1343] Loss: 1.5827 LR: 0.001000\n","Batch [750/1343] Loss: 1.4314 LR: 0.001000\n","Batch [800/1343] Loss: 1.7535 LR: 0.001000\n","Batch [850/1343] Loss: 1.5279 LR: 0.001000\n","Batch [900/1343] Loss: 1.2798 LR: 0.001000\n","Batch [950/1343] Loss: 1.6130 LR: 0.001000\n","Batch [1000/1343] Loss: 1.4498 LR: 0.001000\n","Batch [1050/1343] Loss: 1.1306 LR: 0.001000\n","Batch [1100/1343] Loss: 1.2567 LR: 0.001000\n","Batch [1150/1343] Loss: 1.1222 LR: 0.001000\n","Batch [1200/1343] Loss: 1.3609 LR: 0.001000\n","Batch [1250/1343] Loss: 1.4134 LR: 0.001000\n","Batch [1300/1343] Loss: 1.2548 LR: 0.001000\n","\n","Epoch [15/50] Loss: 1.4011 Time: 301.6s\n","💾 Best model saved (loss: 1.4011)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.202s, Loss: 1.4711\n","Batch [0/1343] Loss: 1.4711 LR: 0.001000\n","   Batch 1: 0.180s, Loss: 1.0791\n","   Batch 2: 0.203s, Loss: 1.4110\n","   Batch 3: 0.221s, Loss: 1.1427\n","   Batch 4: 0.200s, Loss: 1.0246\n","Batch [50/1343] Loss: 1.1167 LR: 0.001000\n","Batch [100/1343] Loss: 1.5641 LR: 0.001000\n","Batch [150/1343] Loss: 1.4057 LR: 0.001000\n","Batch [200/1343] Loss: 1.3854 LR: 0.001000\n","Batch [250/1343] Loss: 1.2025 LR: 0.001000\n","Batch [300/1343] Loss: 1.1534 LR: 0.001000\n","Batch [350/1343] Loss: 1.2874 LR: 0.001000\n","Batch [400/1343] Loss: 1.5636 LR: 0.001000\n","Batch [450/1343] Loss: 1.2874 LR: 0.001000\n","Batch [500/1343] Loss: 1.2033 LR: 0.001000\n","Batch [550/1343] Loss: 1.2496 LR: 0.001000\n","Batch [600/1343] Loss: 2.0250 LR: 0.001000\n","Batch [650/1343] Loss: 1.4892 LR: 0.001000\n","Batch [700/1343] Loss: 1.3711 LR: 0.001000\n","Batch [750/1343] Loss: 1.3226 LR: 0.001000\n","Batch [800/1343] Loss: 1.1072 LR: 0.001000\n","Batch [850/1343] Loss: 1.1609 LR: 0.001000\n","Batch [900/1343] Loss: 1.3025 LR: 0.001000\n","Batch [950/1343] Loss: 1.2897 LR: 0.001000\n","Batch [1000/1343] Loss: 1.3019 LR: 0.001000\n","Batch [1050/1343] Loss: 1.3150 LR: 0.001000\n","Batch [1100/1343] Loss: 1.5802 LR: 0.001000\n","Batch [1150/1343] Loss: 1.4048 LR: 0.001000\n","Batch [1200/1343] Loss: 1.4733 LR: 0.001000\n","Batch [1250/1343] Loss: 1.4443 LR: 0.001000\n","Batch [1300/1343] Loss: 1.2702 LR: 0.001000\n","\n","Epoch [16/50] Loss: 1.3527 Time: 301.8s\n","💾 Best model saved (loss: 1.3527)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.178s, Loss: 1.3789\n","Batch [0/1343] Loss: 1.3789 LR: 0.001000\n","   Batch 1: 0.219s, Loss: 1.3939\n","   Batch 2: 0.164s, Loss: 0.9819\n","   Batch 3: 0.192s, Loss: 1.2602\n","   Batch 4: 0.179s, Loss: 1.2696\n","Batch [50/1343] Loss: 1.1520 LR: 0.001000\n","Batch [100/1343] Loss: 1.3851 LR: 0.001000\n","Batch [150/1343] Loss: 1.7204 LR: 0.001000\n","Batch [200/1343] Loss: 1.1377 LR: 0.001000\n","Batch [250/1343] Loss: 1.2693 LR: 0.001000\n","Batch [300/1343] Loss: 1.2587 LR: 0.001000\n","Batch [350/1343] Loss: 1.1894 LR: 0.001000\n","Batch [400/1343] Loss: 1.1890 LR: 0.001000\n","Batch [450/1343] Loss: 1.5056 LR: 0.001000\n","Batch [500/1343] Loss: 1.6208 LR: 0.001000\n","Batch [550/1343] Loss: 1.0805 LR: 0.001000\n","Batch [600/1343] Loss: 1.2670 LR: 0.001000\n","Batch [650/1343] Loss: 1.5585 LR: 0.001000\n","Batch [700/1343] Loss: 1.0077 LR: 0.001000\n","Batch [750/1343] Loss: 1.3919 LR: 0.001000\n","Batch [800/1343] Loss: 1.1414 LR: 0.001000\n","Batch [850/1343] Loss: 1.7541 LR: 0.001000\n","Batch [900/1343] Loss: 1.5279 LR: 0.001000\n","Batch [950/1343] Loss: 1.4480 LR: 0.001000\n","Batch [1000/1343] Loss: 1.1772 LR: 0.001000\n","Batch [1050/1343] Loss: 1.5075 LR: 0.001000\n","Batch [1100/1343] Loss: 1.5006 LR: 0.001000\n","Batch [1150/1343] Loss: 1.4111 LR: 0.001000\n","Batch [1200/1343] Loss: 1.4723 LR: 0.001000\n","Batch [1250/1343] Loss: 1.7316 LR: 0.001000\n","Batch [1300/1343] Loss: 1.6069 LR: 0.001000\n","\n","Epoch [17/50] Loss: 1.3030 Time: 301.0s\n","💾 Best model saved (loss: 1.3030)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.275s, Loss: 1.2752\n","Batch [0/1343] Loss: 1.2752 LR: 0.001000\n","   Batch 1: 0.193s, Loss: 1.2832\n","   Batch 2: 0.201s, Loss: 1.2927\n","   Batch 3: 0.204s, Loss: 1.2302\n","   Batch 4: 0.199s, Loss: 1.2978\n","Batch [50/1343] Loss: 1.6657 LR: 0.001000\n","Batch [100/1343] Loss: 0.8632 LR: 0.001000\n","Batch [150/1343] Loss: 1.1902 LR: 0.001000\n","Batch [200/1343] Loss: 1.5168 LR: 0.001000\n","Batch [250/1343] Loss: 1.0543 LR: 0.001000\n","Batch [300/1343] Loss: 1.4226 LR: 0.001000\n","Batch [350/1343] Loss: 1.0736 LR: 0.001000\n","Batch [400/1343] Loss: 1.2459 LR: 0.001000\n","Batch [450/1343] Loss: 1.1230 LR: 0.001000\n","Batch [500/1343] Loss: 1.2127 LR: 0.001000\n","Batch [550/1343] Loss: 1.2284 LR: 0.001000\n","Batch [600/1343] Loss: 0.9055 LR: 0.001000\n","Batch [650/1343] Loss: 1.1991 LR: 0.001000\n","Batch [700/1343] Loss: 1.1547 LR: 0.001000\n","Batch [750/1343] Loss: 1.2775 LR: 0.001000\n","Batch [800/1343] Loss: 1.3480 LR: 0.001000\n","Batch [850/1343] Loss: 1.1086 LR: 0.001000\n","Batch [900/1343] Loss: 1.1733 LR: 0.001000\n","Batch [950/1343] Loss: 1.2897 LR: 0.001000\n","Batch [1000/1343] Loss: 1.1830 LR: 0.001000\n","Batch [1050/1343] Loss: 1.3587 LR: 0.001000\n","Batch [1100/1343] Loss: 1.3097 LR: 0.001000\n","Batch [1150/1343] Loss: 1.3648 LR: 0.001000\n","Batch [1200/1343] Loss: 1.2837 LR: 0.001000\n","Batch [1250/1343] Loss: 1.3959 LR: 0.001000\n","Batch [1300/1343] Loss: 1.2828 LR: 0.001000\n","\n","Epoch [18/50] Loss: 1.2624 Time: 303.7s\n","💾 Best model saved (loss: 1.2624)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.253s, Loss: 1.4054\n","Batch [0/1343] Loss: 1.4054 LR: 0.001000\n","   Batch 1: 0.203s, Loss: 0.9959\n","   Batch 2: 0.262s, Loss: 1.3210\n","   Batch 3: 0.204s, Loss: 1.1312\n","   Batch 4: 0.209s, Loss: 1.5071\n","Batch [50/1343] Loss: 1.4815 LR: 0.001000\n","Batch [100/1343] Loss: 1.1888 LR: 0.001000\n","Batch [150/1343] Loss: 1.2216 LR: 0.001000\n","Batch [200/1343] Loss: 1.0520 LR: 0.001000\n","Batch [250/1343] Loss: 1.2733 LR: 0.001000\n","Batch [300/1343] Loss: 1.1141 LR: 0.001000\n","Batch [350/1343] Loss: 1.2768 LR: 0.001000\n","Batch [400/1343] Loss: 1.2631 LR: 0.001000\n","Batch [450/1343] Loss: 1.0277 LR: 0.001000\n","Batch [500/1343] Loss: 1.1610 LR: 0.001000\n","Batch [550/1343] Loss: 1.2788 LR: 0.001000\n","Batch [600/1343] Loss: 1.2387 LR: 0.001000\n","Batch [650/1343] Loss: 1.2617 LR: 0.001000\n","Batch [700/1343] Loss: 1.1992 LR: 0.001000\n","Batch [750/1343] Loss: 1.1885 LR: 0.001000\n","Batch [800/1343] Loss: 1.2997 LR: 0.001000\n","Batch [850/1343] Loss: 1.4162 LR: 0.001000\n","Batch [900/1343] Loss: 1.8148 LR: 0.001000\n","Batch [950/1343] Loss: 1.4052 LR: 0.001000\n","Batch [1000/1343] Loss: 1.1637 LR: 0.001000\n","Batch [1050/1343] Loss: 1.4068 LR: 0.001000\n","Batch [1100/1343] Loss: 1.3031 LR: 0.001000\n","Batch [1150/1343] Loss: 1.1817 LR: 0.001000\n","Batch [1200/1343] Loss: 1.3747 LR: 0.001000\n","Batch [1250/1343] Loss: 1.0168 LR: 0.001000\n","Batch [1300/1343] Loss: 1.3720 LR: 0.001000\n","\n","Epoch [19/50] Loss: 1.2309 Time: 302.2s\n","💾 Best model saved (loss: 1.2309)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.413s, Loss: 1.1101\n","Batch [0/1343] Loss: 1.1101 LR: 0.001000\n","   Batch 1: 0.334s, Loss: 1.3680\n","   Batch 2: 0.307s, Loss: 1.3946\n","   Batch 3: 0.221s, Loss: 1.3687\n","   Batch 4: 0.353s, Loss: 1.3553\n","Batch [50/1343] Loss: 1.0127 LR: 0.001000\n","Batch [100/1343] Loss: 1.3734 LR: 0.001000\n","Batch [150/1343] Loss: 0.8623 LR: 0.001000\n","Batch [200/1343] Loss: 1.1771 LR: 0.001000\n","Batch [250/1343] Loss: 0.9927 LR: 0.001000\n","Batch [300/1343] Loss: 1.6100 LR: 0.001000\n","Batch [350/1343] Loss: 1.3939 LR: 0.001000\n","Batch [400/1343] Loss: 1.4343 LR: 0.001000\n","Batch [450/1343] Loss: 1.0926 LR: 0.001000\n","Batch [500/1343] Loss: 1.3409 LR: 0.001000\n","Batch [550/1343] Loss: 1.0904 LR: 0.001000\n","Batch [600/1343] Loss: 1.3725 LR: 0.001000\n","Batch [650/1343] Loss: 1.3036 LR: 0.001000\n","Batch [700/1343] Loss: 1.0913 LR: 0.001000\n","Batch [750/1343] Loss: 1.1825 LR: 0.001000\n","Batch [800/1343] Loss: 1.6492 LR: 0.001000\n","Batch [850/1343] Loss: 1.1757 LR: 0.001000\n","Batch [900/1343] Loss: 1.2295 LR: 0.001000\n","Batch [950/1343] Loss: 1.2250 LR: 0.001000\n","Batch [1000/1343] Loss: 1.2031 LR: 0.001000\n","Batch [1050/1343] Loss: 1.1384 LR: 0.001000\n","Batch [1100/1343] Loss: 0.8934 LR: 0.001000\n","Batch [1150/1343] Loss: 1.0770 LR: 0.001000\n","Batch [1200/1343] Loss: 1.1811 LR: 0.001000\n","Batch [1250/1343] Loss: 0.9807 LR: 0.001000\n","Batch [1300/1343] Loss: 1.2393 LR: 0.001000\n","\n","Epoch [20/50] Loss: 1.2051 Time: 302.1s\n","💾 Best model saved (loss: 1.2051)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.245s, Loss: 0.8654\n","Batch [0/1343] Loss: 0.8654 LR: 0.001000\n","   Batch 1: 0.276s, Loss: 1.4614\n","   Batch 2: 0.215s, Loss: 1.0570\n","   Batch 3: 0.266s, Loss: 1.3111\n","   Batch 4: 0.264s, Loss: 1.6166\n","Batch [50/1343] Loss: 1.3670 LR: 0.001000\n","Batch [100/1343] Loss: 1.4168 LR: 0.001000\n","Batch [150/1343] Loss: 1.1738 LR: 0.001000\n","Batch [200/1343] Loss: 1.4615 LR: 0.001000\n","Batch [250/1343] Loss: 1.4771 LR: 0.001000\n","Batch [300/1343] Loss: 1.1874 LR: 0.001000\n","Batch [350/1343] Loss: 1.0051 LR: 0.001000\n","Batch [400/1343] Loss: 0.9893 LR: 0.001000\n","Batch [450/1343] Loss: 1.0875 LR: 0.001000\n","Batch [500/1343] Loss: 1.1793 LR: 0.001000\n","Batch [550/1343] Loss: 1.3582 LR: 0.001000\n","Batch [600/1343] Loss: 1.2287 LR: 0.001000\n","Batch [650/1343] Loss: 1.2028 LR: 0.001000\n","Batch [700/1343] Loss: 1.3870 LR: 0.001000\n","Batch [750/1343] Loss: 0.9489 LR: 0.001000\n","Batch [800/1343] Loss: 1.1218 LR: 0.001000\n","Batch [850/1343] Loss: 1.0998 LR: 0.001000\n","Batch [900/1343] Loss: 0.9556 LR: 0.001000\n","Batch [950/1343] Loss: 1.3023 LR: 0.001000\n","Batch [1000/1343] Loss: 1.1012 LR: 0.001000\n","Batch [1050/1343] Loss: 1.5425 LR: 0.001000\n","Batch [1100/1343] Loss: 1.3235 LR: 0.001000\n","Batch [1150/1343] Loss: 1.3379 LR: 0.001000\n","Batch [1200/1343] Loss: 1.1196 LR: 0.001000\n","Batch [1250/1343] Loss: 0.9013 LR: 0.001000\n","Batch [1300/1343] Loss: 1.5461 LR: 0.001000\n","\n","Epoch [21/50] Loss: 1.1791 Time: 303.1s\n","💾 Best model saved (loss: 1.1791)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.265s, Loss: 0.9786\n","Batch [0/1343] Loss: 0.9786 LR: 0.001000\n","   Batch 1: 0.195s, Loss: 1.0135\n","   Batch 2: 0.193s, Loss: 0.8778\n","   Batch 3: 0.230s, Loss: 1.3259\n","   Batch 4: 0.155s, Loss: 0.9795\n","Batch [50/1343] Loss: 1.0825 LR: 0.001000\n","Batch [100/1343] Loss: 1.1085 LR: 0.001000\n","Batch [150/1343] Loss: 1.2548 LR: 0.001000\n","Batch [200/1343] Loss: 1.1911 LR: 0.001000\n","Batch [250/1343] Loss: 1.1963 LR: 0.001000\n","Batch [300/1343] Loss: 1.1370 LR: 0.001000\n","Batch [350/1343] Loss: 0.8365 LR: 0.001000\n","Batch [400/1343] Loss: 1.1566 LR: 0.001000\n","Batch [450/1343] Loss: 0.8241 LR: 0.001000\n","Batch [500/1343] Loss: 1.4589 LR: 0.001000\n","Batch [550/1343] Loss: 1.4386 LR: 0.001000\n","Batch [600/1343] Loss: 0.9276 LR: 0.001000\n","Batch [650/1343] Loss: 1.0036 LR: 0.001000\n","Batch [700/1343] Loss: 1.5011 LR: 0.001000\n","Batch [750/1343] Loss: 1.2482 LR: 0.001000\n","Batch [800/1343] Loss: 1.0105 LR: 0.001000\n","Batch [850/1343] Loss: 0.9685 LR: 0.001000\n","Batch [900/1343] Loss: 0.8424 LR: 0.001000\n","Batch [950/1343] Loss: 1.5786 LR: 0.001000\n","Batch [1000/1343] Loss: 1.0378 LR: 0.001000\n","Batch [1050/1343] Loss: 0.8923 LR: 0.001000\n","Batch [1100/1343] Loss: 1.7239 LR: 0.001000\n","Batch [1150/1343] Loss: 1.2664 LR: 0.001000\n","Batch [1200/1343] Loss: 1.1171 LR: 0.001000\n","Batch [1250/1343] Loss: 0.9398 LR: 0.001000\n","Batch [1300/1343] Loss: 0.9338 LR: 0.001000\n","\n","Epoch [22/50] Loss: 1.1551 Time: 302.9s\n","💾 Best model saved (loss: 1.1551)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.234s, Loss: 1.0296\n","Batch [0/1343] Loss: 1.0296 LR: 0.001000\n","   Batch 1: 0.180s, Loss: 1.0375\n","   Batch 2: 0.218s, Loss: 0.8790\n","   Batch 3: 0.120s, Loss: 0.8297\n","   Batch 4: 0.198s, Loss: 1.4203\n","Batch [50/1343] Loss: 1.1216 LR: 0.001000\n","Batch [100/1343] Loss: 1.1189 LR: 0.001000\n","Batch [150/1343] Loss: 0.8262 LR: 0.001000\n","Batch [200/1343] Loss: 0.9250 LR: 0.001000\n","Batch [250/1343] Loss: 1.2952 LR: 0.001000\n","Batch [300/1343] Loss: 1.2009 LR: 0.001000\n","Batch [350/1343] Loss: 1.2705 LR: 0.001000\n","Batch [400/1343] Loss: 1.4956 LR: 0.001000\n","Batch [450/1343] Loss: 0.6332 LR: 0.001000\n","Batch [500/1343] Loss: 1.1768 LR: 0.001000\n","Batch [550/1343] Loss: 0.8999 LR: 0.001000\n","Batch [600/1343] Loss: 1.1886 LR: 0.001000\n","Batch [650/1343] Loss: 1.1628 LR: 0.001000\n","Batch [700/1343] Loss: 1.2559 LR: 0.001000\n","Batch [750/1343] Loss: 1.2740 LR: 0.001000\n","Batch [800/1343] Loss: 1.2197 LR: 0.001000\n","Batch [850/1343] Loss: 1.2926 LR: 0.001000\n","Batch [900/1343] Loss: 1.0862 LR: 0.001000\n","Batch [950/1343] Loss: 0.9546 LR: 0.001000\n","Batch [1000/1343] Loss: 1.3734 LR: 0.001000\n","Batch [1050/1343] Loss: 1.3192 LR: 0.001000\n","Batch [1100/1343] Loss: 0.9698 LR: 0.001000\n","Batch [1150/1343] Loss: 1.3325 LR: 0.001000\n","Batch [1200/1343] Loss: 0.8320 LR: 0.001000\n","Batch [1250/1343] Loss: 1.0422 LR: 0.001000\n","Batch [1300/1343] Loss: 1.0674 LR: 0.001000\n","\n","Epoch [23/50] Loss: 1.1344 Time: 303.1s\n","💾 Best model saved (loss: 1.1344)\n","   First batch data moved to GPU: images cuda:0, shape torch.Size([8, 1, 416, 416])\n","   First batch predictions: shape torch.Size([8, 169, 20]), device cuda:0\n","   Batch 0: 0.213s, Loss: 1.3623\n","Batch [0/1343] Loss: 1.3623 LR: 0.001000\n","   Batch 1: 0.247s, Loss: 0.9722\n","   Batch 2: 0.222s, Loss: 1.2816\n","   Batch 3: 0.302s, Loss: 1.0436\n","   Batch 4: 0.246s, Loss: 1.1848\n","Batch [50/1343] Loss: 1.2569 LR: 0.001000\n","Batch [100/1343] Loss: 1.0345 LR: 0.001000\n","Batch [150/1343] Loss: 1.0916 LR: 0.001000\n","Batch [200/1343] Loss: 1.2342 LR: 0.001000\n","Batch [250/1343] Loss: 0.8193 LR: 0.001000\n","Batch [300/1343] Loss: 1.0433 LR: 0.001000\n","Batch [350/1343] Loss: 1.1024 LR: 0.001000\n","Batch [400/1343] Loss: 1.0280 LR: 0.001000\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f04d0795aa12>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 上記の train_minimal.py の内容をコピペして保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# または直接実行：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36mtrain_one_epoch_optimized\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# cache this on the first invocation to avoid adding too much overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}