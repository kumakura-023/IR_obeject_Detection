# train_phase3_integrated.py - ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«YOLOçµ±åˆç‰ˆ
import torch
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import time
import os

from config import Config

# â˜…â˜…â˜… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–¢é€£ä¿®æ­£ â˜…â˜…â˜…
try:
    # æ”¹è‰¯ç‰ˆã‚’å„ªå…ˆ
    from improved_augmentation import ImprovedFLIRDataset, create_improved_dataloader
    USE_IMPROVED = True
    print("âœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from dataset import FLIRDataset, collate_fn
    USE_IMPROVED = False
    print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")

# â˜…â˜…â˜… Phase 3 æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from multiscale_model import MultiScaleYOLO
from advanced_losses import AdvancedMultiScaleLoss
from post_processing import AdvancedPostProcessor, SoftNMS
from diagnostic_training import DiagnosticTrainer

# â˜…â˜…â˜… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆå¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ â˜…â˜…â˜…
from model import SimpleYOLO
from loss import YOLOLoss

# â˜…â˜…â˜… å…±æœ‰VersionTrackerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from version_tracker import (
    create_version_tracker, 
    VersionTracker, 
    show_all_project_versions,
    debug_version_status,
    get_version_count
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
training_version = create_version_tracker("Training System v3.0 - Diagnostic Integrated", "train.py")
training_version.add_modification("è¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆ")
training_version.add_modification("æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ")
training_version.add_modification("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")

# ===== Phase 3: EMAã‚¯ãƒ©ã‚¹å®Ÿè£… =====
class EMAModel:
    """Exponential Moving Average for model parameters"""
    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self.register()

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}

# ===== ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é¸æŠé–¢æ•° =====
def create_model_and_loss(cfg):
    """Phase 3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é¸æŠ"""
    
    if getattr(cfg, 'use_multiscale_architecture', True):
        print("ğŸš€ Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
        try:
            # Step 1ã®ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆå®Ÿéš›ã«ã¯Step 1ã§ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
            anchors = {
                'small':  [(7, 11), (14, 28), (22, 65)],      # 52x52 grid
                'medium': [(42, 35), (76, 67), (46, 126)],    # 26x26 grid  
                'large':  [(127, 117), (88, 235), (231, 218)] # 13x13 grid
            }
            
            model = MultiScaleYOLO(num_classes=cfg.num_classes, anchors=anchors)
            criterion = AdvancedMultiScaleLoss(
                anchors=anchors, 
                num_classes=cfg.num_classes,
                use_ciou=getattr(cfg, 'use_ciou', True),
                use_focal=getattr(cfg, 'use_focal', True),
                use_label_smoothing=getattr(cfg, 'use_label_smoothing', False)
            )
            
            print(f"   âœ… MultiScaleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
            print(f"   âœ… AdvancedMultiScaleLoss: 3ã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œ")
            
            return model, criterion, "multiscale"
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
    model = SimpleYOLO(cfg.num_classes, use_phase2_enhancements=False)
    criterion = YOLOLoss(cfg.num_classes)
    
    print(f"   âœ… SimpleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
    print(f"   âœ… YOLOLoss: å˜ä¸€ã‚¹ã‚±ãƒ¼ãƒ«")
    
    return model, criterion, "fallback"

# ===== Phase 3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²é–¢æ•° =====
def create_train_val_split(dataset, val_split=0.15):
    """è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²"""
    total_size = len(dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size
    
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)  # å†ç¾æ€§ã®ãŸã‚
    )
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:")
    print(f"   Train: {train_size} images ({100*(1-val_split):.1f}%)")
    print(f"   Validation: {val_size} images ({100*val_split:.1f}%)")
    return train_dataset, val_dataset

# ===== Phase 3: æ¤œè¨¼é–¢æ•°ï¼ˆãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œï¼‰ =====
def validate_model(model, val_dataloader, criterion, device, architecture_type):
    """æ¤œè¨¼å®Ÿè¡Œï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•åˆ¤å®šï¼‰"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    with torch.no_grad():
        for images, targets in val_dataloader:
            images = images.to(device, non_blocking=True)
            
            if architecture_type == "multiscale":
                # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«: è¾æ›¸å½¢å¼ã®å‡ºåŠ›
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                # å¾“æ¥: ã‚¿ãƒ—ãƒ«å½¢å¼ã®å‡ºåŠ›
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    return avg_val_loss

def validate_model_with_postprocessing(model, val_dataloader, criterion, device, architecture_type, use_advanced_postprocessing=True):
    """å¾Œå‡¦ç†ã‚’å«ã‚€è©³ç´°æ¤œè¨¼"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    # å¾Œå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if use_advanced_postprocessing:
        post_processor = AdvancedPostProcessor(
            use_soft_nms=True,
            use_tta=False,      # æ¤œè¨¼æ™‚ã¯æ™‚é–“åŠ¹ç‡é‡è¦–
            use_multiscale=False,
            conf_threshold=0.25,  # æ”¹è‰¯è¨­å®š
            iou_threshold=0.5
        )
        
        detection_stats = {
            'total_detections': 0,
            'high_conf_detections': 0,  # conf > 0.7
            'processed_detections': 0
        }
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(val_dataloader):
            images = images.to(device, non_blocking=True)
            
            # é€šå¸¸ã®æå¤±è¨ˆç®—
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
            
            # å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼ï¼‰
            if use_advanced_postprocessing and batch_idx % 10 == 0:  # 10ãƒãƒƒãƒã«1å›
                try:
                    # 1æšç›®ã®ç”»åƒã§å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆ
                    single_image = images[0:1]
                    single_pred = {k: v[0:1] for k, v in predictions.items()} if isinstance(predictions, dict) else predictions[0:1]
                    
                    # å¾Œå‡¦ç†å®Ÿè¡Œ
                    processed_detections = post_processor.process_predictions(
                        model, single_image, single_pred
                    )
                    
                    # çµ±è¨ˆæ›´æ–°
                    detection_stats['total_detections'] += len(processed_detections)
                    high_conf = sum(1 for det in processed_detections if det['score'] > 0.7)
                    detection_stats['high_conf_detections'] += high_conf
                    detection_stats['processed_detections'] += 1
                    
                except Exception as e:
                    pass  # å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    
    # å¾Œå‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º
    if use_advanced_postprocessing and detection_stats['processed_detections'] > 0:
        avg_detections = detection_stats['total_detections'] / detection_stats['processed_detections']
        avg_high_conf = detection_stats['high_conf_detections'] / detection_stats['processed_detections']
        
        print(f"ğŸ“Š å¾Œå‡¦ç†çµ±è¨ˆ (ã‚µãƒ³ãƒ—ãƒ«{detection_stats['processed_detections']}æš):")
        print(f"   å¹³å‡æ¤œå‡ºæ•°: {avg_detections:.1f}/ç”»åƒ")
        print(f"   é«˜ä¿¡é ¼åº¦æ¤œå‡º: {avg_high_conf:.1f}/ç”»åƒ (conf>0.7)")
    
    return avg_val_loss

# ===== ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰ =====
def setup_dataloaders(cfg):
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ”¹è‰¯ç‰ˆå¯¾å¿œï¼‰"""
    
    if USE_IMPROVED:
        # æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ¨ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = ImprovedFLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size,
            use_improved_augment=True,
            mixup_in_dataset=False  # DataLoaderãƒ¬ãƒ™ãƒ«ã§å‡¦ç†
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # æ”¹è‰¯ç‰ˆDataLoader
        train_dataloader = create_improved_dataloader(
            train_dataset,
            batch_size=cfg.batch_size,
            use_mixup=getattr(cfg, 'use_mixup', True),
            shuffle=True,
            num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
            pin_memory=getattr(cfg, 'pin_memory', True),
            persistent_workers=False,  # â˜…â˜…â˜… ä¿®æ­£: True â†’ False (å®‰å®šæ€§å‘ä¸Š) â˜…â˜…â˜…
            prefetch_factor=2  # â˜…â˜…â˜… ä¿®æ­£: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤æ˜ç¤º â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = create_improved_dataloader(
                val_dataset,
                batch_size=cfg.batch_size,
                use_mixup=False,  # æ¤œè¨¼æ™‚ã¯MixUpãªã—
                shuffle=False,
                num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 â˜…â˜…â˜…
                pin_memory=getattr(cfg, 'pin_memory', True),
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    else:
        # æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = FLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size, 
            augment=getattr(cfg, 'augment', True)
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # DataLoaderä½œæˆ
        num_workers = 2  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
        pin_memory = getattr(cfg, 'pin_memory', True)
        
        train_dataloader = DataLoader(
            train_dataset,
            batch_size=cfg.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
            persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = DataLoader(
                val_dataset,
                batch_size=cfg.batch_size,
                shuffle=False,
                collate_fn=collate_fn,
                num_workers=num_workers,
                pin_memory=pin_memory,
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    print(f"   Train batches: {len(train_dataloader)}")
    if val_dataloader:
        print(f"   Validation batches: {len(val_dataloader)}")
    
    return train_dataloader, val_dataloader

# ===== Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­çµ±åˆç‰ˆï¼‰ =====
def phase3_integrated_training_loop(model, train_dataloader, val_dataloader, criterion, cfg, architecture_type):
    """Phase 3çµ±åˆå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆï¼‰"""
    
    # â˜…â˜…â˜… è¨ºæ–­æ©Ÿèƒ½åˆæœŸåŒ– â˜…â˜…â˜…
    diagnostics = DiagnosticTrainer(
        save_dir=os.path.join(cfg.save_dir, "diagnostics")
    )
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š
    if getattr(cfg, 'optimizer_type', 'AdamW') == "AdamW":
        optimizer = optim.AdamW(
            model.parameters(),
            lr=cfg.learning_rate,
            weight_decay=getattr(cfg, 'weight_decay', 2e-4),
            betas=getattr(cfg, 'betas', (0.9, 0.999)),
            eps=getattr(cfg, 'eps', 1e-8)
        )
    else:
        optimizer = optim.Adam(model.parameters(), lr=cfg.learning_rate)
    
    # EMAåˆæœŸåŒ–
    ema = None
    if getattr(cfg, 'use_ema', True):
        ema = EMAModel(model, decay=getattr(cfg, 'ema_decay', 0.9995))
        print(f"ğŸ”„ EMA initialized with decay {cfg.ema_decay}")
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¨­å®š
    scheduler = None
    if getattr(cfg, 'use_scheduler', True):
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=cfg.num_epochs,
            eta_min=getattr(cfg, 'min_lr', cfg.learning_rate / 250)
        )
    
    # Early Stoppingè¨­å®š
    best_val_loss = float('inf')
    patience_counter = 0
    
    # å­¦ç¿’çµ±è¨ˆ
    train_losses = []
    val_losses = []
    learning_rates = []
    
    print(f"ğŸš€ Phase 3çµ±åˆå­¦ç¿’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"   Architecture: {architecture_type}")
    print(f"   Optimizer: {getattr(cfg, 'optimizer_type', 'AdamW')}")
    print(f"   EMA: {'ON' if getattr(cfg, 'use_ema', True) else 'OFF'}")
    print(f"   Validation: {'ON' if val_dataloader else 'OFF'}")
    print(f"   Diagnostics: {diagnostics.save_dir}")
    
    for epoch in range(cfg.num_epochs):
        epoch_start = time.time()
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­é–‹å§‹ â˜…â˜…â˜…
        diagnostics.start_epoch_diagnosis(epoch + 1)
        
        # ===== ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‡¦ç† =====
        warmup_epochs = getattr(cfg, 'warmup_epochs', 0)
        if epoch < warmup_epochs:
            warmup_lr = cfg.learning_rate * (epoch + 1) / warmup_epochs
            for param_group in optimizer.param_groups:
                param_group['lr'] = warmup_lr
            print(f"ğŸ”¥ Warmup Epoch {epoch+1}: LR = {warmup_lr:.6f}")
        
        # ===== è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º =====
        model.train()
        epoch_loss = 0
        batch_count = 0
        
        # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            from progress import MultiScaleProgressTracker
            progress_tracker = MultiScaleProgressTracker(len(train_dataloader), print_interval=getattr(cfg, 'print_interval', 5))
            progress_tracker.start_epoch(epoch + 1, cfg.num_epochs)
            use_progress_tracker = True
        except ImportError:
            use_progress_tracker = False
            print_interval = getattr(cfg, 'print_interval', 5)
        
        for batch_idx, (images, targets) in enumerate(train_dataloader):
            images = images.to(cfg.device, non_blocking=True)
            
            # Forwardï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¥ï¼‰
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
                
                # â˜…â˜…â˜… è¨ºæ–­æƒ…å ±å–å¾— â˜…â˜…â˜…
                loss_components = None
                try:
                    # è©³ç´°æƒ…å ±ä»˜ãã§å†è¨ˆç®—ï¼ˆè¨ºæ–­ç”¨ï¼‰
                    if hasattr(criterion, 'return_components') and batch_idx % 20 == 0:
                        criterion.return_components = True
                        _, loss_components = criterion(predictions, targets)
                        criterion.return_components = False
                except:
                    pass  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡è¦–
                
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
                loss_components = None
            
            # â˜…â˜…â˜… ãƒãƒƒãƒè¨ºæ–­å®Ÿè¡Œ â˜…â˜…â˜…
            try:
                diagnostics.log_batch_diagnosis(
                    batch_idx, images, targets, predictions, loss_components
                )
            except Exception as e:
                if batch_idx % 50 == 0:  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æ¸›ã‚‰ã™
                    print(f"   âš ï¸ è¨ºæ–­ã‚¨ãƒ©ãƒ¼ (batch {batch_idx}): {e}")
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
            if hasattr(cfg, 'gradient_clip'):
                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.gradient_clip)
            
            optimizer.step()
            
            # EMAæ›´æ–°
            if ema:
                ema.update()
            
            epoch_loss += loss.item()
            batch_count += 1
            
            # é€²æ—è¡¨ç¤º
            current_lr = optimizer.param_groups[0]['lr']
            if use_progress_tracker:
                # è©³ç´°é€²æ—è¡¨ç¤º
                if architecture_type == "multiscale" and loss_components:
                    progress_tracker.update_batch_multiscale(
                        batch_idx, loss.item(), current_lr, loss_components
                    )
                else:
                    progress_tracker.update_batch(batch_idx, loss.item(), current_lr)
            else:
                # ç°¡æ˜“é€²æ—è¡¨ç¤º
                if batch_idx % print_interval == 0:
                    print(f"   Batch {batch_idx:4d}/{len(train_dataloader)}: Loss={loss.item():.4f}, LR={current_lr:.6f}")
        
        avg_train_loss = epoch_loss / batch_count
        
        # ===== æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º =====
        val_loss = float('inf')
        if val_dataloader and epoch % getattr(cfg, 'validate_every', 1) == 0:
            # EMAãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼
            if ema:
                ema.apply_shadow()
            
            # è©³ç´°æ¤œè¨¼ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã«1å›ï¼‰
            if epoch % 5 == 0 and getattr(cfg, 'use_advanced_postprocessing', True):
                print(f"ğŸ”§ å¾Œå‡¦ç†è¾¼ã¿è©³ç´°æ¤œè¨¼å®Ÿè¡Œä¸­...")
                val_loss = validate_model_with_postprocessing(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            else:
                # é€šå¸¸æ¤œè¨¼ï¼ˆè»½é‡ï¼‰
                val_loss = validate_model(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            
            if ema:
                ema.restore()
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
        if scheduler and epoch >= warmup_epochs:
            scheduler.step()
        
        epoch_time = time.time() - epoch_start
        current_lr = optimizer.param_groups[0]['lr']
        
        # çµ±è¨ˆè¨˜éŒ²
        train_losses.append(avg_train_loss)
        val_losses.append(val_loss)
        learning_rates.append(current_lr)
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­çµ‚äº† & æ”¹å–„ææ¡ˆ â˜…â˜…â˜…
        suggestions = diagnostics.end_epoch_diagnosis(epoch + 1, val_loss, model)
        
        # ãƒ­ã‚°è¡¨ç¤º
        val_str = f"Val: {val_loss:6.4f}" if val_loss != float('inf') else "Val: ----"
        print(f"\nğŸ“ˆ Epoch [{epoch+1:2d}/{cfg.num_epochs}] "
              f"Train: {avg_train_loss:6.4f} {val_str} "
              f"Time: {epoch_time:4.1f}s LR: {current_lr:.6f}")
        
        # æ”¹å–„ææ¡ˆè¡¨ç¤º
        if suggestions:
            print(f"ğŸ’¡ è¨ºæ–­ææ¡ˆ:")
            for suggestion in suggestions[:2]:  # ä¸Šä½2ä»¶ã®ã¿
                print(f"   {suggestion['type']}: {suggestion['suggestion']}")
        
        # GPUä½¿ç”¨é‡è¡¨ç¤ºï¼ˆæœ€åˆã®æ•°ã‚¨ãƒãƒƒã‚¯ï¼‰
        if cfg.device.type == 'cuda' and epoch < 3:
            memory_used = torch.cuda.memory_allocated(0) / 1024**3
            print(f"   GPU Memory: {memory_used:.2f}GB")
        
        # Early Stopping & Best Model Saving
        current_loss = val_loss if val_loss != float('inf') else avg_train_loss
        min_improvement = getattr(cfg, 'min_improvement', 0.005)
        
        if current_loss < best_val_loss - min_improvement:
            best_val_loss = current_loss
            patience_counter = 0
            
            # EMAãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            if ema:
                ema.apply_shadow()
            
            save_best_model_integrated(model, optimizer, ema, epoch, best_val_loss, cfg, architecture_type)
            
            if ema:
                ema.restore()
            
            print(f"ğŸ‰ New best loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            patience = getattr(cfg, 'patience', 10)
            print(f"â³ No improvement for {patience_counter}/{patience} epochs")
            
            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping triggered")
                break
        
        # å®šæœŸä¿å­˜
        save_interval = getattr(cfg, 'save_interval', 2)
        if (epoch + 1) % save_interval == 0:
            save_checkpoint_integrated(model, optimizer, epoch, avg_train_loss, cfg, architecture_type)
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if cfg.device.type == 'cuda':
            empty_cache_every = getattr(cfg, 'empty_cache_every_n_batch', 50)
            if (epoch + 1) % (empty_cache_every // 10) == 0:  # ã‚¨ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã§èª¿æ•´
                torch.cuda.empty_cache()
    
    # â˜…â˜…â˜… æœ€çµ‚è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
    diagnostics.generate_final_report()
    
    print(f"\nâœ… Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
    print(f"ğŸ† Best Loss: {best_val_loss:.4f}")
    
    return train_losses, val_losses, learning_rates, best_val_loss

# ===== çµ±åˆç‰ˆä¿å­˜é–¢æ•° =====
def save_best_model_integrated(model, optimizer, ema, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'ema_state_dict': ema.shadow if ema else None,
        'config': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'ema_decay': getattr(cfg, 'ema_decay', None),
            'validation_split': getattr(cfg, 'validation_split', 0.15),
            'use_multiscale': getattr(cfg, 'use_multiscale_architecture', True)
        },
        'training_stats': {
            'gpu_memory_peak': torch.cuda.max_memory_allocated(0) / 1024**3 if torch.cuda.is_available() else 0,
            'parameters': sum(p.numel() for p in model.parameters())
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'phase3_integrated_{architecture_type}_loss_{loss:.4f}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Phase 3 integrated model saved: {save_path}")

def save_checkpoint_integrated(model, optimizer, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'config_info': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'optimizer_type': getattr(cfg, 'optimizer_type', 'AdamW')
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'checkpoint_integrated_epoch_{epoch+1}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Checkpoint saved: {save_path}")

def plot_training_progress(losses, lrs, val_losses=None, save_path="training_progress_integrated.png"):
    """å­¦ç¿’é€²æ—ã‚’å¯è¦–åŒ–ï¼ˆçµ±åˆç‰ˆï¼‰"""
    try:
        import matplotlib.pyplot as plt
        
        if val_losses:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 4))
        else:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Training Loss plot
        ax1.plot(losses, 'b-', linewidth=2, label='Train Loss')
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax1.plot(valid_epochs, valid_val_losses, 'r-', linewidth=2, label='Val Loss')
        
        ax1.set_title('Phase 3 Integrated Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')
        if val_losses:
            ax1.legend()
        
        # Learning Rate plot
        ax2.plot(lrs, 'r-', linewidth=2)
        ax2.set_title('Learning Rate')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # Validation Loss separate plot
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax3.plot(valid_epochs, valid_val_losses, 'g-', linewidth=2)
                ax3.set_title('Validation Loss')
                ax3.set_xlabel('Epoch')
                ax3.set_ylabel('Val Loss')
                ax3.grid(True, alpha=0.3)
                ax3.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
        
        print(f"ğŸ“Š Training progress saved to {save_path}")
    except ImportError:
        print("âš ï¸ matplotlib not available - skipping visualization")
    except Exception as e:
        print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# ===== GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ =====
def comprehensive_gpu_check():
    """åŒ…æ‹¬çš„ãªGPUç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯")
    print("="*60)
    
    print(f"1. CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   GPU count: {torch.cuda.device_count()}")
        print(f"   Current device: {torch.cuda.current_device()}")
        print(f"   Device name: {torch.cuda.get_device_name(0)}")
        
        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
        memory_reserved = torch.cuda.memory_reserved(0) / 1024**3
        print(f"   GPU memory - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
    else:
        print("   âŒ CUDA not available!")
        return False
    
    print(f"2. PyTorch version: {torch.__version__}")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"3. Selected device: {device}")
    
    return True

# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====
def main():
    print("ğŸš€ Starting Phase 3 Integrated YOLO Training (Diagnostic Enhanced)")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª")
    print("="*80)
    VersionTracker.print_all_versions()

    # è¨­å®šã¨GPUç¢ºèª
    cfg = Config()
    os.makedirs(cfg.save_dir, exist_ok=True)
    
    # è¨ºæ–­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    diagnostic_dir = os.path.join(cfg.save_dir, "diagnostics")
    os.makedirs(diagnostic_dir, exist_ok=True)
    
    # GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯
    if not comprehensive_gpu_check():
        print("âŒ GPUä½¿ç”¨ä¸å¯ - CPUå­¦ç¿’ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        cfg.device = torch.device('cpu')
        cfg.batch_size = max(cfg.batch_size // 4, 1)
        print(f"   CPUç”¨ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {cfg.batch_size} ã«èª¿æ•´")
    
    print(f"\nğŸ“‹ å­¦ç¿’è¨­å®š:")
    print(f"   Device: {cfg.device}")
    print(f"   Batch size: {cfg.batch_size}")
    print(f"   Image size: {cfg.img_size}")
    print(f"   Classes: {cfg.num_classes}")
    print(f"   Learning rate: {cfg.learning_rate:.0e}")
    print(f"   EMA: {getattr(cfg, 'use_ema', True)}")
    print(f"   Validation Split: {getattr(cfg, 'validation_split', 0.15)}")
    print(f"   Diagnostics: ON")
    
    # Phase 3çµ±åˆ: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ & æ¤œè¨¼åˆ†å‰²
    print("\nğŸ“Š Loading dataset with validation split...")
    try:
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
        
        print(f"   Total train batches: {len(train_dataloader)}")
        if val_dataloader:
            print(f"   Total validation batches: {len(val_dataloader)}")
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒªãƒˆãƒ©ã‚¤ä¸­...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        global USE_IMPROVED
        USE_IMPROVED = False
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
    
    # Phase 3çµ±åˆ: ãƒ¢ãƒ‡ãƒ«&æå¤±é–¢æ•°ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•é¸æŠï¼‰
    print("\nğŸ¤– Creating Phase 3 integrated model...")
    model, criterion, architecture_type = create_model_and_loss(cfg)
    
    # GPUã«ç§»å‹•
    print(f"   Moving model to {cfg.device}...")
    model = model.to(cfg.device)
    
    if cfg.device.type == 'cuda':
        model = model.float()
    
    print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    model_device = next(model.parameters()).device
    print(f"   Model device confirmed: {model_device}")
    
    # Phase 3çµ±åˆå­¦ç¿’å®Ÿè¡Œ
    print("\nğŸš€ Phase 3çµ±åˆå­¦ç¿’ã‚’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"ğŸ¯ ç›®æ¨™: Val Loss 43.45 â†’ 25-30")
    
    try:
        train_losses, val_losses, lrs, best_loss = phase3_integrated_training_loop(
            model, train_dataloader, val_dataloader, criterion, cfg, architecture_type
        )
        
        # çµæœå¯è¦–åŒ–
        try:
            plot_training_progress(train_losses, lrs, val_losses)
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\nğŸ¯ Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
        print(f"ğŸ† Best Loss: {best_loss:.4f}")
        print(f"ğŸ”§ Architecture: {architecture_type}")
        
        # ç›®æ¨™é”æˆåˆ¤å®š
        print(f"\nğŸ“Š ç›®æ¨™é”æˆåˆ¤å®š:")
        if best_loss < 30.0:
            print("ğŸ‰ Step 1ç›®æ¨™é”æˆ! (Val Loss < 30.0)")
            if best_loss < 20.0:
                print("ğŸ† äºˆæƒ³ã‚’ä¸Šå›ã‚‹æˆæœ! (Val Loss < 20.0)")
        elif best_loss < 35.0:
            print("ğŸŸ¡ éƒ¨åˆ†çš„æ”¹å–„ (Val Loss < 35.0) - ç¶™ç¶šæ¨å¥¨")
        else:
            print("ğŸ”´ ç›®æ¨™æœªé”æˆ - æ–¹é‡è»¢æ›æ¤œè¨")
            print("   æ¨å¥¨: å­¦ç¿’ç‡ã‚’ã•ã‚‰ã«2å€ã€ã¾ãŸã¯ã‚¢ãƒ³ã‚«ãƒ¼è¦‹ç›´ã—")
        
        # å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
        improvement_ratio = 43.45 / best_loss if best_loss > 0 else 1
        print(f"\nğŸ’¡ æ”¹å–„çµæœ:")
        print(f"   æ”¹å–„ç‡: {improvement_ratio:.1f}x (43.45 â†’ {best_loss:.4f})")
        print(f"   æ¬¡ç›®æ¨™: Val Loss < {best_loss * 0.7:.1f}")
        
        if best_loss > 35.0:
            print(f"\nğŸš¨ ç·Šæ€¥æ”¹å–„æ¡ˆ:")
            print(f"   1. å­¦ç¿’ç‡ã‚’2å€ã« ({cfg.learning_rate:.0e} â†’ {cfg.learning_rate*2:.0e})")
            print(f"   2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã« ({cfg.batch_size} â†’ {cfg.batch_size//2})")
            print(f"   3. ã‚¢ãƒ³ã‚«ãƒ¼ã‚µã‚¤ã‚ºã®å…¨é¢è¦‹ç›´ã—")
        
    except Exception as e:
        print(f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nâœ… Training completed!")
    
    # æœ€çµ‚çµ±è¨ˆ
    if cfg.device.type == 'cuda':
        final_memory = torch.cuda.memory_allocated(0) / 1024**3
        max_memory = torch.cuda.max_memory_allocated(0) / 1024**3
        print(f"ğŸ“Š æœ€çµ‚GPUçµ±è¨ˆ:")
        print(f"   ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory:.2f}GB")
        print(f"   æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {max_memory:.2f}GB")
    
    # å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ¯ å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   Architecture: {architecture_type}")
    print(f"   æœ€çµ‚Loss: {best_loss:.4f}")
    print(f"   æ”¹è‰¯æ‹¡å¼µ: {'ON' if USE_IMPROVED else 'OFF'}")
    print(f"   è¨ºæ–­æ©Ÿèƒ½: ON")
    print(f"   EMAä½¿ç”¨: {'Yes' if getattr(cfg, 'use_ema', True) else 'No'}")
    print(f"   æ¤œè¨¼åˆ†å‰²: {'Yes' if getattr(cfg, 'validation_split', 0.15) > 0 else 'No'}")
    print(f"   ä¿å­˜å…ˆ: {cfg.save_dir}")
    print(f"   è¨ºæ–­ãƒ­ã‚°: {diagnostic_dir}")

if __name__ == "__main__":
    main()# train_phase3_integrated.py - ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«YOLOçµ±åˆç‰ˆ
import torch
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import time
import os

from config import Config

# â˜…â˜…â˜… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–¢é€£ä¿®æ­£ â˜…â˜…â˜…
try:
    # æ”¹è‰¯ç‰ˆã‚’å„ªå…ˆ
    from improved_augmentation import ImprovedFLIRDataset, create_improved_dataloader
    USE_IMPROVED = True
    print("âœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from dataset import FLIRDataset, collate_fn
    USE_IMPROVED = False
    print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")

# â˜…â˜…â˜… Phase 3 æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from multiscale_model import MultiScaleYOLO
from advanced_losses import AdvancedMultiScaleLoss
from post_processing import AdvancedPostProcessor, SoftNMS
from diagnostic_training import DiagnosticTrainer

# â˜…â˜…â˜… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆå¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ â˜…â˜…â˜…
from model import SimpleYOLO
from loss import YOLOLoss

# â˜…â˜…â˜… å…±æœ‰VersionTrackerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from version_tracker import (
    create_version_tracker, 
    VersionTracker, 
    show_all_project_versions,
    debug_version_status,
    get_version_count
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
training_version = create_version_tracker("Training System v3.0 - Diagnostic Integrated", "train.py")
training_version.add_modification("è¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆ")
training_version.add_modification("æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ")
training_version.add_modification("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")

# ===== Phase 3: EMAã‚¯ãƒ©ã‚¹å®Ÿè£… =====
class EMAModel:
    """Exponential Moving Average for model parameters"""
    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self.register()

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}

# ===== ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é¸æŠé–¢æ•° =====
def create_model_and_loss(cfg):
    """Phase 3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é¸æŠ"""
    
    if getattr(cfg, 'use_multiscale_architecture', True):
        print("ğŸš€ Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
        try:
            # Step 1ã®ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆå®Ÿéš›ã«ã¯Step 1ã§ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
            anchors = {
                'small':  [(7, 11), (14, 28), (22, 65)],      # 52x52 grid
                'medium': [(42, 35), (76, 67), (46, 126)],    # 26x26 grid  
                'large':  [(127, 117), (88, 235), (231, 218)] # 13x13 grid
            }
            
            model = MultiScaleYOLO(num_classes=cfg.num_classes, anchors=anchors)
            criterion = AdvancedMultiScaleLoss(
                anchors=anchors, 
                num_classes=cfg.num_classes,
                use_ciou=getattr(cfg, 'use_ciou', True),
                use_focal=getattr(cfg, 'use_focal', True),
                use_label_smoothing=getattr(cfg, 'use_label_smoothing', False)
            )
            
            print(f"   âœ… MultiScaleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
            print(f"   âœ… AdvancedMultiScaleLoss: 3ã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œ")
            
            return model, criterion, "multiscale"
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
    model = SimpleYOLO(cfg.num_classes, use_phase2_enhancements=False) 
    criterion = YOLOLoss(cfg.num_classes)
    
    print(f"   âœ… SimpleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
    print(f"   âœ… YOLOLoss: å˜ä¸€ã‚¹ã‚±ãƒ¼ãƒ«")
    
    return model, criterion, "fallback"

# ===== Phase 3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²é–¢æ•° =====
def create_train_val_split(dataset, val_split=0.15):
    """è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²"""
    total_size = len(dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size
    
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)  # å†ç¾æ€§ã®ãŸã‚
    )
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:")
    print(f"   Train: {train_size} images ({100*(1-val_split):.1f}%)")
    print(f"   Validation: {val_size} images ({100*val_split:.1f}%)")
    return train_dataset, val_dataset

# ===== Phase 3: æ¤œè¨¼é–¢æ•°ï¼ˆãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œï¼‰ =====
def validate_model(model, val_dataloader, criterion, device, architecture_type):
    """æ¤œè¨¼å®Ÿè¡Œï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•åˆ¤å®šï¼‰"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    with torch.no_grad():
        for images, targets in val_dataloader:
            images = images.to(device, non_blocking=True)
            
            if architecture_type == "multiscale":
                # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«: è¾æ›¸å½¢å¼ã®å‡ºåŠ›
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                # å¾“æ¥: ã‚¿ãƒ—ãƒ«å½¢å¼ã®å‡ºåŠ›
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    return avg_val_loss

def validate_model_with_postprocessing(model, val_dataloader, criterion, device, architecture_type, use_advanced_postprocessing=True):
    """å¾Œå‡¦ç†ã‚’å«ã‚€è©³ç´°æ¤œè¨¼"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    # å¾Œå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if use_advanced_postprocessing:
        post_processor = AdvancedPostProcessor(
            use_soft_nms=True,
            use_tta=False,      # æ¤œè¨¼æ™‚ã¯æ™‚é–“åŠ¹ç‡é‡è¦–
            use_multiscale=False,
            conf_threshold=0.25,  # æ”¹è‰¯è¨­å®š
            iou_threshold=0.5
        )
        
        detection_stats = {
            'total_detections': 0,
            'high_conf_detections': 0,  # conf > 0.7
            'processed_detections': 0
        }
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(val_dataloader):
            images = images.to(device, non_blocking=True)
            
            # é€šå¸¸ã®æå¤±è¨ˆç®—
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
            
            # å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼ï¼‰
            if use_advanced_postprocessing and batch_idx % 10 == 0:  # 10ãƒãƒƒãƒã«1å›
                try:
                    # 1æšç›®ã®ç”»åƒã§å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆ
                    single_image = images[0:1]
                    single_pred = {k: v[0:1] for k, v in predictions.items()} if isinstance(predictions, dict) else predictions[0:1]
                    
                    # å¾Œå‡¦ç†å®Ÿè¡Œ
                    processed_detections = post_processor.process_predictions(
                        model, single_image, single_pred
                    )
                    
                    # çµ±è¨ˆæ›´æ–°
                    detection_stats['total_detections'] += len(processed_detections)
                    high_conf = sum(1 for det in processed_detections if det['score'] > 0.7)
                    detection_stats['high_conf_detections'] += high_conf
                    detection_stats['processed_detections'] += 1
                    
                except Exception as e:
                    pass  # å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    
    # å¾Œå‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º
    if use_advanced_postprocessing and detection_stats['processed_detections'] > 0:
        avg_detections = detection_stats['total_detections'] / detection_stats['processed_detections']
        avg_high_conf = detection_stats['high_conf_detections'] / detection_stats['processed_detections']
        
        print(f"ğŸ“Š å¾Œå‡¦ç†çµ±è¨ˆ (ã‚µãƒ³ãƒ—ãƒ«{detection_stats['processed_detections']}æš):")
        print(f"   å¹³å‡æ¤œå‡ºæ•°: {avg_detections:.1f}/ç”»åƒ")
        print(f"   é«˜ä¿¡é ¼åº¦æ¤œå‡º: {avg_high_conf:.1f}/ç”»åƒ (conf>0.7)")
    
    return avg_val_loss

# ===== ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰ =====
def setup_dataloaders(cfg):
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ”¹è‰¯ç‰ˆå¯¾å¿œï¼‰"""
    
    if USE_IMPROVED:
        # æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ¨ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = ImprovedFLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size,
            use_improved_augment=True,
            mixup_in_dataset=False  # DataLoaderãƒ¬ãƒ™ãƒ«ã§å‡¦ç†
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # æ”¹è‰¯ç‰ˆDataLoader
        train_dataloader = create_improved_dataloader(
            train_dataset,
            batch_size=cfg.batch_size,
            use_mixup=getattr(cfg, 'use_mixup', True),
            shuffle=True,
            num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
            pin_memory=getattr(cfg, 'pin_memory', True),
            persistent_workers=False,  # â˜…â˜…â˜… ä¿®æ­£: True â†’ False (å®‰å®šæ€§å‘ä¸Š) â˜…â˜…â˜…
            prefetch_factor=2  # â˜…â˜…â˜… ä¿®æ­£: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤æ˜ç¤º â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = create_improved_dataloader(
                val_dataset,
                batch_size=cfg.batch_size,
                use_mixup=False,  # æ¤œè¨¼æ™‚ã¯MixUpãªã—
                shuffle=False,
                num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 â˜…â˜…â˜…
                pin_memory=getattr(cfg, 'pin_memory', True),
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    else:
        # æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = FLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size, 
            augment=getattr(cfg, 'augment', True)
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # DataLoaderä½œæˆ
        num_workers = 2  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
        pin_memory = getattr(cfg, 'pin_memory', True)
        
        train_dataloader = DataLoader(
            train_dataset,
            batch_size=cfg.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
            persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = DataLoader(
                val_dataset,
                batch_size=cfg.batch_size,
                shuffle=False,
                collate_fn=collate_fn,
                num_workers=num_workers,
                pin_memory=pin_memory,
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    print(f"   Train batches: {len(train_dataloader)}")
    if val_dataloader:
        print(f"   Validation batches: {len(val_dataloader)}")
    
    return train_dataloader, val_dataloader

# ===== Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­çµ±åˆç‰ˆï¼‰ =====
def phase3_integrated_training_loop(model, train_dataloader, val_dataloader, criterion, cfg, architecture_type):
    """Phase 3çµ±åˆå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆï¼‰"""
    
    # â˜…â˜…â˜… è¨ºæ–­æ©Ÿèƒ½åˆæœŸåŒ– â˜…â˜…â˜…
    diagnostics = DiagnosticTrainer(
        save_dir=os.path.join(cfg.save_dir, "diagnostics")
    )
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š
    if getattr(cfg, 'optimizer_type', 'AdamW') == "AdamW":
        optimizer = optim.AdamW(
            model.parameters(),
            lr=cfg.learning_rate,
            weight_decay=getattr(cfg, 'weight_decay', 2e-4),
            betas=getattr(cfg, 'betas', (0.9, 0.999)),
            eps=getattr(cfg, 'eps', 1e-8)
        )
    else:
        optimizer = optim.Adam(model.parameters(), lr=cfg.learning_rate)
    
    # EMAåˆæœŸåŒ–
    ema = None
    if getattr(cfg, 'use_ema', True):
        ema = EMAModel(model, decay=getattr(cfg, 'ema_decay', 0.9995))
        print(f"ğŸ”„ EMA initialized with decay {cfg.ema_decay}")
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¨­å®š
    scheduler = None
    if getattr(cfg, 'use_scheduler', True):
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=cfg.num_epochs,
            eta_min=getattr(cfg, 'min_lr', cfg.learning_rate / 250)
        )
    
    # Early Stoppingè¨­å®š
    best_val_loss = float('inf')
    patience_counter = 0
    
    # å­¦ç¿’çµ±è¨ˆ
    train_losses = []
    val_losses = []
    learning_rates = []
    
    print(f"ğŸš€ Phase 3çµ±åˆå­¦ç¿’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"   Architecture: {architecture_type}")
    print(f"   Optimizer: {getattr(cfg, 'optimizer_type', 'AdamW')}")
    print(f"   EMA: {'ON' if getattr(cfg, 'use_ema', True) else 'OFF'}")
    print(f"   Validation: {'ON' if val_dataloader else 'OFF'}")
    print(f"   Diagnostics: {diagnostics.save_dir}")
    
    for epoch in range(cfg.num_epochs):
        epoch_start = time.time()
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­é–‹å§‹ â˜…â˜…â˜…
        diagnostics.start_epoch_diagnosis(epoch + 1)
        
        # ===== ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‡¦ç† =====
        warmup_epochs = getattr(cfg, 'warmup_epochs', 0)
        if epoch < warmup_epochs:
            warmup_lr = cfg.learning_rate * (epoch + 1) / warmup_epochs
            for param_group in optimizer.param_groups:
                param_group['lr'] = warmup_lr
            print(f"ğŸ”¥ Warmup Epoch {epoch+1}: LR = {warmup_lr:.6f}")
        
        # ===== è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º =====
        model.train()
        epoch_loss = 0
        batch_count = 0
        
        # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            from progress import MultiScaleProgressTracker
            progress_tracker = MultiScaleProgressTracker(len(train_dataloader), print_interval=getattr(cfg, 'print_interval', 5))
            progress_tracker.start_epoch(epoch + 1, cfg.num_epochs)
            use_progress_tracker = True
        except ImportError:
            use_progress_tracker = False
            print_interval = getattr(cfg, 'print_interval', 5)
        
        for batch_idx, (images, targets) in enumerate(train_dataloader):
            images = images.to(cfg.device, non_blocking=True)
            
            # Forwardï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¥ï¼‰
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
                
                # â˜…â˜…â˜… è¨ºæ–­æƒ…å ±å–å¾— â˜…â˜…â˜…
                loss_components = None
                try:
                    # è©³ç´°æƒ…å ±ä»˜ãã§å†è¨ˆç®—ï¼ˆè¨ºæ–­ç”¨ï¼‰
                    if hasattr(criterion, 'return_components') and batch_idx % 20 == 0:
                        criterion.return_components = True
                        _, loss_components = criterion(predictions, targets)
                        criterion.return_components = False
                except:
                    pass  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡è¦–
                
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
                loss_components = None
            
            # â˜…â˜…â˜… ãƒãƒƒãƒè¨ºæ–­å®Ÿè¡Œ â˜…â˜…â˜…
            try:
                diagnostics.log_batch_diagnosis(
                    batch_idx, images, targets, predictions, loss_components
                )
            except Exception as e:
                if batch_idx % 50 == 0:  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æ¸›ã‚‰ã™
                    print(f"   âš ï¸ è¨ºæ–­ã‚¨ãƒ©ãƒ¼ (batch {batch_idx}): {e}")
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
            if hasattr(cfg, 'gradient_clip'):
                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.gradient_clip)
            
            optimizer.step()
            
            # EMAæ›´æ–°
            if ema:
                ema.update()
            
            epoch_loss += loss.item()
            batch_count += 1
            
            # é€²æ—è¡¨ç¤º
            current_lr = optimizer.param_groups[0]['lr']
            if use_progress_tracker:
                # è©³ç´°é€²æ—è¡¨ç¤º
                if architecture_type == "multiscale" and loss_components:
                    progress_tracker.update_batch_multiscale(
                        batch_idx, loss.item(), current_lr, loss_components
                    )
                else:
                    progress_tracker.update_batch(batch_idx, loss.item(), current_lr)
            else:
                # ç°¡æ˜“é€²æ—è¡¨ç¤º
                if batch_idx % print_interval == 0:
                    print(f"   Batch {batch_idx:4d}/{len(train_dataloader)}: Loss={loss.item():.4f}, LR={current_lr:.6f}")
        
        avg_train_loss = epoch_loss / batch_count
        
        # ===== æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º =====
        val_loss = float('inf')
        if val_dataloader and epoch % getattr(cfg, 'validate_every', 1) == 0:
            # EMAãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼
            if ema:
                ema.apply_shadow()
            
            # è©³ç´°æ¤œè¨¼ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã«1å›ï¼‰
            if epoch % 5 == 0 and getattr(cfg, 'use_advanced_postprocessing', True):
                print(f"ğŸ”§ å¾Œå‡¦ç†è¾¼ã¿è©³ç´°æ¤œè¨¼å®Ÿè¡Œä¸­...")
                val_loss = validate_model_with_postprocessing(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            else:
                # é€šå¸¸æ¤œè¨¼ï¼ˆè»½é‡ï¼‰
                val_loss = validate_model(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            
            if ema:
                ema.restore()
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
        if scheduler and epoch >= warmup_epochs:
            scheduler.step()
        
        epoch_time = time.time() - epoch_start
        current_lr = optimizer.param_groups[0]['lr']
        
        # çµ±è¨ˆè¨˜éŒ²
        train_losses.append(avg_train_loss)
        val_losses.append(val_loss)
        learning_rates.append(current_lr)
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­çµ‚äº† & æ”¹å–„ææ¡ˆ â˜…â˜…â˜…
        suggestions = diagnostics.end_epoch_diagnosis(epoch + 1, val_loss, model)
        
        # ãƒ­ã‚°è¡¨ç¤º
        val_str = f"Val: {val_loss:6.4f}" if val_loss != float('inf') else "Val: ----"
        print(f"\nğŸ“ˆ Epoch [{epoch+1:2d}/{cfg.num_epochs}] "
              f"Train: {avg_train_loss:6.4f} {val_str} "
              f"Time: {epoch_time:4.1f}s LR: {current_lr:.6f}")
        
        # æ”¹å–„ææ¡ˆè¡¨ç¤º
        if suggestions:
            print(f"ğŸ’¡ è¨ºæ–­ææ¡ˆ:")
            for suggestion in suggestions[:2]:  # ä¸Šä½2ä»¶ã®ã¿
                print(f"   {suggestion['type']}: {suggestion['suggestion']}")
        
        # GPUä½¿ç”¨é‡è¡¨ç¤ºï¼ˆæœ€åˆã®æ•°ã‚¨ãƒãƒƒã‚¯ï¼‰
        if cfg.device.type == 'cuda' and epoch < 3:
            memory_used = torch.cuda.memory_allocated(0) / 1024**3
            print(f"   GPU Memory: {memory_used:.2f}GB")
        
        # Early Stopping & Best Model Saving
        current_loss = val_loss if val_loss != float('inf') else avg_train_loss
        min_improvement = getattr(cfg, 'min_improvement', 0.005)
        
        if current_loss < best_val_loss - min_improvement:
            best_val_loss = current_loss
            patience_counter = 0
            
            # EMAãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            if ema:
                ema.apply_shadow()
            
            save_best_model_integrated(model, optimizer, ema, epoch, best_val_loss, cfg, architecture_type)
            
            if ema:
                ema.restore()
            
            print(f"ğŸ‰ New best loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            patience = getattr(cfg, 'patience', 10)
            print(f"â³ No improvement for {patience_counter}/{patience} epochs")
            
            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping triggered")
                break
        
        # å®šæœŸä¿å­˜
        save_interval = getattr(cfg, 'save_interval', 2)
        if (epoch + 1) % save_interval == 0:
            save_checkpoint_integrated(model, optimizer, epoch, avg_train_loss, cfg, architecture_type)
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if cfg.device.type == 'cuda':
            empty_cache_every = getattr(cfg, 'empty_cache_every_n_batch', 50)
            if (epoch + 1) % (empty_cache_every // 10) == 0:  # ã‚¨ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã§èª¿æ•´
                torch.cuda.empty_cache()
    
    # â˜…â˜…â˜… æœ€çµ‚è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
    diagnostics.generate_final_report()
    
    print(f"\nâœ… Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
    print(f"ğŸ† Best Loss: {best_val_loss:.4f}")
    
    return train_losses, val_losses, learning_rates, best_val_loss

# ===== çµ±åˆç‰ˆä¿å­˜é–¢æ•° =====
def save_best_model_integrated(model, optimizer, ema, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'ema_state_dict': ema.shadow if ema else None,
        'config': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'ema_decay': getattr(cfg, 'ema_decay', None),
            'validation_split': getattr(cfg, 'validation_split', 0.15),
            'use_multiscale': getattr(cfg, 'use_multiscale_architecture', True)
        },
        'training_stats': {
            'gpu_memory_peak': torch.cuda.max_memory_allocated(0) / 1024**3 if torch.cuda.is_available() else 0,
            'parameters': sum(p.numel() for p in model.parameters())
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'phase3_integrated_{architecture_type}_loss_{loss:.4f}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Phase 3 integrated model saved: {save_path}")

def save_checkpoint_integrated(model, optimizer, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'config_info': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'optimizer_type': getattr(cfg, 'optimizer_type', 'AdamW')
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'checkpoint_integrated_epoch_{epoch+1}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Checkpoint saved: {save_path}")

def plot_training_progress(losses, lrs, val_losses=None, save_path="training_progress_integrated.png"):
    """å­¦ç¿’é€²æ—ã‚’å¯è¦–åŒ–ï¼ˆçµ±åˆç‰ˆï¼‰"""
    try:
        import matplotlib.pyplot as plt
        
        if val_losses:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 4))
        else:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Training Loss plot
        ax1.plot(losses, 'b-', linewidth=2, label='Train Loss')
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax1.plot(valid_epochs, valid_val_losses, 'r-', linewidth=2, label='Val Loss')
        
        ax1.set_title('Phase 3 Integrated Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')
        if val_losses:
            ax1.legend()
        
        # Learning Rate plot
        ax2.plot(lrs, 'r-', linewidth=2)
        ax2.set_title('Learning Rate')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # Validation Loss separate plot
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax3.plot(valid_epochs, valid_val_losses, 'g-', linewidth=2)
                ax3.set_title('Validation Loss')
                ax3.set_xlabel('Epoch')
                ax3.set_ylabel('Val Loss')
                ax3.grid(True, alpha=0.3)
                ax3.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
        
        print(f"ğŸ“Š Training progress saved to {save_path}")
    except ImportError:
        print("âš ï¸ matplotlib not available - skipping visualization")
    except Exception as e:
        print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# ===== GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ =====
def comprehensive_gpu_check():
    """åŒ…æ‹¬çš„ãªGPUç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯")
    print("="*60)
    
    print(f"1. CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   GPU count: {torch.cuda.device_count()}")
        print(f"   Current device: {torch.cuda.current_device()}")
        print(f"   Device name: {torch.cuda.get_device_name(0)}")
        
        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
        memory_reserved = torch.cuda.memory_reserved(0) / 1024**3
        print(f"   GPU memory - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
    else:
        print("   âŒ CUDA not available!")
        return False
    
    print(f"2. PyTorch version: {torch.__version__}")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"3. Selected device: {device}")
    
    return True

# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====
def main():
    print("ğŸš€ Starting Phase 3 Integrated YOLO Training (Diagnostic Enhanced)")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª")
    print("="*80)
    VersionTracker.print_all_versions()

    # è¨­å®šã¨GPUç¢ºèª
    cfg = Config()
    os.makedirs(cfg.save_dir, exist_ok=True)
    
    # è¨ºæ–­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    diagnostic_dir = os.path.join(cfg.save_dir, "diagnostics")
    os.makedirs(diagnostic_dir, exist_ok=True)
    
    # GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯
    if not comprehensive_gpu_check():
        print("âŒ GPUä½¿ç”¨ä¸å¯ - CPUå­¦ç¿’ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        cfg.device = torch.device('cpu')
        cfg.batch_size = max(cfg.batch_size // 4, 1)
        print(f"   CPUç”¨ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {cfg.batch_size} ã«èª¿æ•´")
    
    print(f"\nğŸ“‹ å­¦ç¿’è¨­å®š:")
    print(f"   Device: {cfg.device}")
    print(f"   Batch size: {cfg.batch_size}")
    print(f"   Image size: {cfg.img_size}")
    print(f"   Classes: {cfg.num_classes}")
    print(f"   Learning rate: {cfg.learning_rate:.0e}")
    print(f"   EMA: {getattr(cfg, 'use_ema', True)}")
    print(f"   Validation Split: {getattr(cfg, 'validation_split', 0.15)}")
    print(f"   Diagnostics: ON")
    
    # Phase 3çµ±åˆ: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ & æ¤œè¨¼åˆ†å‰²
    print("\nğŸ“Š Loading dataset with validation split...")
    try:
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
        
        print(f"   Total train batches: {len(train_dataloader)}")
        if val_dataloader:
            print(f"   Total validation batches: {len(val_dataloader)}")
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒªãƒˆãƒ©ã‚¤ä¸­...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        global USE_IMPROVED
        USE_IMPROVED = False
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
    
    # Phase 3çµ±åˆ: ãƒ¢ãƒ‡ãƒ«&æå¤±é–¢æ•°ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•é¸æŠï¼‰
    print("\nğŸ¤– Creating Phase 3 integrated model...")
    model, criterion, architecture_type = create_model_and_loss(cfg)
    
    # GPUã«ç§»å‹•
    print(f"   Moving model to {cfg.device}...")
    model = model.to(cfg.device)
    
    if cfg.device.type == 'cuda':
        model = model.float()
    
    print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    model_device = next(model.parameters()).device
    print(f"   Model device confirmed: {model_device}")
    
    # Phase 3çµ±åˆå­¦ç¿’å®Ÿè¡Œ
    print("\nğŸš€ Phase 3çµ±åˆå­¦ç¿’ã‚’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"ğŸ¯ ç›®æ¨™: Val Loss 43.45 â†’ 25-30")
    
    try:
        train_losses, val_losses, lrs, best_loss = phase3_integrated_training_loop(
            model, train_dataloader, val_dataloader, criterion, cfg, architecture_type
        )
        
        # çµæœå¯è¦–åŒ–
        try:
            plot_training_progress(train_losses, lrs, val_losses)
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\nğŸ¯ Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
        print(f"ğŸ† Best Loss: {best_loss:.4f}")
        print(f"ğŸ”§ Architecture: {architecture_type}")
        
        # ç›®æ¨™é”æˆåˆ¤å®š
        print(f"\nğŸ“Š ç›®æ¨™é”æˆåˆ¤å®š:")
        if best_loss < 30.0:
            print("ğŸ‰ Step 1ç›®æ¨™é”æˆ! (Val Loss < 30.0)")
            if best_loss < 20.0:
                print("ğŸ† äºˆæƒ³ã‚’ä¸Šå›ã‚‹æˆæœ! (Val Loss < 20.0)")
        elif best_loss < 35.0:
            print("ğŸŸ¡ éƒ¨åˆ†çš„æ”¹å–„ (Val Loss < 35.0) - ç¶™ç¶šæ¨å¥¨")
        else:
            print("ğŸ”´ ç›®æ¨™æœªé”æˆ - æ–¹é‡è»¢æ›æ¤œè¨")
            print("   æ¨å¥¨: å­¦ç¿’ç‡ã‚’ã•ã‚‰ã«2å€ã€ã¾ãŸã¯ã‚¢ãƒ³ã‚«ãƒ¼è¦‹ç›´ã—")
        
        # å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
        improvement_ratio = 43.45 / best_loss if best_loss > 0 else 1
        print(f"\nğŸ’¡ æ”¹å–„çµæœ:")
        print(f"   æ”¹å–„ç‡: {improvement_ratio:.1f}x (43.45 â†’ {best_loss:.4f})")
        print(f"   æ¬¡ç›®æ¨™: Val Loss < {best_loss * 0.7:.1f}")
        
        if best_loss > 35.0:
            print(f"\nğŸš¨ ç·Šæ€¥æ”¹å–„æ¡ˆ:")
            print(f"   1. å­¦ç¿’ç‡ã‚’2å€ã« ({cfg.learning_rate:.0e} â†’ {cfg.learning_rate*2:.0e})")
            print(f"   2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã« ({cfg.batch_size} â†’ {cfg.batch_size//2})")
            print(f"   3. ã‚¢ãƒ³ã‚«ãƒ¼ã‚µã‚¤ã‚ºã®å…¨é¢è¦‹ç›´ã—")
        
    except Exception as e:
        print(f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nâœ… Training completed!")
    
    # æœ€çµ‚çµ±è¨ˆ
    if cfg.device.type == 'cuda':
        final_memory = torch.cuda.memory_allocated(0) / 1024**3
        max_memory = torch.cuda.max_memory_allocated(0) / 1024**3
        print(f"ğŸ“Š æœ€çµ‚GPUçµ±è¨ˆ:")
        print(f"   ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory:.2f}GB")
        print(f"   æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {max_memory:.2f}GB")
    
    # å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ¯ å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   Architecture: {architecture_type}")
    print(f"   æœ€çµ‚Loss: {best_loss:.4f}")
    print(f"   æ”¹è‰¯æ‹¡å¼µ: {'ON' if USE_IMPROVED else 'OFF'}")
    print(f"   è¨ºæ–­æ©Ÿèƒ½: ON")
    print(f"   EMAä½¿ç”¨: {'Yes' if getattr(cfg, 'use_ema', True) else 'No'}")
    print(f"   æ¤œè¨¼åˆ†å‰²: {'Yes' if getattr(cfg, 'validation_split', 0.15) > 0 else 'No'}")
    print(f"   ä¿å­˜å…ˆ: {cfg.save_dir}")
    print(f"   è¨ºæ–­ãƒ­ã‚°: {diagnostic_dir}")

if __name__ == "__main__":
    main()# train_phase3_integrated.py - ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«YOLOçµ±åˆç‰ˆ
import torch
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import time
import os

from config import Config

# â˜…â˜…â˜… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–¢é€£ä¿®æ­£ â˜…â˜…â˜…
try:
    # æ”¹è‰¯ç‰ˆã‚’å„ªå…ˆ
    from improved_augmentation import ImprovedFLIRDataset, create_improved_dataloader
    USE_IMPROVED = True
    print("âœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from dataset import FLIRDataset, collate_fn
    USE_IMPROVED = False
    print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨")

# â˜…â˜…â˜… Phase 3 æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from multiscale_model import MultiScaleYOLO
from advanced_losses import AdvancedMultiScaleLoss
from post_processing import AdvancedPostProcessor, SoftNMS
from diagnostic_training import DiagnosticTrainer

# â˜…â˜…â˜… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆå¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ â˜…â˜…â˜…
from model import SimpleYOLO
from loss import YOLOLoss

# â˜…â˜…â˜… å…±æœ‰VersionTrackerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from version_tracker import (
    create_version_tracker, 
    VersionTracker, 
    show_all_project_versions,
    debug_version_status,
    get_version_count
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
training_version = create_version_tracker("Training System v3.0 - Diagnostic Integrated", "train.py")
training_version.add_modification("è¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆ")
training_version.add_modification("æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ")
training_version.add_modification("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")

# ===== Phase 3: EMAã‚¯ãƒ©ã‚¹å®Ÿè£… =====
class EMAModel:
    """Exponential Moving Average for model parameters"""
    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self.register()

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}

# ===== ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é¸æŠé–¢æ•° =====
def create_model_and_loss(cfg):
    """Phase 3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é¸æŠ"""
    
    if getattr(cfg, 'use_multiscale_architecture', True):
        print("ğŸš€ Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
        try:
            # Step 1ã®ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆå®Ÿéš›ã«ã¯Step 1ã§ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
            anchors = {
                'small':  [(7, 11), (14, 28), (22, 65)],      # 52x52 grid
                'medium': [(42, 35), (76, 67), (46, 126)],    # 26x26 grid  
                'large':  [(127, 117), (88, 235), (231, 218)] # 13x13 grid
            }
            
            model = MultiScaleYOLO(num_classes=cfg.num_classes, anchors=anchors)
            criterion = AdvancedMultiScaleLoss(
                anchors=anchors, 
                num_classes=cfg.num_classes,
                use_ciou=getattr(cfg, 'use_ciou', True),
                use_focal=getattr(cfg, 'use_focal', True),
                use_label_smoothing=getattr(cfg, 'use_label_smoothing', False)
            )
            
            print(f"   âœ… MultiScaleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
            print(f"   âœ… AdvancedMultiScaleLoss: 3ã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œ")
            
            return model, criterion, "multiscale"
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    print("ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨")
    model = SimpleYOLO(cfg.num_classes, use_phase2_enhancements=False)
    criterion = YOLOLoss(cfg.num_classes)
    
    print(f"   âœ… SimpleYOLO: {sum(p.numel() for p in model.parameters()):,} parameters")
    print(f"   âœ… YOLOLoss: å˜ä¸€ã‚¹ã‚±ãƒ¼ãƒ«")
    
    return model, criterion, "fallback"

# ===== Phase 3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²é–¢æ•° =====
def create_train_val_split(dataset, val_split=0.15):
    """è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²"""
    total_size = len(dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size
    
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)  # å†ç¾æ€§ã®ãŸã‚
    )
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:")
    print(f"   Train: {train_size} images ({100*(1-val_split):.1f}%)")
    print(f"   Validation: {val_size} images ({100*val_split:.1f}%)")
    return train_dataset, val_dataset

# ===== Phase 3: æ¤œè¨¼é–¢æ•°ï¼ˆãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œï¼‰ =====
def validate_model(model, val_dataloader, criterion, device, architecture_type):
    """æ¤œè¨¼å®Ÿè¡Œï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•åˆ¤å®šï¼‰"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    with torch.no_grad():
        for images, targets in val_dataloader:
            images = images.to(device, non_blocking=True)
            
            if architecture_type == "multiscale":
                # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«: è¾æ›¸å½¢å¼ã®å‡ºåŠ›
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                # å¾“æ¥: ã‚¿ãƒ—ãƒ«å½¢å¼ã®å‡ºåŠ›
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    return avg_val_loss

def validate_model_with_postprocessing(model, val_dataloader, criterion, device, architecture_type, use_advanced_postprocessing=True):
    """å¾Œå‡¦ç†ã‚’å«ã‚€è©³ç´°æ¤œè¨¼"""
    model.eval()
    total_val_loss = 0
    val_batches = 0
    
    # å¾Œå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if use_advanced_postprocessing:
        post_processor = AdvancedPostProcessor(
            use_soft_nms=True,
            use_tta=False,      # æ¤œè¨¼æ™‚ã¯æ™‚é–“åŠ¹ç‡é‡è¦–
            use_multiscale=False,
            conf_threshold=0.25,  # æ”¹è‰¯è¨­å®š
            iou_threshold=0.5
        )
        
        detection_stats = {
            'total_detections': 0,
            'high_conf_detections': 0,  # conf > 0.7
            'processed_detections': 0
        }
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(val_dataloader):
            images = images.to(device, non_blocking=True)
            
            # é€šå¸¸ã®æå¤±è¨ˆç®—
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
            
            total_val_loss += loss.item()
            val_batches += 1
            
            # å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼ï¼‰
            if use_advanced_postprocessing and batch_idx % 10 == 0:  # 10ãƒãƒƒãƒã«1å›
                try:
                    # 1æšç›®ã®ç”»åƒã§å¾Œå‡¦ç†ãƒ†ã‚¹ãƒˆ
                    single_image = images[0:1]
                    single_pred = {k: v[0:1] for k, v in predictions.items()} if isinstance(predictions, dict) else predictions[0:1]
                    
                    # å¾Œå‡¦ç†å®Ÿè¡Œ
                    processed_detections = post_processor.process_predictions(
                        model, single_image, single_pred
                    )
                    
                    # çµ±è¨ˆæ›´æ–°
                    detection_stats['total_detections'] += len(processed_detections)
                    high_conf = sum(1 for det in processed_detections if det['score'] > 0.7)
                    detection_stats['high_conf_detections'] += high_conf
                    detection_stats['processed_detections'] += 1
                    
                except Exception as e:
                    pass  # å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    
    avg_val_loss = total_val_loss / val_batches if val_batches > 0 else float('inf')
    
    # å¾Œå‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º
    if use_advanced_postprocessing and detection_stats['processed_detections'] > 0:
        avg_detections = detection_stats['total_detections'] / detection_stats['processed_detections']
        avg_high_conf = detection_stats['high_conf_detections'] / detection_stats['processed_detections']
        
        print(f"ğŸ“Š å¾Œå‡¦ç†çµ±è¨ˆ (ã‚µãƒ³ãƒ—ãƒ«{detection_stats['processed_detections']}æš):")
        print(f"   å¹³å‡æ¤œå‡ºæ•°: {avg_detections:.1f}/ç”»åƒ")
        print(f"   é«˜ä¿¡é ¼åº¦æ¤œå‡º: {avg_high_conf:.1f}/ç”»åƒ (conf>0.7)")
    
    return avg_val_loss

# ===== ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰ =====
def setup_dataloaders(cfg):
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ”¹è‰¯ç‰ˆå¯¾å¿œï¼‰"""
    
    if USE_IMPROVED:
        # æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ¨ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = ImprovedFLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size,
            use_improved_augment=True,
            mixup_in_dataset=False  # DataLoaderãƒ¬ãƒ™ãƒ«ã§å‡¦ç†
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # æ”¹è‰¯ç‰ˆDataLoader
        train_dataloader = create_improved_dataloader(
            train_dataset,
            batch_size=cfg.batch_size,
            use_mixup=getattr(cfg, 'use_mixup', True),
            shuffle=True,
            num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
            pin_memory=getattr(cfg, 'pin_memory', True),
            persistent_workers=False,  # â˜…â˜…â˜… ä¿®æ­£: True â†’ False (å®‰å®šæ€§å‘ä¸Š) â˜…â˜…â˜…
            prefetch_factor=2  # â˜…â˜…â˜… ä¿®æ­£: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤æ˜ç¤º â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = create_improved_dataloader(
                val_dataset,
                batch_size=cfg.batch_size,
                use_mixup=False,  # æ¤œè¨¼æ™‚ã¯MixUpãªã—
                shuffle=False,
                num_workers=2,  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 â˜…â˜…â˜…
                pin_memory=getattr(cfg, 'pin_memory', True),
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    else:
        # æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
        print("ğŸ“š æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ä¸­...")
        full_dataset = FLIRDataset(
            cfg.train_img_dir, 
            cfg.train_label_dir, 
            cfg.img_size, 
            augment=getattr(cfg, 'augment', True)
        )
        
        # æ¤œè¨¼åˆ†å‰²
        if cfg.validation_split > 0:
            train_dataset, val_dataset = create_train_val_split(full_dataset, cfg.validation_split)
        else:
            train_dataset = full_dataset
            val_dataset = None
        
        # DataLoaderä½œæˆ
        num_workers = 2  # â˜…â˜…â˜… ä¿®æ­£: 4 â†’ 2 (è­¦å‘Šå¯¾ç­–) â˜…â˜…â˜…
        pin_memory = getattr(cfg, 'pin_memory', True)
        
        train_dataloader = DataLoader(
            train_dataset,
            batch_size=cfg.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
            persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
        )
        
        val_dataloader = None
        if val_dataset:
            val_dataloader = DataLoader(
                val_dataset,
                batch_size=cfg.batch_size,
                shuffle=False,
                collate_fn=collate_fn,
                num_workers=num_workers,
                pin_memory=pin_memory,
                persistent_workers=False  # â˜…â˜…â˜… ä¿®æ­£: å®‰å®šæ€§å‘ä¸Š â˜…â˜…â˜…
            )
    
    print(f"   Train batches: {len(train_dataloader)}")
    if val_dataloader:
        print(f"   Validation batches: {len(val_dataloader)}")
    
    return train_dataloader, val_dataloader

# ===== Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­çµ±åˆç‰ˆï¼‰ =====
def phase3_integrated_training_loop(model, train_dataloader, val_dataloader, criterion, cfg, architecture_type):
    """Phase 3çµ±åˆå­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè¨ºæ–­æ©Ÿèƒ½å®Œå…¨çµ±åˆï¼‰"""
    
    # â˜…â˜…â˜… è¨ºæ–­æ©Ÿèƒ½åˆæœŸåŒ– â˜…â˜…â˜…
    diagnostics = DiagnosticTrainer(
        save_dir=os.path.join(cfg.save_dir, "diagnostics")
    )
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š
    if getattr(cfg, 'optimizer_type', 'AdamW') == "AdamW":
        optimizer = optim.AdamW(
            model.parameters(),
            lr=cfg.learning_rate,
            weight_decay=getattr(cfg, 'weight_decay', 2e-4),
            betas=getattr(cfg, 'betas', (0.9, 0.999)),
            eps=getattr(cfg, 'eps', 1e-8)
        )
    else:
        optimizer = optim.Adam(model.parameters(), lr=cfg.learning_rate)
    
    # EMAåˆæœŸåŒ–
    ema = None
    if getattr(cfg, 'use_ema', True):
        ema = EMAModel(model, decay=getattr(cfg, 'ema_decay', 0.9995))
        print(f"ğŸ”„ EMA initialized with decay {cfg.ema_decay}")
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¨­å®š
    scheduler = None
    if getattr(cfg, 'use_scheduler', True):
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=cfg.num_epochs,
            eta_min=getattr(cfg, 'min_lr', cfg.learning_rate / 250)
        )
    
    # Early Stoppingè¨­å®š
    best_val_loss = float('inf')
    patience_counter = 0
    
    # å­¦ç¿’çµ±è¨ˆ
    train_losses = []
    val_losses = []
    learning_rates = []
    
    print(f"ğŸš€ Phase 3çµ±åˆå­¦ç¿’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"   Architecture: {architecture_type}")
    print(f"   Optimizer: {getattr(cfg, 'optimizer_type', 'AdamW')}")
    print(f"   EMA: {'ON' if getattr(cfg, 'use_ema', True) else 'OFF'}")
    print(f"   Validation: {'ON' if val_dataloader else 'OFF'}")
    print(f"   Diagnostics: {diagnostics.save_dir}")
    
    for epoch in range(cfg.num_epochs):
        epoch_start = time.time()
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­é–‹å§‹ â˜…â˜…â˜…
        diagnostics.start_epoch_diagnosis(epoch + 1)
        
        # ===== ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‡¦ç† =====
        warmup_epochs = getattr(cfg, 'warmup_epochs', 0)
        if epoch < warmup_epochs:
            warmup_lr = cfg.learning_rate * (epoch + 1) / warmup_epochs
            for param_group in optimizer.param_groups:
                param_group['lr'] = warmup_lr
            print(f"ğŸ”¥ Warmup Epoch {epoch+1}: LR = {warmup_lr:.6f}")
        
        # ===== è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º =====
        model.train()
        epoch_loss = 0
        batch_count = 0
        
        # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            from progress import MultiScaleProgressTracker
            progress_tracker = MultiScaleProgressTracker(len(train_dataloader), print_interval=getattr(cfg, 'print_interval', 5))
            progress_tracker.start_epoch(epoch + 1, cfg.num_epochs)
            use_progress_tracker = True
        except ImportError:
            use_progress_tracker = False
            print_interval = getattr(cfg, 'print_interval', 5)
        
        for batch_idx, (images, targets) in enumerate(train_dataloader):
            images = images.to(cfg.device, non_blocking=True)
            
            # Forwardï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¥ï¼‰
            if architecture_type == "multiscale":
                predictions = model(images)
                loss = criterion(predictions, targets)
                
                # â˜…â˜…â˜… è¨ºæ–­æƒ…å ±å–å¾— â˜…â˜…â˜…
                loss_components = None
                try:
                    # è©³ç´°æƒ…å ±ä»˜ãã§å†è¨ˆç®—ï¼ˆè¨ºæ–­ç”¨ï¼‰
                    if hasattr(criterion, 'return_components') and batch_idx % 20 == 0:
                        criterion.return_components = True
                        _, loss_components = criterion(predictions, targets)
                        criterion.return_components = False
                except:
                    pass  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡è¦–
                
            else:
                predictions, grid_size = model(images)
                loss = criterion(predictions, targets, grid_size)
                loss_components = None
            
            # â˜…â˜…â˜… ãƒãƒƒãƒè¨ºæ–­å®Ÿè¡Œ â˜…â˜…â˜…
            try:
                diagnostics.log_batch_diagnosis(
                    batch_idx, images, targets, predictions, loss_components
                )
            except Exception as e:
                if batch_idx % 50 == 0:  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æ¸›ã‚‰ã™
                    print(f"   âš ï¸ è¨ºæ–­ã‚¨ãƒ©ãƒ¼ (batch {batch_idx}): {e}")
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
            if hasattr(cfg, 'gradient_clip'):
                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.gradient_clip)
            
            optimizer.step()
            
            # EMAæ›´æ–°
            if ema:
                ema.update()
            
            epoch_loss += loss.item()
            batch_count += 1
            
            # é€²æ—è¡¨ç¤º
            current_lr = optimizer.param_groups[0]['lr']
            if use_progress_tracker:
                # è©³ç´°é€²æ—è¡¨ç¤º
                if architecture_type == "multiscale" and loss_components:
                    progress_tracker.update_batch_multiscale(
                        batch_idx, loss.item(), current_lr, loss_components
                    )
                else:
                    progress_tracker.update_batch(batch_idx, loss.item(), current_lr)
            else:
                # ç°¡æ˜“é€²æ—è¡¨ç¤º
                if batch_idx % print_interval == 0:
                    print(f"   Batch {batch_idx:4d}/{len(train_dataloader)}: Loss={loss.item():.4f}, LR={current_lr:.6f}")
        
        avg_train_loss = epoch_loss / batch_count
        
        # ===== æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º =====
        val_loss = float('inf')
        if val_dataloader and epoch % getattr(cfg, 'validate_every', 1) == 0:
            # EMAãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼
            if ema:
                ema.apply_shadow()
            
            # è©³ç´°æ¤œè¨¼ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã«1å›ï¼‰
            if epoch % 5 == 0 and getattr(cfg, 'use_advanced_postprocessing', True):
                print(f"ğŸ”§ å¾Œå‡¦ç†è¾¼ã¿è©³ç´°æ¤œè¨¼å®Ÿè¡Œä¸­...")
                val_loss = validate_model_with_postprocessing(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            else:
                # é€šå¸¸æ¤œè¨¼ï¼ˆè»½é‡ï¼‰
                val_loss = validate_model(
                    model, val_dataloader, criterion, cfg.device, architecture_type
                )
            
            if ema:
                ema.restore()
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
        if scheduler and epoch >= warmup_epochs:
            scheduler.step()
        
        epoch_time = time.time() - epoch_start
        current_lr = optimizer.param_groups[0]['lr']
        
        # çµ±è¨ˆè¨˜éŒ²
        train_losses.append(avg_train_loss)
        val_losses.append(val_loss)
        learning_rates.append(current_lr)
        
        # â˜…â˜…â˜… ã‚¨ãƒãƒƒã‚¯è¨ºæ–­çµ‚äº† & æ”¹å–„ææ¡ˆ â˜…â˜…â˜…
        suggestions = diagnostics.end_epoch_diagnosis(epoch + 1, val_loss, model)
        
        # ãƒ­ã‚°è¡¨ç¤º
        val_str = f"Val: {val_loss:6.4f}" if val_loss != float('inf') else "Val: ----"
        print(f"\nğŸ“ˆ Epoch [{epoch+1:2d}/{cfg.num_epochs}] "
              f"Train: {avg_train_loss:6.4f} {val_str} "
              f"Time: {epoch_time:4.1f}s LR: {current_lr:.6f}")
        
        # æ”¹å–„ææ¡ˆè¡¨ç¤º
        if suggestions:
            print(f"ğŸ’¡ è¨ºæ–­ææ¡ˆ:")
            for suggestion in suggestions[:2]:  # ä¸Šä½2ä»¶ã®ã¿
                print(f"   {suggestion['type']}: {suggestion['suggestion']}")
        
        # GPUä½¿ç”¨é‡è¡¨ç¤ºï¼ˆæœ€åˆã®æ•°ã‚¨ãƒãƒƒã‚¯ï¼‰
        if cfg.device.type == 'cuda' and epoch < 3:
            memory_used = torch.cuda.memory_allocated(0) / 1024**3
            print(f"   GPU Memory: {memory_used:.2f}GB")
        
        # Early Stopping & Best Model Saving
        current_loss = val_loss if val_loss != float('inf') else avg_train_loss
        min_improvement = getattr(cfg, 'min_improvement', 0.005)
        
        if current_loss < best_val_loss - min_improvement:
            best_val_loss = current_loss
            patience_counter = 0
            
            # EMAãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            if ema:
                ema.apply_shadow()
            
            save_best_model_integrated(model, optimizer, ema, epoch, best_val_loss, cfg, architecture_type)
            
            if ema:
                ema.restore()
            
            print(f"ğŸ‰ New best loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            patience = getattr(cfg, 'patience', 10)
            print(f"â³ No improvement for {patience_counter}/{patience} epochs")
            
            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping triggered")
                break
        
        # å®šæœŸä¿å­˜
        save_interval = getattr(cfg, 'save_interval', 2)
        if (epoch + 1) % save_interval == 0:
            save_checkpoint_integrated(model, optimizer, epoch, avg_train_loss, cfg, architecture_type)
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if cfg.device.type == 'cuda':
            empty_cache_every = getattr(cfg, 'empty_cache_every_n_batch', 50)
            if (epoch + 1) % (empty_cache_every // 10) == 0:  # ã‚¨ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã§èª¿æ•´
                torch.cuda.empty_cache()
    
    # â˜…â˜…â˜… æœ€çµ‚è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
    diagnostics.generate_final_report()
    
    print(f"\nâœ… Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
    print(f"ğŸ† Best Loss: {best_val_loss:.4f}")
    
    return train_losses, val_losses, learning_rates, best_val_loss

# ===== çµ±åˆç‰ˆä¿å­˜é–¢æ•° =====
def save_best_model_integrated(model, optimizer, ema, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'ema_state_dict': ema.shadow if ema else None,
        'config': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'ema_decay': getattr(cfg, 'ema_decay', None),
            'validation_split': getattr(cfg, 'validation_split', 0.15),
            'use_multiscale': getattr(cfg, 'use_multiscale_architecture', True)
        },
        'training_stats': {
            'gpu_memory_peak': torch.cuda.max_memory_allocated(0) / 1024**3 if torch.cuda.is_available() else 0,
            'parameters': sum(p.numel() for p in model.parameters())
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'phase3_integrated_{architecture_type}_loss_{loss:.4f}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Phase 3 integrated model saved: {save_path}")

def save_checkpoint_integrated(model, optimizer, epoch, loss, cfg, architecture_type):
    """çµ±åˆç‰ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'architecture_type': architecture_type,
        'config_info': {
            'batch_size': cfg.batch_size,
            'learning_rate': cfg.learning_rate,
            'optimizer_type': getattr(cfg, 'optimizer_type', 'AdamW')
        },
        'version_info': VersionTracker.get_all_trackers()
    }
    
    save_path = os.path.join(cfg.save_dir, f'checkpoint_integrated_epoch_{epoch+1}.pth')
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Checkpoint saved: {save_path}")

def plot_training_progress(losses, lrs, val_losses=None, save_path="training_progress_integrated.png"):
    """å­¦ç¿’é€²æ—ã‚’å¯è¦–åŒ–ï¼ˆçµ±åˆç‰ˆï¼‰"""
    try:
        import matplotlib.pyplot as plt
        
        if val_losses:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 4))
        else:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Training Loss plot
        ax1.plot(losses, 'b-', linewidth=2, label='Train Loss')
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax1.plot(valid_epochs, valid_val_losses, 'r-', linewidth=2, label='Val Loss')
        
        ax1.set_title('Phase 3 Integrated Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')
        if val_losses:
            ax1.legend()
        
        # Learning Rate plot
        ax2.plot(lrs, 'r-', linewidth=2)
        ax2.set_title('Learning Rate')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # Validation Loss separate plot
        if val_losses:
            valid_val_losses = [loss for loss in val_losses if loss != float('inf')]
            valid_epochs = [i for i, loss in enumerate(val_losses) if loss != float('inf')]
            if valid_val_losses:
                ax3.plot(valid_epochs, valid_val_losses, 'g-', linewidth=2)
                ax3.set_title('Validation Loss')
                ax3.set_xlabel('Epoch')
                ax3.set_ylabel('Val Loss')
                ax3.grid(True, alpha=0.3)
                ax3.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
        
        print(f"ğŸ“Š Training progress saved to {save_path}")
    except ImportError:
        print("âš ï¸ matplotlib not available - skipping visualization")
    except Exception as e:
        print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# ===== GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ =====
def comprehensive_gpu_check():
    """åŒ…æ‹¬çš„ãªGPUç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯")
    print("="*60)
    
    print(f"1. CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   GPU count: {torch.cuda.device_count()}")
        print(f"   Current device: {torch.cuda.current_device()}")
        print(f"   Device name: {torch.cuda.get_device_name(0)}")
        
        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
        memory_reserved = torch.cuda.memory_reserved(0) / 1024**3
        print(f"   GPU memory - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
    else:
        print("   âŒ CUDA not available!")
        return False
    
    print(f"2. PyTorch version: {torch.__version__}")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"3. Selected device: {device}")
    
    return True

# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====
def main():
    print("ğŸš€ Starting Phase 3 Integrated YOLO Training (Diagnostic Enhanced)")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª")
    print("="*80)
    VersionTracker.print_all_versions()

    # è¨­å®šã¨GPUç¢ºèª
    cfg = Config()
    os.makedirs(cfg.save_dir, exist_ok=True)
    
    # è¨ºæ–­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    diagnostic_dir = os.path.join(cfg.save_dir, "diagnostics")
    os.makedirs(diagnostic_dir, exist_ok=True)
    
    # GPUç’°å¢ƒè©³ç´°ãƒã‚§ãƒƒã‚¯
    if not comprehensive_gpu_check():
        print("âŒ GPUä½¿ç”¨ä¸å¯ - CPUå­¦ç¿’ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        cfg.device = torch.device('cpu')
        cfg.batch_size = max(cfg.batch_size // 4, 1)
        print(f"   CPUç”¨ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {cfg.batch_size} ã«èª¿æ•´")
    
    print(f"\nğŸ“‹ å­¦ç¿’è¨­å®š:")
    print(f"   Device: {cfg.device}")
    print(f"   Batch size: {cfg.batch_size}")
    print(f"   Image size: {cfg.img_size}")
    print(f"   Classes: {cfg.num_classes}")
    print(f"   Learning rate: {cfg.learning_rate:.0e}")
    print(f"   EMA: {getattr(cfg, 'use_ema', True)}")
    print(f"   Validation Split: {getattr(cfg, 'validation_split', 0.15)}")
    print(f"   Diagnostics: ON")
    
    # Phase 3çµ±åˆ: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ & æ¤œè¨¼åˆ†å‰²
    print("\nğŸ“Š Loading dataset with validation split...")
    try:
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
        
        print(f"   Total train batches: {len(train_dataloader)}")
        if val_dataloader:
            print(f"   Total validation batches: {len(val_dataloader)}")
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒªãƒˆãƒ©ã‚¤ä¸­...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        global USE_IMPROVED
        USE_IMPROVED = False
        train_dataloader, val_dataloader = setup_dataloaders(cfg)
    
    # Phase 3çµ±åˆ: ãƒ¢ãƒ‡ãƒ«&æå¤±é–¢æ•°ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªå‹•é¸æŠï¼‰
    print("\nğŸ¤– Creating Phase 3 integrated model...")
    model, criterion, architecture_type = create_model_and_loss(cfg)
    
    # GPUã«ç§»å‹•
    print(f"   Moving model to {cfg.device}...")
    model = model.to(cfg.device)
    
    if cfg.device.type == 'cuda':
        model = model.float()
    
    print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    model_device = next(model.parameters()).device
    print(f"   Model device confirmed: {model_device}")
    
    # Phase 3çµ±åˆå­¦ç¿’å®Ÿè¡Œ
    print("\nğŸš€ Phase 3çµ±åˆå­¦ç¿’ã‚’é–‹å§‹ï¼ˆè¨ºæ–­æ©Ÿèƒ½ä»˜ãï¼‰")
    print(f"ğŸ¯ ç›®æ¨™: Val Loss 43.45 â†’ 25-30")
    
    try:
        train_losses, val_losses, lrs, best_loss = phase3_integrated_training_loop(
            model, train_dataloader, val_dataloader, criterion, cfg, architecture_type
        )
        
        # çµæœå¯è¦–åŒ–
        try:
            plot_training_progress(train_losses, lrs, val_losses)
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\nğŸ¯ Phase 3çµ±åˆå­¦ç¿’å®Œäº†!")
        print(f"ğŸ† Best Loss: {best_loss:.4f}")
        print(f"ğŸ”§ Architecture: {architecture_type}")
        
        # ç›®æ¨™é”æˆåˆ¤å®š
        print(f"\nğŸ“Š ç›®æ¨™é”æˆåˆ¤å®š:")
        if best_loss < 30.0:
            print("ğŸ‰ Step 1ç›®æ¨™é”æˆ! (Val Loss < 30.0)")
            if best_loss < 20.0:
                print("ğŸ† äºˆæƒ³ã‚’ä¸Šå›ã‚‹æˆæœ! (Val Loss < 20.0)")
        elif best_loss < 35.0:
            print("ğŸŸ¡ éƒ¨åˆ†çš„æ”¹å–„ (Val Loss < 35.0) - ç¶™ç¶šæ¨å¥¨")
        else:
            print("ğŸ”´ ç›®æ¨™æœªé”æˆ - æ–¹é‡è»¢æ›æ¤œè¨")
            print("   æ¨å¥¨: å­¦ç¿’ç‡ã‚’ã•ã‚‰ã«2å€ã€ã¾ãŸã¯ã‚¢ãƒ³ã‚«ãƒ¼è¦‹ç›´ã—")
        
        # å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
        improvement_ratio = 43.45 / best_loss if best_loss > 0 else 1
        print(f"\nğŸ’¡ æ”¹å–„çµæœ:")
        print(f"   æ”¹å–„ç‡: {improvement_ratio:.1f}x (43.45 â†’ {best_loss:.4f})")
        print(f"   æ¬¡ç›®æ¨™: Val Loss < {best_loss * 0.7:.1f}")
        
        if best_loss > 35.0:
            print(f"\nğŸš¨ ç·Šæ€¥æ”¹å–„æ¡ˆ:")
            print(f"   1. å­¦ç¿’ç‡ã‚’2å€ã« ({cfg.learning_rate:.0e} â†’ {cfg.learning_rate*2:.0e})")
            print(f"   2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã« ({cfg.batch_size} â†’ {cfg.batch_size//2})")
            print(f"   3. ã‚¢ãƒ³ã‚«ãƒ¼ã‚µã‚¤ã‚ºã®å…¨é¢è¦‹ç›´ã—")
        
    except Exception as e:
        print(f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nâœ… Training completed!")
    
    # æœ€çµ‚çµ±è¨ˆ
    if cfg.device.type == 'cuda':
        final_memory = torch.cuda.memory_allocated(0) / 1024**3
        max_memory = torch.cuda.max_memory_allocated(0) / 1024**3
        print(f"ğŸ“Š æœ€çµ‚GPUçµ±è¨ˆ:")
        print(f"   ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory:.2f}GB")
        print(f"   æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {max_memory:.2f}GB")
    
    # å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ¯ å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   Architecture: {architecture_type}")
    print(f"   æœ€çµ‚Loss: {best_loss:.4f}")
    print(f"   æ”¹è‰¯æ‹¡å¼µ: {'ON' if USE_IMPROVED else 'OFF'}")
    print(f"   è¨ºæ–­æ©Ÿèƒ½: ON")
    print(f"   EMAä½¿ç”¨: {'Yes' if getattr(cfg, 'use_ema', True) else 'No'}")
    print(f"   æ¤œè¨¼åˆ†å‰²: {'Yes' if getattr(cfg, 'validation_split', 0.15) > 0 else 'No'}")
    print(f"   ä¿å­˜å…ˆ: {cfg.save_dir}")
    print(f"   è¨ºæ–­ãƒ­ã‚°: {diagnostic_dir}")

if __name__ == "__main__":
    main()