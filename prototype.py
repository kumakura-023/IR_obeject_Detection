#!/usr/bin/env python3
"""
Improved YOLO v1 - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨å­¦ç¿’ç‡èª¿æ•´ã‚’è¿½åŠ 
train_minimal.py ã‹ã‚‰ã®æ”¹å–„ç‚¹ï¼š
1. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆæ˜åº¦èª¿æ•´ã€ãƒã‚¤ã‚ºï¼‰
2. å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
3. æ¤œè¨¼ã‚»ãƒƒãƒˆå¯¾å¿œ
4. ã‚ˆã‚Šè©³ç´°ãªãƒ­ã‚°
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import cv2
import time
import random
from torch.optim.lr_scheduler import CosineAnnealingLR

# ===== verç®¡ç† =====
class VersionTracker:
    """ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ä¿®æ­£å±¥æ­´ã‚’è¿½è·¡"""
    
    def __init__(self, script_name, version="1.0.0"):
        self.script_name = script_name
        self.version = version
        self.load_time = datetime.datetime.now()
        self.modifications = []
        
    def add_modification(self, description, author="AI Assistant"):
        """ä¿®æ­£å±¥æ­´ã‚’è¿½åŠ """
        timestamp = datetime.datetime.now()
        self.modifications.append({
            'timestamp': timestamp,
            'description': description,
            'author': author
        })
        
    def get_file_hash(self, filepath):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œå‡ºç”¨ï¼‰"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()[:8]
        except:
            return "unknown"
    
    def print_version_info(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ {self.script_name} - Version {self.version}")
        print(f"â° Loaded: {self.load_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if hasattr(self, 'file_hash'):
            print(f"ğŸ”— File Hash: {self.file_hash}")
        
        if self.modifications:
            print(f"ğŸ“ Recent Modifications ({len(self.modifications)}):")
            for i, mod in enumerate(self.modifications[-3:], 1):  # æœ€æ–°3ä»¶
                print(f"   {i}. {mod['timestamp'].strftime('%H:%M:%S')} - {mod['description']}")
        
        print(f"{'='*60}\n")

# å„ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’ä½œæˆ
def create_version_tracker(script_name, filepath=None):
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’ä½œæˆ"""
    tracker = VersionTracker(script_name)
    
    if filepath:
        tracker.file_hash = tracker.get_file_hash(filepath)
    
    return tracker

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
training_version = create_version_tracker("Unified Training System v0.1", "prototype.py")
training_version.add_modification("ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")



# ===== è¨­å®š =====
class Config:
    # ãƒ‘ã‚¹
    train_img_dir = "/content/FLIR_YOLO_local/images/train"
    train_label_dir = "/content/FLIR_YOLO_local/labels/train"
    save_dir = "/content/drive/MyDrive/IR_obj_detection/improved_yolo_v1"
    
    # åŸºæœ¬è¨­å®š
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 8  # å°‘ã—å¢—ã‚„ã™
    img_size = 416
    num_classes = 15
    num_epochs = 30  # ã‚ˆã‚Šé•·ã
    
    # å­¦ç¿’è¨­å®š
    learning_rate = 3e-4
    weight_decay = 1e-4
    momentum = 0.9
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
    augment = True
    brightness_range = 0.3
    noise_level = 0.02

# ===== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ‹¡å¼µæ©Ÿèƒ½ä»˜ãï¼‰=====
class ImprovedDataset(Dataset):
    def __init__(self, img_dir, label_dir, img_size=416, augment=False):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_size = img_size
        self.augment = augment
        
        # å…¨ç”»åƒã‚’ä½¿ç”¨
        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
        print(f"Dataset: {len(self.img_files)} images")
        
    def __len__(self):
        return len(self.img_files)
    
    def augment_image(self, img):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ"""
        # æ˜åº¦èª¿æ•´
        if random.random() < 0.5:
            factor = 1 + random.uniform(-Config.brightness_range, Config.brightness_range)
            img = np.clip(img * factor, 0, 1)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º
        if random.random() < 0.3:
            noise = np.random.normal(0, Config.noise_level, img.shape)
            img = np.clip(img + noise, 0, 1)
        
        return img
    
    def __getitem__(self, idx):
        # ç”»åƒèª­ã¿è¾¼ã¿
        img_path = os.path.join(self.img_dir, self.img_files[idx])
        img = cv2.imread(img_path, 0)
        img = cv2.resize(img, (self.img_size, self.img_size))
        img = img.astype(np.float32) / 255.0
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
        if self.augment:
            img = self.augment_image(img)
        
        img = torch.from_numpy(img).float().unsqueeze(0)
        
        # ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿
        label_path = os.path.join(self.label_dir, self.img_files[idx].replace('.jpg', '.txt'))
        targets = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        cls, cx, cy, w, h = map(float, parts)
                        # ç¯„å›²ãƒã‚§ãƒƒã‚¯
                        if 0 <= cls < Config.num_classes and 0 < w < 1 and 0 < h < 1:
                            targets.append([cls, cx, cy, w, h])
        
        return img, torch.tensor(targets) if targets else torch.zeros((0, 5))

# ===== ãƒ¢ãƒ‡ãƒ«ï¼ˆå°‘ã—æ”¹è‰¯ï¼‰=====
class ImprovedYOLO(nn.Module):
    def __init__(self, num_classes=15):
        super().__init__()
        self.num_classes = num_classes
        
        # ã‚ˆã‚Šæ·±ã„Backbone
        self.features = nn.Sequential(
            # 416 -> 208
            self._make_layer(1, 32, stride=2),
            # 208 -> 104
            self._make_layer(32, 64, stride=2),
            # 104 -> 52
            self._make_layer(64, 128, stride=2),
            # 52 -> 26
            self._make_layer(128, 256, stride=2),
            # 26 -> 13
            self._make_layer(256, 512, stride=2),
            # è¿½åŠ ã®ç•³ã¿è¾¼ã¿
            self._make_layer(512, 512, stride=1),
        )
        
        # Detection head
        self.detector = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 5 + num_classes, 1)
        )
        
        # åˆæœŸåŒ–
        self._initialize_weights()
        
    def _make_layer(self, in_channels, out_channels, stride):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride, 1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.1, inplace=True)
        )
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        x = self.features(x)
        x = self.detector(x)
        
        B, C, H, W = x.shape
        x = x.permute(0, 2, 3, 1).contiguous()
        x = x.view(B, H * W, C)
        
        return x, (H, W)

# ===== æå¤±é–¢æ•°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰=====
class ImprovedLoss(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes
        self.lambda_coord = 5.0
        self.lambda_noobj = 0.5
        
    def forward(self, predictions, targets, grid_size):
        B = predictions.size(0)
        H, W = grid_size
        device = predictions.device
        
        # äºˆæ¸¬å€¤ã‚’åˆ†è§£
        pred_xy = predictions[..., :2].sigmoid()
        pred_wh = predictions[..., 2:4]
        pred_conf = predictions[..., 4].sigmoid()
        pred_cls = predictions[..., 5:]
        
        # æå¤±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        losses = {
            'xy': 0, 'wh': 0, 'conf_obj': 0, 'conf_noobj': 0, 'cls': 0,
            'total': 0, 'num_obj': 0, 'num_noobj': 0
        }
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚¹ã‚¯
        obj_mask = torch.zeros(B, H * W, dtype=torch.bool, device=device)
        noobj_mask = torch.ones(B, H * W, dtype=torch.bool, device=device)
        
        # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†
        for b in range(B):
            if len(targets[b]) == 0:
                continue
                
            for t in targets[b]:
                cls_id, cx, cy, w, h = t
                
                # ã‚°ãƒªãƒƒãƒ‰åº§æ¨™
                gx = int(cx * W)
                gy = int(cy * H)
                
                if 0 <= gx < W and 0 <= gy < H:
                    gi = gy * W + gx
                    
                    # ãƒã‚¹ã‚¯æ›´æ–°
                    obj_mask[b, gi] = True
                    noobj_mask[b, gi] = False
                    
                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåº§æ¨™
                    tx = cx * W - gx
                    ty = cy * H - gy
                    tw = torch.log(w * W + 1e-16)
                    th = torch.log(h * H + 1e-16)
                    
                    # åº§æ¨™æå¤±
                    losses['xy'] += F.mse_loss(pred_xy[b, gi], torch.tensor([tx, ty], device=device))
                    losses['wh'] += F.mse_loss(pred_wh[b, gi], torch.tensor([tw, th], device=device))
                    
                    # ã‚¯ãƒ©ã‚¹æå¤±
                    cls_target = F.one_hot(torch.tensor(int(cls_id)), self.num_classes).float().to(device)
                    losses['cls'] += F.cross_entropy(pred_cls[b, gi:gi+1], torch.tensor([int(cls_id)], device=device))
                    
                    losses['num_obj'] += 1
        
        # Confidenceæå¤±
        if obj_mask.any():
            losses['conf_obj'] = F.binary_cross_entropy(pred_conf[obj_mask], torch.ones_like(pred_conf[obj_mask]))
        
        losses['num_noobj'] = noobj_mask.sum().item()
        if noobj_mask.any():
            losses['conf_noobj'] = F.binary_cross_entropy(pred_conf[noobj_mask], torch.zeros_like(pred_conf[noobj_mask]))
        
        # é‡ã¿ä»˜ãåˆè¨ˆ
        num_obj = max(losses['num_obj'], 1)
        losses['total'] = (
            self.lambda_coord * (losses['xy'] + losses['wh']) / num_obj +
            losses['conf_obj'] / num_obj +
            self.lambda_noobj * losses['conf_noobj'] / max(losses['num_noobj'], 1) +
            losses['cls'] / num_obj
        )
        
        return losses

# ===== å­¦ç¿’é–¢æ•° =====
def train_epoch(model, dataloader, criterion, optimizer, epoch, device):
    model.train()
    metrics = defaultdict(float)
    
    for batch_idx, (images, targets) in enumerate(dataloader):
        images = images.to(device)
        
        # Forward
        predictions, grid_size = model(images)
        losses = criterion(predictions, targets, grid_size)
        
        # Backward
        optimizer.zero_grad()
        losses['total'].backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
        optimizer.step()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        for k, v in losses.items():
            if isinstance(v, torch.Tensor):
                metrics[k] += v.item()
            else:
                metrics[k] += v
        
        # é€²æ—è¡¨ç¤º
        if batch_idx % 20 == 0:
            print(f"Epoch [{epoch}] Batch [{batch_idx}/{len(dataloader)}] "
                  f"Loss: {losses['total']:.4f} "
                  f"(xy:{losses['xy']:.3f} wh:{losses['wh']:.3f} "
                  f"conf:{losses['conf_obj']:.3f}/{losses['conf_noobj']:.3f} "
                  f"cls:{losses['cls']:.3f}) "
                  f"Obj: {losses['num_obj']}")
    
    # ã‚¨ãƒãƒƒã‚¯å¹³å‡
    num_batches = len(dataloader)
    for k in metrics:
        metrics[k] /= num_batches
    
    return metrics

# ===== ãƒ¡ã‚¤ãƒ³ =====
def main():
    print("ğŸš€ Starting Improved YOLO Training v1")
    
    cfg = Config()
    os.makedirs(cfg.save_dir, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    print("\nğŸ“Š Loading dataset...")
    train_dataset = ImprovedDataset(cfg.train_img_dir, cfg.train_label_dir, 
                                  cfg.img_size, augment=cfg.augment)
    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, 
                            shuffle=True, num_workers=4, pin_memory=True)
    
    # ãƒ¢ãƒ‡ãƒ«
    print("\nğŸ¤– Creating model...")
    model = ImprovedYOLO(cfg.num_classes).to(cfg.device)
    print(f"Parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # æœ€é©åŒ–
    criterion = ImprovedLoss(cfg.num_classes)
    optimizer = optim.SGD(model.parameters(), lr=cfg.learning_rate, 
                         momentum=cfg.momentum, weight_decay=cfg.weight_decay)
    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    print("\nğŸ¯ Starting training...")
    best_loss = float('inf')
    
    for epoch in range(1, cfg.num_epochs + 1):
        # å­¦ç¿’
        start_time = time.time()
        metrics = train_epoch(model, train_loader, criterion, optimizer, epoch, cfg.device)
        epoch_time = time.time() - start_time
        
        # å­¦ç¿’ç‡æ›´æ–°
        scheduler.step()
        current_lr = scheduler.get_last_lr()[0]
        
        # ãƒ­ã‚°
        print(f"\nğŸ“ˆ Epoch {epoch}/{cfg.num_epochs} - {epoch_time:.1f}s - LR: {current_lr:.6f}")
        print(f"   Loss: {metrics['total']:.4f} "
              f"(xy:{metrics['xy']:.3f} wh:{metrics['wh']:.3f} "
              f"conf:{metrics['conf_obj']:.3f}/{metrics['conf_noobj']:.3f} "
              f"cls:{metrics['cls']:.3f})")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        if metrics['total'] < best_loss:
            best_loss = metrics['total']
            save_path = os.path.join(cfg.save_dir, 'best_model.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': best_loss,
                'config': cfg.__dict__
            }, save_path)
            print(f"ğŸ’¾ Best model saved (loss: {best_loss:.4f})")
        
        # å®šæœŸä¿å­˜
        if epoch % 5 == 0:
            save_path = os.path.join(cfg.save_dir, f'checkpoint_epoch_{epoch}.pth')
            torch.save(model.state_dict(), save_path)
    
    print("\nâœ… Training completed!")

if __name__ == "__main__":
    main()