# unified_training_corrected.py - æœ€æ–°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«å¯¾å¿œ

import os
import gc
import math
import time
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, Optional, Tuple, List
import numpy as np
import torch.nn.functional as F
from collections import defaultdict

# PyTorch AMPã®äº’æ›æ€§è¨­å®š
if torch.__version__ >= '2.0':
    from torch.amp import autocast, GradScaler
    AMP_DEVICE = 'cuda'
else:
    from torch.cuda.amp import autocast, GradScaler
    AMP_DEVICE = None

# ===== ä¿®æ­£: æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«åã§import =====
from dataset import YoloInfraredDataset
from efficientnet_model import create_efficientnet_model
from unified_targets import (
    analyze_dataset_statistics,
    prepare_anchor_grid_info,
    build_targets,
    evaluate_anchor_quality,
    get_default_anchors,
    compare_anchor_sets
)
from unified_loss import create_enhanced_loss


# ===== ãƒ‡ãƒãƒƒã‚°ã‚·ã‚¹ãƒ†ãƒ  =====
class LossDebugTracker:
    """ãƒ­ã‚¹è¨ˆç®—ã®å…¨å·¥ç¨‹ã‚’è¿½è·¡ã™ã‚‹ãƒ‡ãƒãƒƒã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.step_history = []
        self.focal_loss_history = []
        self.target_history = []
        self.prediction_history = []
        self.weight_history = []
        
    def track_step(self, step, batch_idx, epoch, preds, targets, loss_dict, loss_fn):
        """å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°æƒ…å ±ã‚’è¨˜éŒ²"""
        
        debug_info = {
            'step': step,
            'batch_idx': batch_idx,
            'epoch': epoch,
            'timestamp': time.time()
        }
        
        # 1. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†æ
        target_obj = targets['objectness']
        debug_info['target_analysis'] = {
            'total_targets': target_obj.numel(),
            'positive_001': (target_obj > 0.001).sum().item(),
            'positive_01': (target_obj > 0.01).sum().item(),
            'positive_1': (target_obj > 0.1).sum().item(),
            'positive_5': (target_obj > 0.5).sum().item(),
            'max_objectness': target_obj.max().item(),
            'mean_positive': target_obj[target_obj > 0.01].mean().item() if (target_obj > 0.01).any() else 0.0,
            'min_positive': target_obj[target_obj > 0.01].min().item() if (target_obj > 0.01).any() else 0.0
        }
        
        # 2. äºˆæ¸¬åˆ†æ
        pred_obj = preds[..., 4]
        pred_obj_sigmoid = torch.sigmoid(pred_obj)
        debug_info['prediction_analysis'] = {
            'pred_obj_logits_mean': pred_obj.mean().item(),
            'pred_obj_logits_std': pred_obj.std().item(),
            'pred_obj_sigmoid_mean': pred_obj_sigmoid.mean().item(),
            'pred_obj_sigmoid_std': pred_obj_sigmoid.std().item(),
            'pred_obj_sigmoid_max': pred_obj_sigmoid.max().item(),
            'pred_obj_sigmoid_min': pred_obj_sigmoid.min().item()
        }
        
        # 3. ãƒ­ã‚¹é–¢æ•°å†…éƒ¨çŠ¶æ…‹ã®è¿½è·¡
        if hasattr(loss_fn, 'obj_loss_fn') and hasattr(loss_fn.obj_loss_fn, 'gamma'):
            debug_info['focal_loss_state'] = {
                'gamma': getattr(loss_fn.obj_loss_fn, 'gamma', 'N/A'),
                'alpha': getattr(loss_fn.obj_loss_fn, 'alpha', 'N/A'),
                'step_count': getattr(loss_fn.obj_loss_fn, 'step_count', 'N/A'),
                'loss_history_length': len(getattr(loss_fn.obj_loss_fn, 'loss_history', []))
            }
        
        # 4. å‹•çš„é‡ã¿
        if 'dynamic_weights' in loss_dict:
            debug_info['dynamic_weights'] = loss_dict['dynamic_weights']
        
        # 5. ãƒ­ã‚¹å€¤
        debug_info['loss_values'] = {
            'total': loss_dict['total'].item(),
            'box': loss_dict['box'].item(),
            'obj': loss_dict['obj'].item(),
            'cls': loss_dict['cls'].item(),
            'pos_samples': loss_dict['pos_samples']
        }
        
        # 6. æ‰‹å‹•ãƒ­ã‚¹è¨ˆç®—ï¼ˆæ¤œè¨¼ç”¨ï¼‰
        debug_info['manual_loss_check'] = self._manual_loss_calculation(preds, targets, loss_fn)
        
        self.step_history.append(debug_info)
        
        # ç•°å¸¸æ¤œå‡º
        if step > 5:  # æœ€åˆã®æ•°ã‚¹ãƒ†ãƒƒãƒ—ã¯ã‚¹ã‚­ãƒƒãƒ—
            self._detect_anomalies(debug_info, step)
    
    def _manual_loss_calculation(self, preds, targets, loss_fn):
        """æ‰‹å‹•ã§ãƒ­ã‚¹è¨ˆç®—ã‚’å®Ÿè¡Œã—ã¦æ¤œè¨¼"""
        try:
            device = preds.device
            pred_obj = preds[..., 4]
            target_obj = targets['objectness']
            
            # AdaptiveFocalLossã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            if hasattr(loss_fn, 'obj_loss_fn'):
                obj_loss_fn = loss_fn.obj_loss_fn
                alpha = getattr(obj_loss_fn, 'alpha', 0.75)
                gamma = getattr(obj_loss_fn, 'gamma', 1.5)
            else:
                alpha, gamma = 0.75, 1.5
            
            # ãƒã‚¤ãƒŠãƒªã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆï¼ˆloss_fn ã®å‡¦ç†ã‚’æ¨¡å€£ï¼‰
            obj_target_for_loss = target_obj.clone()
            obj_target_for_loss = torch.where(
                obj_target_for_loss > 0.01,
                obj_target_for_loss,
                torch.zeros_like(obj_target_for_loss)
            )
            obj_target_binary = (obj_target_for_loss > 0.3).float()
            
            # æ‰‹å‹•BCEè¨ˆç®—
            bce_loss = F.binary_cross_entropy_with_logits(pred_obj, obj_target_binary, reduction='none')
            
            # æ‰‹å‹•Focal Lossè¨ˆç®—
            probs = torch.sigmoid(pred_obj)
            pt = torch.where(obj_target_binary == 1, probs, 1 - probs)
            alpha_t = torch.where(obj_target_binary == 1, alpha, 1 - alpha)
            focal_loss = alpha_t * (1 - pt) ** gamma * bce_loss
            
            return {
                'binary_targets_sum': obj_target_binary.sum().item(),
                'manual_bce_mean': bce_loss.mean().item(),
                'manual_focal_mean': focal_loss.mean().item(),
                'pt_mean': pt.mean().item(),
                'alpha_t_mean': alpha_t.mean().item(),
                'gamma_used': gamma,
                'alpha_used': alpha
            }
        except Exception as e:
            return {'error': str(e)}
    
    def _detect_anomalies(self, current_info, step):
        """ç•°å¸¸å€¤ã‚’æ¤œå‡ºã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆ"""
        current_obj_loss = current_info['loss_values']['obj']
        
        # éå»5ã‚¹ãƒ†ãƒƒãƒ—ã®å¹³å‡ã¨æ¯”è¼ƒ
        if len(self.step_history) >= 5:
            recent_obj_losses = [info['loss_values']['obj'] for info in self.step_history[-5:]]
            avg_recent = sum(recent_obj_losses) / len(recent_obj_losses)
            
            # æ€¥æ¿€ãªæ¸›å°‘ã‚’æ¤œå‡º
            if current_obj_loss < avg_recent * 0.1 and current_obj_loss < 0.01:
                print(f"\nğŸš¨ ANOMALY DETECTED at Step {step}!")
                print(f"   Obj Loss dropped from {avg_recent:.6f} to {current_obj_loss:.6f}")
                print(f"   Investigating cause...")
                
                self._investigate_cause(current_info, step)
    
    def _investigate_cause(self, current_info, step):
        """ç•°å¸¸ã®åŸå› ã‚’èª¿æŸ»"""
        print(f"\nğŸ” INVESTIGATING ANOMALY at Step {step}:")
        
        # 1. Focal Loss ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if 'focal_loss_state' in current_info:
            focal_state = current_info['focal_loss_state']
            print(f"   Focal Loss State:")
            print(f"     Gamma: {focal_state.get('gamma', 'N/A')}")
            print(f"     Alpha: {focal_state.get('alpha', 'N/A')}")
            print(f"     Step Count: {focal_state.get('step_count', 'N/A')}")
        
        # 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰åŒ–ãƒã‚§ãƒƒã‚¯
        target_analysis = current_info['target_analysis']
        print(f"   Target Analysis:")
        print(f"     Positive targets (>0.01): {target_analysis['positive_01']}")
        print(f"     Mean positive objectness: {target_analysis['mean_positive']:.6f}")
        
        # 3. æ‰‹å‹•è¨ˆç®—ã¨ã®æ¯”è¼ƒ
        if 'manual_loss_check' in current_info:
            manual = current_info['manual_loss_check']
            if 'error' not in manual:
                actual_obj_loss = current_info['loss_values']['obj']
                manual_focal_loss = manual['manual_focal_mean']
                print(f"   Manual vs Actual Loss:")
                print(f"     Manual Focal: {manual_focal_loss:.6f}")
                print(f"     Actual Obj: {actual_obj_loss:.6f}")
                print(f"     Difference: {abs(manual_focal_loss - actual_obj_loss):.6f}")
                print(f"     Binary targets: {manual['binary_targets_sum']}")
                print(f"     Gamma used: {manual['gamma_used']}")
        
        # 4. å‹•çš„é‡ã¿ãƒã‚§ãƒƒã‚¯
        if 'dynamic_weights' in current_info:
            weights = current_info['dynamic_weights']
            print(f"   Dynamic Weights:")
            print(f"     Box: {weights['box']:.2f}, Obj: {weights['obj']:.2f}, Cls: {weights['cls']:.2f}")
    
    def save_debug_log(self, filename="loss_debug_log.json"):
        """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’ä¿å­˜"""
        try:
            # NumPy/Tensorã‚’é€šå¸¸ã®Pythonå‹ã«å¤‰æ›
            json_safe_log = []
            for entry in self.step_history:
                safe_entry = {}
                for key, value in entry.items():
                    if isinstance(value, dict):
                        safe_entry[key] = {k: float(v) if isinstance(v, (torch.Tensor, float)) else v 
                                         for k, v in value.items()}
                    else:
                        safe_entry[key] = float(value) if isinstance(value, (torch.Tensor, float)) else value
                json_safe_log.append(safe_entry)
            
            with open(filename, 'w') as f:
                json.dump(json_safe_log, f, indent=2)
            print(f"ğŸ“ Debug log saved to {filename}")
        except Exception as e:
            print(f"âš ï¸ Failed to save debug log: {e}")
    
    def print_summary(self):
        """ãƒ‡ãƒãƒƒã‚°ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        if len(self.step_history) == 0:
            return
        
        print(f"\nğŸ“Š LOSS DEBUG SUMMARY ({len(self.step_history)} steps tracked)")
        
        # Obj Lossã®æ¨ç§»
        obj_losses = [info['loss_values']['obj'] for info in self.step_history]
        print(f"   Obj Loss: {obj_losses[0]:.6f} â†’ {obj_losses[-1]:.6f}")
        
        # æœ€å¤§å€¤ã¨æœ€å°å€¤
        max_obj = max(obj_losses)
        min_obj = min(obj_losses)
        print(f"   Range: {min_obj:.6f} - {max_obj:.6f}")
        
        # æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡º
        for i in range(1, len(obj_losses)):
            if obj_losses[i] < obj_losses[i-1] * 0.1 and obj_losses[i] < 0.01:
                print(f"   ğŸš¨ Sharp drop detected at step {self.step_history[i]['step']}")
                break

def check_for_nan_gradients(model, step):
    """ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®å‹¾é…ã«NaNãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹"""
    nan_found = False
    for name, param in model.named_parameters():
        if param.grad is not None and torch.isnan(param.grad).any():
            print(f"ğŸš¨ğŸš¨ğŸš¨ NaN GRADIENT DETECTED IN ==> {name} at step {step}")
            nan_found = True
    if nan_found:
        # NaNãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€ãƒ‡ãƒãƒƒã‚¬ã‚’èµ·å‹•ã™ã‚‹ï¼ˆColabã§æœ‰åŠ¹ï¼‰
        import pdb; pdb.set_trace()
    return nan_found

class RootCauseInvestigator:
    """äºˆæ¸¬å€¤å´©å£Šã®æ ¹æœ¬åŸå› ã‚’èª¿æŸ»"""
    
    def __init__(self):
        self.weight_history = []
        self.gradient_history = []
        self.activation_history = []
        self.loss_component_history = []
        
    def investigate_prediction_collapse(self, model, preds, targets, loss_dict, 
                                      optimizer, step, batch_idx):
        """äºˆæ¸¬å€¤å´©å£Šã®æ ¹æœ¬åŸå› ã‚’èª¿æŸ»"""
        
        print(f"\nğŸ”¬ [ROOT CAUSE INVESTIGATION] Step {step}, Batch {batch_idx}")
        
        # 1. ãƒ¢ãƒ‡ãƒ«é‡ã¿ã®ç•°å¸¸èª¿æŸ»
        self._investigate_model_weights(model, step)
        
        # 2. å‹¾é…ã®ç•°å¸¸èª¿æŸ»
        self._investigate_gradients(model, step)
        
        # 3. ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³èª¿æŸ»
        self._investigate_activations(model, preds, step)
        
        # 4. ãƒ­ã‚¹æˆåˆ†ã®å¯„ä¸åº¦èª¿æŸ»
        self._investigate_loss_components(preds, targets, loss_dict, step)
    
    def _investigate_model_weights(self, model, step):
        """ãƒ¢ãƒ‡ãƒ«é‡ã¿ã®ç•°å¸¸ã‚’èª¿æŸ»"""
        print("   ğŸ” Model Weights Analysis:")
        
        # Detection Headã®é‡ã¿ï¼ˆæœ€ã‚‚å½±éŸ¿ãŒå¤§ãã„ï¼‰
        detection_head = model.head.detection_head
        weight_data = detection_head.weight.data
        bias_data = detection_head.bias.data if detection_head.bias is not None else None
        
        # Objectnesså‡ºåŠ›ã«å¯¾å¿œã™ã‚‹é‡ã¿ï¼ˆchannel 4ï¼‰
        # detection_head: [num_anchors * (5+num_classes), in_channels, 1, 1]
        num_anchors = 3
        num_classes = 15
        outputs_per_anchor = 5 + num_classes  # 20
        
        obj_weight_indices = []
        for anchor_idx in range(num_anchors):
            obj_idx = anchor_idx * outputs_per_anchor + 4  # objectnessä½ç½®
            obj_weight_indices.append(obj_idx)
        
        obj_weights = weight_data[obj_weight_indices]  # [3, 256, 1, 1]
        obj_biases = bias_data[obj_weight_indices] if bias_data is not None else None
        
        weight_stats = {
            'obj_weight_mean': obj_weights.mean().item(),
            'obj_weight_std': obj_weights.std().item(),
            'obj_weight_max': obj_weights.max().item(),
            'obj_weight_min': obj_weights.min().item(),
            'obj_bias_mean': obj_biases.mean().item() if obj_biases is not None else 0.0,
            'obj_bias_std': obj_biases.std().item() if obj_biases is not None else 0.0
        }
        
        self.weight_history.append({'step': step, **weight_stats})
        
        print(f"     Obj weights: mean={weight_stats['obj_weight_mean']:.6f}, "
              f"std={weight_stats['obj_weight_std']:.6f}")
        print(f"     Obj biases: mean={weight_stats['obj_bias_mean']:.6f}, "
              f"std={weight_stats['obj_bias_std']:.6f}")
        
        # ç•°å¸¸æ¤œå‡º
        if abs(weight_stats['obj_weight_mean']) > 10.0:
            print(f"     ğŸš¨ WEIGHT EXPLOSION: obj_weight_mean = {weight_stats['obj_weight_mean']:.6f}")
        elif abs(weight_stats['obj_weight_mean']) < 1e-6:
            print(f"     ğŸš¨ WEIGHT VANISHING: obj_weight_mean = {weight_stats['obj_weight_mean']:.6f}")
        
        if abs(weight_stats['obj_bias_mean']) > 50.0:
            print(f"     ğŸš¨ BIAS EXPLOSION: obj_bias_mean = {weight_stats['obj_bias_mean']:.6f}")
        elif abs(weight_stats['obj_bias_mean']) < -50.0:
            print(f"     ğŸš¨ LARGE NEGATIVE BIAS: obj_bias_mean = {weight_stats['obj_bias_mean']:.6f}")
            print(f"       â†’ This could cause sigmoid collapse!")
    
    def _investigate_gradients(self, model, step):
        """å‹¾é…ã®ç•°å¸¸ã‚’èª¿æŸ»"""
        print("   ğŸ” Gradient Analysis:")
        
        detection_head = model.head.detection_head
        if detection_head.weight.grad is not None:
            grad_data = detection_head.weight.grad.data
            
            # Objectnesså‹¾é…
            num_anchors = 3
            num_classes = 15
            outputs_per_anchor = 5 + num_classes
            
            obj_grad_indices = []
            for anchor_idx in range(num_anchors):
                obj_idx = anchor_idx * outputs_per_anchor + 4
                obj_grad_indices.append(obj_idx)
            
            obj_grads = grad_data[obj_grad_indices]
            
            grad_stats = {
                'obj_grad_mean': obj_grads.mean().item(),
                'obj_grad_std': obj_grads.std().item(),
                'obj_grad_max': obj_grads.max().item(),
                'obj_grad_min': obj_grads.min().item(),
                'obj_grad_norm': obj_grads.norm().item()
            }
            
            self.gradient_history.append({'step': step, **grad_stats})
            
            print(f"     Obj gradients: mean={grad_stats['obj_grad_mean']:.6f}, "
                  f"norm={grad_stats['obj_grad_norm']:.6f}")
            
            # å‹¾é…ç•°å¸¸æ¤œå‡º
            if grad_stats['obj_grad_norm'] > 100.0:
                print(f"     ğŸš¨ GRADIENT EXPLOSION: norm = {grad_stats['obj_grad_norm']:.6f}")
            elif grad_stats['obj_grad_norm'] < 1e-8:
                print(f"     ğŸš¨ GRADIENT VANISHING: norm = {grad_stats['obj_grad_norm']:.6f}")
        else:
            print("     âš ï¸ No gradients found (may be due to gradient accumulation)")
    
    def _investigate_activations(self, model, preds, step):
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³èª¿æŸ»"""
        print("   ğŸ” Activation Analysis:")
        
        # Objectness logits (sigmoidé©ç”¨å‰)
        obj_logits = preds[..., 4]  # [B, N]
        
        activation_stats = {
            'obj_logits_mean': obj_logits.mean().item(),
            'obj_logits_std': obj_logits.std().item(),
            'obj_logits_max': obj_logits.max().item(),
            'obj_logits_min': obj_logits.min().item(),
            'obj_logits_median': obj_logits.median().item()
        }
        
        self.activation_history.append({'step': step, **activation_stats})
        
        print(f"     Obj logits: mean={activation_stats['obj_logits_mean']:.6f}, "
              f"min={activation_stats['obj_logits_min']:.6f}, "
              f"max={activation_stats['obj_logits_max']:.6f}")
        
        # Sigmoidå´©å£Šã®åˆ¤å®š
        if activation_stats['obj_logits_max'] < -10.0:
            print(f"     ğŸš¨ SIGMOID SATURATION (negative): max_logit = {activation_stats['obj_logits_max']:.6f}")
            print(f"       â†’ sigmoid({activation_stats['obj_logits_max']:.2f}) â‰ˆ {torch.sigmoid(torch.tensor(activation_stats['obj_logits_max'])).item():.8f}")
        elif activation_stats['obj_logits_min'] > 10.0:
            print(f"     ğŸš¨ SIGMOID SATURATION (positive): min_logit = {activation_stats['obj_logits_min']:.6f}")
    
    def _investigate_loss_components(self, preds, targets, loss_dict, step):
        """ãƒ­ã‚¹æˆåˆ†ã®å¯„ä¸åº¦èª¿æŸ»"""
        print("   ğŸ” Loss Component Analysis:")
        
        # å„ãƒ­ã‚¹æˆåˆ†ã®å¤§ãã•
        total_loss = loss_dict['total'].item()
        box_loss = loss_dict['box'].item()
        obj_loss = loss_dict['obj'].item()
        cls_loss = loss_dict['cls'].item()
        
        # é‡ã¿ä»˜ãå¯„ä¸åº¦
        if 'dynamic_weights' in loss_dict:
            weights = loss_dict['dynamic_weights']
            w_box, w_obj, w_cls = weights['box'], weights['obj'], weights['cls']
            
            weighted_box = w_box * box_loss
            weighted_obj = w_obj * obj_loss
            weighted_cls = w_cls * cls_loss
            
            total_weighted = weighted_box + weighted_obj + weighted_cls
            
            if total_weighted > 0:
                box_contribution = weighted_box / total_weighted
                obj_contribution = weighted_obj / total_weighted
                cls_contribution = weighted_cls / total_weighted
                
                print(f"     Loss contributions:")
                print(f"       Box: {box_contribution:.3f} ({weighted_box:.6f})")
                print(f"       Obj: {obj_contribution:.3f} ({weighted_obj:.6f})")
                print(f"       Cls: {cls_contribution:.3f} ({weighted_cls:.6f})")
                
                # ç•°å¸¸å¯„ä¸åº¦æ¤œå‡º
                if obj_contribution > 0.8:
                    print(f"     ğŸš¨ OBJ LOSS DOMINANCE: {obj_contribution:.3f}")
                    print(f"       â†’ Objectness loss is overwhelming other components")
                elif obj_contribution < 0.05:
                    print(f"     ğŸš¨ OBJ LOSS TOO WEAK: {obj_contribution:.3f}")


# ===== ä¿®æ­£ã•ã‚ŒãŸãƒ‡ãƒãƒƒã‚°é–¢æ•° =====
def debug_loss_calculation_comprehensive(preds, targets, loss_fn, model, optimizer, 
                                       batch_idx, epoch, tracker: LossDebugTracker, 
                                       step_count, root_investigator: RootCauseInvestigator):
    """åŒ…æ‹¬çš„ãƒ­ã‚¹è¨ˆç®—ãƒ‡ãƒãƒƒã‚° - ä¿®æ­£ç‰ˆ"""
    
    # 1. é€šå¸¸ã®ãƒ­ã‚¹è¨ˆç®—ã‚’å®Ÿè¡Œ
    loss_dict = loss_fn(preds, targets)
    
    # 2. ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã«è¨˜éŒ²
    tracker.track_step(step_count, batch_idx, epoch, preds, targets, loss_dict, loss_fn)
    
    # 3. äºˆæ¸¬å€¤ç•°å¸¸æ™‚ã«æ ¹æœ¬åŸå› èª¿æŸ»
    pred_obj_sigmoid = torch.sigmoid(preds[..., 4])
    sigmoid_mean = pred_obj_sigmoid.mean().item()
    
    if sigmoid_mean < 0.001 or step_count in [0, 1, 2, 10, 20]:  # ç•°å¸¸æ™‚ + ç‰¹å®šã‚¹ãƒ†ãƒƒãƒ—
        root_investigator.investigate_prediction_collapse(
            model, preds, targets, loss_dict, optimizer, step_count, batch_idx
        )
    
    # 4. æœ€åˆã®æ•°ã‚¹ãƒ†ãƒƒãƒ—ã¨ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§ã®è©³ç´°å‡ºåŠ›
    if step_count <= 3 or (batch_idx in [10, 20, 30] and epoch == 0):
        print(f"\nğŸ”¬ [COMPREHENSIVE DEBUG] Step {step_count}, Batch {batch_idx}")
        
        # ç›´å‰ã®è¨˜éŒ²ã‚’è¡¨ç¤º
        if tracker.step_history:
            latest = tracker.step_history[-1]
            
            print(f"   Target Summary:")
            target_info = latest['target_analysis']
            print(f"     Positive (>0.01): {target_info['positive_01']}")
            print(f"     Positive (>0.1): {target_info['positive_1']}")
            print(f"     Mean positive: {target_info['mean_positive']:.6f}")
            
            print(f"   Prediction Summary:")
            pred_info = latest['prediction_analysis']
            print(f"     Sigmoid mean: {pred_info['pred_obj_sigmoid_mean']:.6f}")
            print(f"     Sigmoid std: {pred_info['pred_obj_sigmoid_std']:.6f}")
            
            if 'focal_loss_state' in latest:
                focal_info = latest['focal_loss_state']
                print(f"   Focal Loss State:")
                print(f"     Gamma: {focal_info['gamma']}")
                print(f"     Alpha: {focal_info['alpha']}")
                print(f"     Internal step: {focal_info['step_count']}")
            
            print(f"   Loss Values:")
            loss_info = latest['loss_values']
            print(f"     Total: {loss_info['total']:.6f}")
            print(f"     Box: {loss_info['box']:.6f}")
            print(f"     Obj: {loss_info['obj']:.6f}")
            print(f"     Cls: {loss_info['cls']:.6f}")
            
            if 'manual_loss_check' in latest and 'error' not in latest['manual_loss_check']:
                manual_info = latest['manual_loss_check']
                print(f"   Manual Check:")
                print(f"     Manual focal: {manual_info['manual_focal_mean']:.6f}")
                print(f"     Difference: {abs(manual_info['manual_focal_mean'] - loss_info['obj']):.6f}")
    
    return loss_dict


# ===== æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ï¼ˆunified_training_gm.pyã‹ã‚‰ï¼‰ =====
class TrainingConfig:
    """å­¦ç¿’è¨­å®šã‚’ä¸€å…ƒç®¡ç†"""
    def __init__(self):
        # åŸºæœ¬è¨­å®š
        self.batch_size = 20
        self.num_classes = 15
        self.epochs = 30
        self.input_size = (640, 512)  # (W, H)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # å­¦ç¿’ç‡è¨­å®š
        self.initial_lr = 1e-3
        self.max_lr = 1e-3
        self.min_lr = 1e-6
        self.warmup_steps = 500  # <<< ã“ã®è¡Œã‚’è¿½åŠ ã—ã¦ãã ã•ã„

        # Lossé‡ã¿ï¼ˆåˆæœŸå€¤ï¼‰
        self.loss_weights = {
            'box': 5.0,
            'obj': 2.0,
            'cls': 1.0
        }
        
        # Gradient Accumulation
        self.accumulation_steps = 4
        self.effective_batch_size = self.batch_size * self.accumulation_steps
        
        # ãƒ‘ã‚¹è¨­å®š
        self.project_root = "/content/drive/MyDrive/EfficientNet_Project"
        self.train_img_dir = "/content/FLIR_YOLO_local/images/train"
        self.train_label_dir = "/content/FLIR_YOLO_local/labels/train"
        self.model_save_path = os.path.join(self.project_root, "saved_models")
        os.makedirs(self.model_save_path, exist_ok=True)
        
        # é€²æ—è¡¨ç¤ºè¨­å®š
        self.progress_interval = 10
        self.memory_check_interval = 50
        
        # ã‚¢ãƒ³ã‚«ãƒ¼è¨­å®š
        self.anchor_threshold = 0.2  # IoUé–¾å€¤
        self.num_anchors = 9  # ç·ã‚¢ãƒ³ã‚«ãƒ¼æ•°


class WarmRestartScheduler:
    """Cosine Annealing with Warm Restarts"""
    def __init__(self, optimizer, T_0=10, T_mult=2, eta_min=1e-6, verbose=True):
        self.optimizer = optimizer
        self.T_0 = T_0
        self.T_mult = T_mult
        self.eta_min = eta_min
        self.eta_max = optimizer.param_groups[0]['lr']
        self.verbose = verbose
        
        self.T_cur = 0
        self.T_i = T_0
        self.restart_count = 0
        self.total_steps = 0
        
        self._set_lr(self.eta_max)
    
    def _set_lr(self, lr):
        """ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å­¦ç¿’ç‡ã‚’è¨­å®š"""
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
    
    def get_lr(self):
        lr = self.eta_min + (self.eta_max - self.eta_min) * \
             (1 + math.cos(math.pi * self.T_cur / self.T_i)) / 2
        return lr
    
    def step(self):
        self.total_steps += 1
        self.T_cur += 1
        
        new_lr = self.get_lr()
        self._set_lr(new_lr)
        
        if self.T_cur >= self.T_i:
            self.restart_count += 1
            if self.verbose:
                print(f"\nğŸ”„ Learning rate warm restart #{self.restart_count}")
                print(f"   Next cycle: {int(self.T_i * self.T_mult)} steps")
            
            self.T_cur = 0
            self.T_i = int(self.T_i * self.T_mult)
        
        return new_lr


def get_memory_usage() -> Dict[str, float]:
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    memory_info = {}
    
    if torch.cuda.is_available():
        memory_info['gpu_allocated'] = torch.cuda.memory_allocated() / 1024**3
        memory_info['gpu_reserved'] = torch.cuda.memory_reserved() / 1024**3
    
    memory_info['cpu_percent'] = 0.0  # psutilãªã—ã§ã‚·ãƒ³ãƒ—ãƒ«ã«
    
    return memory_info


def progressive_unfreezing(model: nn.Module, epoch: int) -> str:
    """æ®µéšçš„ãƒ¬ã‚¤ãƒ¤ãƒ¼è§£å‡"""
    total_layers = len(list(model.backbone.parameters()))
    
    if epoch < 3:
        # Stage 1: Backboneå®Œå…¨å‡çµ
        for param in model.backbone.parameters():
            param.requires_grad = False
        stage = "Head+Neck Only"
    elif epoch < 8:
        # Stage 2: å¾ŒåŠ50%ã‚’è§£å‡
        for i, param in enumerate(model.backbone.parameters()):
            param.requires_grad = i >= total_layers // 2
        stage = "Backbone 50% + Head+Neck"
    elif epoch < 15:
        # Stage 3: å¾ŒåŠ75%ã‚’è§£å‡
        for i, param in enumerate(model.backbone.parameters()):
            param.requires_grad = i >= total_layers // 4
        stage = "Backbone 75% + Head+Neck"
    else:
        # Stage 4: å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼è§£å‡
        for param in model.backbone.parameters():
            param.requires_grad = True
        stage = "Full Model"
    
    # Neck/Headã¯å¸¸ã«å­¦ç¿’å¯èƒ½
    for param in model.neck.parameters():
        param.requires_grad = True
    for param in model.head.parameters():
        param.requires_grad = True
    
    return stage


def collate_fn(batch):
    """DataLoaderç”¨ã®collateé–¢æ•°"""
    return tuple(zip(*batch))


# ===== ãƒ¡ã‚¤ãƒ³å­¦ç¿’é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰ =====
def main():
    # è¨­å®šåˆæœŸåŒ–
    config = TrainingConfig()
    print("ğŸš€ Starting Unified EfficientNet Training with Comprehensive Debug")
    print(f"ğŸ“± Device: {config.device}")
    print(f"ğŸ¯ Target: {config.num_classes} classes")
    print(f"ğŸ“ Input size: {config.input_size}")
    print("ver 1.3-gemini - Corrected for Latest Project Structure")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    from efficientnet_model import test_model_creation

    model = test_model_creation()
    if model:
        print("âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸï¼")
    else:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ä½œæˆå¤±æ•—")

    # === ãƒ‡ãƒãƒƒã‚°ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ– ===
    debug_tracker = LossDebugTracker()
    root_investigator = RootCauseInvestigator()
    step_counter = 0
    
    # â˜…â˜…â˜…ã€æœ€çµ‚åˆ‡ã‚Šåˆ†ã‘å®Ÿé¨“ã€‘AMPã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ â˜…â˜…â˜…
    use_amp = False  # torch.cuda.is_available() ã‹ã‚‰ False ã«å¤‰æ›´
    print("--- âš ï¸ã€è¨ºæ–­ãƒ¢ãƒ¼ãƒ‰ã€‘AMPï¼ˆè‡ªå‹•æ··åˆç²¾åº¦è¨ˆç®—ï¼‰ã‚’ç„¡åŠ¹åŒ–ã—ã¦å®Ÿè¡Œã—ã¾ã™ ---")

    # AMPè¨­å®š
    use_amp = torch.cuda.is_available()
    if use_amp:
        if AMP_DEVICE:
            scaler = GradScaler(AMP_DEVICE)
        else:
            scaler = GradScaler()
    else:
        scaler = None
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    print("\n=== ğŸ“š Dataset Loading ===")
    train_dataset = YoloInfraredDataset(
        image_dir=config.train_img_dir,
        label_dir=config.train_label_dir,
        input_size=config.input_size,
        num_classes=config.num_classes
    )
    
    print(f"âœ… Dataset: {len(train_dataset)} samples")
    
    # ã‚¢ãƒ³ã‚«ãƒ¼æœ€é©åŒ–
    print("\n=== ğŸ¯ Anchor Optimization ===")
    
    default_anchors = get_default_anchors()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†æã¨ã‚¢ãƒ³ã‚«ãƒ¼æœ€é©åŒ–
        optimized_anchors_pixel, class_dist, stats = analyze_dataset_statistics(
            train_dataset,
            num_samples=1000,
            input_size=config.input_size
        )
        
        if optimized_anchors_pixel is None:
            print("âš ï¸ Using default anchors")
            optimized_anchors_pixel = default_anchors
        else:
            print("âœ… Anchor optimization completed")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã®æ¯”è¼ƒ
            print("\n=== ğŸ“Š Anchor Comparison ===")
            comparison = compare_anchor_sets(
                train_dataset,
                default_anchors,
                optimized_anchors_pixel,
                num_samples=500,
                input_size=config.input_size
            )
            
    except Exception as e:
        print(f"âš ï¸ Anchor optimization failed: {e}")
        print("   Using default anchors")
        optimized_anchors_pixel = default_anchors
    
    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=2,
        pin_memory=True
    )
    
    print(f"ğŸ“¦ Batches per epoch: {len(train_loader)}")
    
    # é€²æ—è¡¨ç¤ºé–“éš”ã®èª¿æ•´
    if len(train_loader) < config.progress_interval:
        print(f"âš ï¸ Only {len(train_loader)} batches, adjusting progress interval to 1")
        config.progress_interval = 1
    else:
        print(f"ğŸ“Š Progress will be shown every {config.progress_interval} batches")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("\n=== ğŸ¤– Model Initialization ===")
    model = create_efficientnet_model(
        num_classes=config.num_classes,
        pretrained=True
    ).to(config.device)
    
    # ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºæ¤œå‡º
    print("\n=== ğŸ” Grid Size Detection ===")
    model.eval()
    with torch.no_grad():
        test_input = torch.randn(1, 1, *config.input_size[::-1]).to(config.device)
        feat1, feat2, feat3 = model.backbone(test_input)
        p1, p2, p3 = model.neck(feat1, feat2, feat3)
        grid_sizes = [
            (p1.shape[2], p1.shape[3]),
            (p2.shape[2], p2.shape[3]),
            (p3.shape[2], p3.shape[3])
        ]
    model.train()
    print(f"ğŸ“ Grid sizes: {grid_sizes}")
    
    # ã‚¢ãƒ³ã‚«ãƒ¼ãƒ»ã‚°ãƒªãƒƒãƒ‰æƒ…å ±æº–å‚™
    anchor_grid_info = prepare_anchor_grid_info(
        anchors_pixel_per_level=optimized_anchors_pixel,
        model_grid_sizes=grid_sizes,
        input_size_wh=config.input_size
    )
    
    # Lossé–¢æ•°åˆæœŸåŒ–
    print("\n=== ğŸ¯ Loss Function Setup ===")
    loss_fn = create_enhanced_loss(
        num_classes=config.num_classes,
        loss_strategy='balanced',  # unified_loss.pyã®æˆ¦ç•¥ã‚’ä½¿ç”¨
        anchor_info=anchor_grid_info
    )
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
    print("\n=== âš™ï¸ Optimizer Setup ===")
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.initial_lr,
        weight_decay=0.01,
        betas=(0.9, 0.999)
    )
    
    batches_per_optimizer_step = len(train_loader) // config.accumulation_steps
    scheduler = WarmRestartScheduler(
        optimizer=optimizer,
        T_0=batches_per_optimizer_step * 2,  # 2ã‚¨ãƒãƒƒã‚¯ç›¸å½“
        T_mult=1.5,
        eta_min=config.min_lr,
        verbose=True
    )
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    print(f"\nğŸ¬ Training Started with Debug System!")
    best_box_loss = float('inf')
    best_obj_loss = 0.0
    
    for epoch in range(config.epochs):
        epoch_start_time = time.time()
        epoch_losses = {"total": [], "box": [], "obj": [], "cls": []}
        
        # æ®µéšçš„è§£å‡
        unfreezing_stage = progressive_unfreezing(model, epoch)
        
        print(f"\nğŸ¯ Epoch {epoch+1}/{config.epochs}")
        print(f"ğŸ§Š Stage: {unfreezing_stage}")
        
        # Gradient Accumulationç”¨
        accumulated_loss = 0.0
        optimizer.zero_grad()
        
        for batch_idx, (images, targets) in enumerate(train_loader):
            if len(images) == 0:
                continue
            
            try:
                # ãƒãƒƒãƒæº–å‚™
                images = torch.stack(images).to(config.device, non_blocking=True)
                targets = [t.to(config.device, non_blocking=True) for t in targets]
                
                # Forward pass
                if AMP_DEVICE:
                    # PyTorch 2.0ä»¥é™
                    with autocast(AMP_DEVICE, enabled=use_amp):
                        preds = model(images)
                else:
                    # PyTorch 1.x
                    with autocast(enabled=use_amp):
                        preds = model(images)
                
                # ===== ä¿®æ­£éƒ¨åˆ†: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ§‹ç¯‰ã‚’å…ˆã«å®Ÿè¡Œ =====
                target_dict = build_targets(
                    targets=targets,
                    anchors_pixel_per_level=anchor_grid_info['anchors_pixel_per_level'],
                    strides_per_level=anchor_grid_info['strides_per_level'],
                    grid_sizes=grid_sizes,
                    input_size=config.input_size,
                    num_classes=config.num_classes,
                    device=config.device,
                    anchor_threshold=config.anchor_threshold
                )
                
                # ===== ä¿®æ­£éƒ¨åˆ†: ãƒ‡ãƒãƒƒã‚°é–¢æ•°ã«target_dictã‚’æ¸¡ã™ =====
                loss_dict = debug_loss_calculation_comprehensive(
                    preds, target_dict, loss_fn, model, optimizer, 
                    batch_idx, epoch, debug_tracker, step_counter, root_investigator
                )
                
                # Gradient Accumulation
                loss = loss_dict["total"] / config.accumulation_steps
                accumulated_loss += loss.item()
                
                # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›1: backwardç›´å‰ã®lossã®å€¤ â˜…â˜…â˜…
                print(f"--- Step {step_counter} | Loss before backward: {loss.item():.6f} ---")

                # Backward pass
                if scaler:
                    scaler.scale(loss).backward()
                else:
                    loss.backward()

                # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›2: backwardç›´å¾Œã®å‹¾é…ã‚’ãƒã‚§ãƒƒã‚¯ â˜…â˜…â˜…
                if check_for_nan_gradients(model, step_counter):
                    print("!!! TRAINING HALTED DUE TO NaN GRADIENT !!!")
                    return # NaNãŒè¦‹ã¤ã‹ã£ãŸã‚‰å­¦ç¿’ã‚’åœæ­¢
                
                # Gradient Step
                if (batch_idx + 1) % config.accumulation_steps == 0:

                    # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚° (å€¤ã‚’1.0ã«èª¿æ•´ã—ã€å®‰å®šæ€§ã‚’å‘ä¸Š)
                    if scaler:
                        scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚¹ãƒ†ãƒƒãƒ—
                    if scaler:
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        optimizer.step()
                    
                    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—ã‚„ã™ (æ­£ã—ã„å ´æ‰€ã«ç§»å‹•)
                    step_counter += 1

                    # å­¦ç¿’ç‡ã®æ›´æ–° (å®‰å®šã—ãŸã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©)
                    current_lr = 0.0
                    if step_counter < config.warmup_steps:
                        # ç·šå½¢ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
                        lr_scale = (step_counter + 1) / config.warmup_steps
                        current_lr = config.initial_lr * lr_scale
                        for g in optimizer.param_groups:
                            g['lr'] = current_lr
                    else:
                        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’é©ç”¨
                        current_lr = scheduler.step()

                    optimizer.zero_grad()
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    for key in ['total', 'box', 'obj', 'cls']:
                        epoch_losses[key].append(loss_dict[key].item())
                    
                    # é€²æ—è¡¨ç¤º
                    if batch_idx % config.progress_interval == 0:
                        memory_info = get_memory_usage()
                        print(f"   ğŸ“Š Batch {batch_idx+1}/{len(train_loader)} | "
                              f"Loss: {loss_dict['total']:.4f} "
                              f"(Box: {loss_dict['box']:.4f}, "
                              f"Obj: {loss_dict['obj']:.4f}, "
                              f"Cls: {loss_dict['cls']:.4f}) | "
                              f"Pos: {loss_dict['pos_samples']} | "
                              f"LR: {current_lr:.2e} | "
                              f"GPU: {memory_info.get('gpu_allocated', 0):.1f}GB")
                    
                    accumulated_loss = 0.0
                
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                if batch_idx % config.memory_check_interval == 0:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        
            except Exception as e:
                print(f"âš ï¸ Training error at batch {batch_idx}: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # ã‚¨ãƒãƒƒã‚¯çµ‚äº†å‡¦ç†
        epoch_time = time.time() - epoch_start_time
        
        if epoch_losses["total"]:
            avg_metrics = {
                'total': np.mean(epoch_losses['total']),
                'box': np.mean(epoch_losses['box']),
                'obj': np.mean(epoch_losses['obj']),
                'cls': np.mean(epoch_losses['cls'])
            }
            
            print(f"\nğŸ“Š Epoch {epoch+1} Summary:")
            print(f"   â±ï¸  Time: {epoch_time:.1f}s")
            print(f"   ğŸ“‰ Avg Loss: {avg_metrics['total']:.4f}")
            print(f"   ğŸ“¦ Box Loss: {avg_metrics['box']:.4f}")
            print(f"   ğŸ‘ï¸  Obj Loss: {avg_metrics['obj']:.4f}")
            print(f"   ğŸ·ï¸  Cls Loss: {avg_metrics['cls']:.4f}")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜æ¡ä»¶
            save_model = False
            
            # Box Lossæ”¹å–„
            if avg_metrics['box'] < best_box_loss:
                best_box_loss = avg_metrics['box']
                save_model = True
                print(f"   ğŸ‰ New best Box Loss: {best_box_loss:.4f}")
            
            # Obj Lossæ”¹å–„ï¼ˆ0ã‚ˆã‚Šå¤§ããï¼‰
            if avg_metrics['obj'] > best_obj_loss and avg_metrics['obj'] > 0.01:
                best_obj_loss = avg_metrics['obj']
                save_model = True
                print(f"   ğŸ‰ Obj Loss improved: {best_obj_loss:.4f}")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if save_model:
                checkpoint = {
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.__dict__,
                    'best_box_loss': best_box_loss,
                    'best_obj_loss': best_obj_loss,
                    'avg_metrics': avg_metrics,
                    'anchor_info': anchor_grid_info,
                    'debug_history': debug_tracker.step_history[-100:]  # æœ€è¿‘100ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                }
                
                save_path = os.path.join(
                    config.model_save_path,
                    f"corrected_model_epoch_{epoch+1}_box_{avg_metrics['box']:.4f}_obj_{avg_metrics['obj']:.4f}.pth"
                )
                torch.save(checkpoint, save_path)
                print(f"   ğŸ’¾ Model saved with debug info")
            
            # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
            if avg_metrics['box'] < 0.5:
                print(f"ğŸ¯ TARGET ACHIEVED! Box Loss < 0.5")
                break
            elif avg_metrics['box'] < 0.8:
                print(f"ğŸ¯ Phase 1 Goal Achieved! Box Loss < 0.8")
    
    # å­¦ç¿’çµ‚äº†å¾Œã«ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã¨ãƒ­ã‚°ä¿å­˜
    print(f"\nğŸŠ Training Complete!")
    print(f"   ğŸ† Best Box Loss: {best_box_loss:.4f}")
    print(f"   ğŸ‘ï¸  Best Obj Loss: {best_obj_loss:.4f}")
    
    # ãƒ‡ãƒãƒƒã‚°ã‚µãƒãƒªãƒ¼ã¨ãƒ­ã‚°ä¿å­˜
    debug_tracker.print_summary()
    debug_tracker.save_debug_log("corrected_comprehensive_debug_log.json")
    
    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    final_save_path = os.path.join(config.model_save_path, "corrected_final_model.pth")
    torch.save(model.state_dict(), final_save_path)
    print(f"   ğŸ’¾ Final model saved")
    
    return model, best_box_loss, best_obj_loss


if __name__ == "__main__":
    try:
        model, best_box_loss, best_obj_loss = main()
        print(f"\nâœ… Training completed successfully!")
        print(f"ğŸ¯ Final best Box Loss: {best_box_loss:.4f}")
        print(f"ğŸ‘ï¸ Final best Obj Loss: {best_obj_loss:.4f}")
    except KeyboardInterrupt:
        print("\nâš ï¸ Training interrupted by user")
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()