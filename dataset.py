# dataset.py
import torch
from torch.utils.data import Dataset
import cv2
import numpy as np
import os

import datetime
import hashlib
# ===== verç®¡ç† =====
class VersionTracker:
    """ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ä¿®æ­£å±¥æ­´ã‚’è¿½è·¡"""
    _all_trackers = {}

    def __init__(self, script_name, version="1.0.0"):
        self.script_name = script_name
        self.version = version
        self.load_time = datetime.datetime.now()
        self.modifications = []
        
        VersionTracker._all_trackers[script_name] = self
        
    def add_modification(self, description, author="AI Assistant"):
        """ä¿®æ­£å±¥æ­´ã‚’è¿½åŠ """
        timestamp = datetime.datetime.now()
        self.modifications.append({
            'timestamp': timestamp,
            'description': description,
            'author': author
        })
        
    def get_file_hash(self, filepath):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œå‡ºç”¨ï¼‰"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()[:8]
        except:
            return "unknown"
    
    def print_version_info(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ {self.script_name} - Version {self.version}")
        print(f"â° Loaded: {self.load_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if hasattr(self, 'file_hash'):
            print(f"ğŸ”— File Hash: {self.file_hash}")
        
        if self.modifications:
            print(f"ğŸ“ Recent Modifications ({len(self.modifications)}):")
            for i, mod in enumerate(self.modifications[-3:], 1):  # æœ€æ–°3ä»¶
                print(f"   {i}. {mod['timestamp'].strftime('%H:%M:%S')} - {mod['description']}")
        
        print(f"{'='*60}\n")

# å„ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’ä½œæˆ
def create_version_tracker(script_name, filepath=None):
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’ä½œæˆ"""
    tracker = VersionTracker(script_name)
    
    if filepath:
        tracker.file_hash = tracker.get_file_hash(filepath)
    
    return tracker

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
training_version = create_version_tracker("Unified Training System v0.0", "dataset.py")
training_version.add_modification("ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")

class FLIRDataset(Dataset):
    def __init__(self, img_dir, label_dir, img_size=416):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_size = img_size
        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
        
    def __len__(self):
        return len(self.img_files)
    
    def __getitem__(self, idx):
        # ç”»åƒèª­ã¿è¾¼ã¿
        img_path = os.path.join(self.img_dir, self.img_files[idx])
        img = cv2.imread(img_path, 0)
        img = cv2.resize(img, (self.img_size, self.img_size))
        img = torch.from_numpy(img).float() / 255.0
        img = img.unsqueeze(0)
        
        # ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿
        label_path = os.path.join(self.label_dir, 
                                 self.img_files[idx].replace('.jpg', '.txt'))
        targets = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        targets.append(list(map(float, parts)))
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«ï¼ˆç©ºã®å ´åˆã‚‚å¯¾å¿œï¼‰
        targets = torch.tensor(targets) if targets else torch.zeros((0, 5))
        return img, targets

def collate_fn(batch):
    """ã‚«ã‚¹ã‚¿ãƒ collateé–¢æ•° - ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’å‡¦ç†"""
    #verå–å¾—
    training_version.print_version_info()

    images, targets = zip(*batch)
    images = torch.stack(images, 0)
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¯ãƒªã‚¹ãƒˆã®ã¾ã¾è¿”ã™ï¼ˆå„ç”»åƒã§ç‰©ä½“æ•°ãŒç•°ãªã‚‹ãŸã‚ï¼‰
    return images, list(targets)