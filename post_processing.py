# post_processing.py - Phase 4: ÂæåÂá¶ÁêÜÊúÄÈÅ©Âåñ

import torch
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Optional
import math

class SoftNMS:
    """Soft-NMS: „Çà„ÇäËâØ„ÅÑÈáçË§áÈô§Âéª"""
    
    def __init__(self, sigma=0.5, iou_threshold=0.3, score_threshold=0.001, method='gaussian'):
        self.sigma = sigma
        self.iou_threshold = iou_threshold
        self.score_threshold = score_threshold
        self.method = method  # 'linear' or 'gaussian'
        
    def __call__(self, boxes, scores, class_ids):
        """
        Args:
            boxes: [N, 4] (x1, y1, x2, y2)
            scores: [N] confidence scores
            class_ids: [N] class indices
        Returns:
            keep_indices: ‰øùÊåÅ„Åô„Çã„Éú„ÉÉ„ÇØ„Çπ„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
        """
        if len(boxes) == 0:
            return []
        
        # „Çπ„Ç≥„Ç¢È†Ü„Å´„ÇΩ„Éº„Éà
        sorted_indices = torch.argsort(scores, descending=True)
        
        keep_indices = []
        remaining_indices = sorted_indices.clone()
        
        while len(remaining_indices) > 0:
            # ÊúÄÈ´ò„Çπ„Ç≥„Ç¢„ÅÆ„Éú„ÉÉ„ÇØ„Çπ„Çí‰øùÊåÅ
            current_idx = remaining_indices[0]
            keep_indices.append(current_idx.item())
            
            if len(remaining_indices) == 1:
                break
            
            # ÁèæÂú®„ÅÆ„Éú„ÉÉ„ÇØ„Çπ„Å®ÊÆã„Çä„ÅÆ„Éú„ÉÉ„ÇØ„Çπ„ÅÆIoUË®àÁÆó
            current_box = boxes[current_idx].unsqueeze(0)
            remaining_boxes = boxes[remaining_indices[1:]]
            
            ious = self.calculate_iou(current_box, remaining_boxes)
            
            # Soft-NMS„Å´„Çà„Çã„Çπ„Ç≥„Ç¢Êõ¥Êñ∞
            if self.method == 'gaussian':
                # Gaussian decay
                decay_weights = torch.exp(-(ious ** 2) / self.sigma)
            else:
                # Linear decay
                decay_weights = torch.where(
                    ious > self.iou_threshold,
                    1 - ious,
                    torch.ones_like(ious)
                )
            
            # „Çπ„Ç≥„Ç¢Êõ¥Êñ∞
            remaining_scores = scores[remaining_indices[1:]] * decay_weights
            
            # ÈñæÂÄ§‰ª•‰∏ã„ÅÆ„Éú„ÉÉ„ÇØ„Çπ„ÇíÈô§Âéª
            valid_mask = remaining_scores > self.score_threshold
            remaining_indices = remaining_indices[1:][valid_mask]
            
            # „Çπ„Ç≥„Ç¢Êõ¥Êñ∞„ÇíÂèçÊò†
            scores[remaining_indices] = remaining_scores[valid_mask]
            
            # ÂÜç„ÇΩ„Éº„Éà
            if len(remaining_indices) > 0:
                remaining_scores_valid = scores[remaining_indices]
                sorted_order = torch.argsort(remaining_scores_valid, descending=True)
                remaining_indices = remaining_indices[sorted_order]
        
        return keep_indices
    
    def calculate_iou(self, boxes1, boxes2):
        """IoUË®àÁÆó"""
        # Intersection
        x1 = torch.max(boxes1[:, 0:1], boxes2[:, 0:1].T)
        y1 = torch.max(boxes1[:, 1:2], boxes2[:, 1:2].T)
        x2 = torch.min(boxes1[:, 2:3], boxes2[:, 2:3].T)
        y2 = torch.min(boxes1[:, 3:4], boxes2[:, 3:4].T)
        
        intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)
        
        # Union
        area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])
        area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])
        union = area1.unsqueeze(1) + area2.unsqueeze(0) - intersection
        
        iou = intersection / (union + 1e-7)
        return iou.squeeze()

class TestTimeAugmentation:
    """Test Time Augmentation: Êé®Ë´ñÊôÇ„Éá„Éº„ÇøÊã°Âºµ"""
    
    def __init__(self, scales=[0.8, 1.0, 1.2], flips=[False, True]):
        self.scales = scales
        self.flips = flips
        
    def __call__(self, model, image):
        """
        Args:
            model: YOLO model
            image: [1, C, H, W] input image
        Returns:
            aggregated_predictions: ÈõÜÁ¥Ñ„Åï„Çå„Åü‰∫àÊ∏¨ÁµêÊûú
        """
        model.eval()
        all_predictions = []
        
        with torch.no_grad():
            for scale in self.scales:
                for flip in self.flips:
                    # ÁîªÂÉèÂ§âÊèõ
                    transformed_image = self.transform_image(image, scale, flip)
                    
                    # Êé®Ë´ñ
                    predictions = model(transformed_image)
                    
                    # ‰∫àÊ∏¨ÁµêÊûú„ÇíÂÖÉ„ÅÆÂ∫ßÊ®ôÁ≥ª„Å´Êàª„Åô
                    restored_predictions = self.restore_predictions(
                        predictions, scale, flip, image.shape[-2:]
                    )
                    
                    all_predictions.append(restored_predictions)
        
        # ‰∫àÊ∏¨ÁµêÊûú„ÇíÈõÜÁ¥Ñ
        aggregated = self.aggregate_predictions(all_predictions)
        return aggregated
    
    def transform_image(self, image, scale, flip):
        """ÁîªÂÉèÂ§âÊèõ"""
        # „Çπ„Ç±„Éº„É´Â§âÊèõ
        if scale != 1.0:
            new_size = (int(image.shape[-2] * scale), int(image.shape[-1] * scale))
            image = F.interpolate(image, size=new_size, mode='bilinear', align_corners=False)
        
        # „Éï„É™„ÉÉ„Éó
        if flip:
            image = torch.flip(image, dims=[-1])
        
        return image
    
    def restore_predictions(self, predictions, scale, flip, original_size):
        """‰∫àÊ∏¨ÁµêÊûú„ÇíÂÖÉÂ∫ßÊ®ôÁ≥ª„Å´Âæ©ÂÖÉ"""
        # „Éû„É´„ÉÅ„Çπ„Ç±„Éº„É´‰∫àÊ∏¨„ÅÆÂ†¥Âêà
        if isinstance(predictions, dict):
            restored = {}
            for scale_name, preds in predictions.items():
                restored[scale_name] = self.restore_single_scale(
                    preds, scale, flip, original_size
                )
            return restored
        else:
            return self.restore_single_scale(predictions, scale, flip, original_size)
    
    def restore_single_scale(self, predictions, scale, flip, original_size):
        """Âçò‰∏Ä„Çπ„Ç±„Éº„É´‰∫àÊ∏¨„ÅÆÂæ©ÂÖÉ"""
        # Â∫ßÊ®ô„Çí„Çπ„Ç±„Éº„É´Ë™øÊï¥
        if scale != 1.0:
            predictions[..., :4] /= scale
        
        # „Éï„É™„ÉÉ„Éó„ÅÆÂ†¥Âêà„ÅÆxÂ∫ßÊ®ôË™øÊï¥
        if flip:
            predictions[..., 0] = 1.0 - predictions[..., 0]  # cxÂ∫ßÊ®ôÂèçËª¢
        
        return predictions
    
    def aggregate_predictions(self, all_predictions):
        """Ë§áÊï∞‰∫àÊ∏¨ÁµêÊûú„ÅÆÈõÜÁ¥Ñ"""
        # ÂçòÁ¥îÂπ≥ÂùáÔºà„Çà„ÇäÈ´òÂ∫¶„Å™ÊâãÊ≥ï„ÇÇÂèØËÉΩÔºâ
        if isinstance(all_predictions[0], dict):
            # „Éû„É´„ÉÅ„Çπ„Ç±„Éº„É´„ÅÆÂ†¥Âêà
            aggregated = {}
            for scale_name in all_predictions[0].keys():
                scale_preds = [pred[scale_name] for pred in all_predictions]
                aggregated[scale_name] = torch.mean(torch.stack(scale_preds), dim=0)
            return aggregated
        else:
            return torch.mean(torch.stack(all_predictions), dim=0)

class MultiScaleInference:
    """Multi-scale Testing: Ë§áÊï∞Ëß£ÂÉèÂ∫¶„Åß„ÅÆÊé®Ë´ñ"""
    
    def __init__(self, scales=[320, 416, 512, 608]):
        self.scales = scales
        
    def __call__(self, model, image_path_or_tensor):
        """
        Args:
            model: YOLO model
            image_path_or_tensor: ÁîªÂÉè„Éë„Çπ„Åæ„Åü„ÅØ„ÉÜ„É≥„ÇΩ„É´
        Returns:
            best_predictions: ÊúÄÈÅ©„Å™‰∫àÊ∏¨ÁµêÊûú
        """
        model.eval()
        scale_results = []
        
        with torch.no_grad():
            for scale in self.scales:
                # ÁîªÂÉè„Çí„Çπ„Ç±„Éº„É´„Å´„É™„Çµ„Ç§„Ç∫
                if isinstance(image_path_or_tensor, str):
                    image = self.load_and_resize_image(image_path_or_tensor, scale)
                else:
                    image = F.interpolate(
                        image_path_or_tensor, 
                        size=(scale, scale), 
                        mode='bilinear', 
                        align_corners=False
                    )
                
                # Êé®Ë´ñ
                predictions = model(image)
                
                # ÁµêÊûú„Çí‰øùÂ≠òÔºà„Çπ„Ç±„Éº„É´ÊÉÖÂ†±‰ªò„ÅçÔºâ
                scale_results.append({
                    'scale': scale,
                    'predictions': predictions,
                    'confidence': self.calculate_avg_confidence(predictions)
                })
        
        # ÊúÄ„ÇÇ‰ø°È†ºÂ∫¶„ÅÆÈ´ò„ÅÑ„Çπ„Ç±„Éº„É´„ÅÆÁµêÊûú„ÇíËøî„Åô
        best_result = max(scale_results, key=lambda x: x['confidence'])
        return best_result['predictions']
    
    def load_and_resize_image(self, image_path, size):
        """ÁîªÂÉèË™≠„ÅøËæº„Åø„Å®„É™„Çµ„Ç§„Ç∫"""
        import cv2
        
        img = cv2.imread(image_path, 0)  # „Ç∞„É¨„Éº„Çπ„Ç±„Éº„É´
        img = cv2.resize(img, (size, size))
        img = img.astype(np.float32) / 255.0
        
        tensor = torch.from_numpy(img).float().unsqueeze(0).unsqueeze(0)
        return tensor
    
    def calculate_avg_confidence(self, predictions):
        """Âπ≥Âùá‰ø°È†ºÂ∫¶Ë®àÁÆó"""
        if isinstance(predictions, dict):
            total_conf = 0
            count = 0
            for scale_preds in predictions.values():
                conf = torch.sigmoid(scale_preds[..., 4]).mean()
                total_conf += conf
                count += 1
            return total_conf / count
        else:
            return torch.sigmoid(predictions[..., 4]).mean()

class AdvancedPostProcessor:
    """Phase 4: Áµ±ÂêàÂæåÂá¶ÁêÜ„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self, 
                 use_soft_nms=True,
                 use_tta=False,  # ÊôÇÈñì„Ç≥„Çπ„ÉàËÄÉÊÖÆ
                 use_multiscale=False,  # ÊôÇÈñì„Ç≥„Çπ„ÉàËÄÉÊÖÆ
                 conf_threshold=0.5,
                 iou_threshold=0.45):
        
        self.use_soft_nms = use_soft_nms
        self.use_tta = use_tta
        self.use_multiscale = use_multiscale
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # ÂæåÂá¶ÁêÜ„Ç≥„É≥„Éù„Éº„Éç„É≥„ÉàÂàùÊúüÂåñ
        if use_soft_nms:
            self.soft_nms = SoftNMS(
                sigma=0.5,
                iou_threshold=iou_threshold,
                score_threshold=0.001,
                method='gaussian'
            )
        
        if use_tta:
            self.tta = TestTimeAugmentation(
                scales=[0.9, 1.0, 1.1],  # ËªΩÈáèÁâà
                flips=[False, True]
            )
        
        if use_multiscale:
            self.multiscale = MultiScaleInference(
                scales=[384, 416, 448]  # ËªΩÈáèÁâà
            )
        
        print(f"üîß AdvancedPostProcessor initialized")
        print(f"   Soft-NMS: {'ON' if use_soft_nms else 'OFF'}")
        print(f"   TTA: {'ON' if use_tta else 'OFF'}")
        print(f"   Multi-scale: {'ON' if use_multiscale else 'OFF'}")
    
    def process_predictions(self, model, image, raw_predictions=None):
        """
        Áµ±ÂêàÂæåÂá¶ÁêÜÂÆüË°å
        
        Args:
            model: YOLO model
            image: ÂÖ•ÂäõÁîªÂÉè
            raw_predictions: ‰∫ãÂâçË®àÁÆó„Åï„Çå„Åü‰∫àÊ∏¨ÔºàÁúÅÁï•ÂèØÔºâ
        Returns:
            final_detections: ÊúÄÁµÇÊ§úÂá∫ÁµêÊûú
        """
        # 1. ‰∫àÊ∏¨ÂèñÂæóÔºàTTA/Multi-scaleÂØæÂøúÔºâ
        if self.use_tta and raw_predictions is None:
            predictions = self.tta(model, image)
        elif self.use_multiscale and raw_predictions is None:
            predictions = self.multiscale(model, image)
        else:
            if raw_predictions is None:
                with torch.no_grad():
                    predictions = model(image)
            else:
                predictions = raw_predictions
        
        # 2. „Éá„Ç≥„Éº„ÉâÂá¶ÁêÜ
        decoded_detections = self.decode_predictions(predictions)
        
        # 3. Soft-NMSÈÅ©Áî®
        if self.use_soft_nms:
            final_detections = self.apply_soft_nms(decoded_detections)
        else:
            final_detections = self.apply_standard_nms(decoded_detections)
        
        return final_detections
    
    def decode_predictions(self, predictions):
        """‰∫àÊ∏¨ÁµêÊûú„ÅÆ„Éá„Ç≥„Éº„Éâ"""
        all_detections = []
        
        if isinstance(predictions, dict):
            # „Éû„É´„ÉÅ„Çπ„Ç±„Éº„É´‰∫àÊ∏¨
            for scale_name, scale_preds in predictions.items():
                scale_detections = self.decode_single_scale(scale_preds, scale_name)
                all_detections.extend(scale_detections)
        else:
            # Âçò‰∏Ä„Çπ„Ç±„Éº„É´‰∫àÊ∏¨
            all_detections = self.decode_single_scale(predictions, 'single')
        
        return all_detections
    
    def decode_single_scale(self, predictions, scale_name):
        """Âçò‰∏Ä„Çπ„Ç±„Éº„É´‰∫àÊ∏¨„ÅÆ„Éá„Ç≥„Éº„Éâ"""
        # [B, N, C] -> [N, C]
        if predictions.dim() == 3:
            predictions = predictions[0]  # „Éê„ÉÉ„ÉÅ„ÅÆÊúÄÂàù„ÅÆË¶ÅÁ¥†
        
        # ‰ø°È†ºÂ∫¶„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
        conf_scores = torch.sigmoid(predictions[:, 4])
        conf_mask = conf_scores > self.conf_threshold
        
        if not conf_mask.any():
            return []
        
        # „Éï„Ç£„É´„ÇøÂæå„ÅÆ‰∫àÊ∏¨
        filtered_preds = predictions[conf_mask]
        filtered_conf = conf_scores[conf_mask]
        
        # Â∫ßÊ®ô„Å®„ÇØ„É©„Çπ‰∫àÊ∏¨
        xy = torch.sigmoid(filtered_preds[:, :2])
        wh = filtered_preds[:, 2:4]
        class_probs = torch.softmax(filtered_preds[:, 5:], dim=-1)
        
        # „Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„ÇπÂ§âÊèõ
        boxes = torch.cat([xy, wh], dim=-1)
        
        # „ÇØ„É©„ÇπÂà•Ê§úÂá∫ÁµêÊûú
        detections = []
        for i in range(class_probs.shape[-1]):
            class_conf = filtered_conf * class_probs[:, i]
            class_mask = class_conf > self.conf_threshold
            
            if class_mask.any():
                class_boxes = boxes[class_mask]
                class_scores = class_conf[class_mask]
                class_ids = torch.full((class_mask.sum(),), i)
                
                for j in range(len(class_boxes)):
                    detections.append({
                        'box': class_boxes[j],
                        'score': class_scores[j],
                        'class_id': class_ids[j],
                        'scale': scale_name
                    })
        
        return detections
    
    def apply_soft_nms(self, detections):
        """Soft-NMSÈÅ©Áî®"""
        if len(detections) == 0:
            return []
        
        # „ÇØ„É©„ÇπÂà•„Å´Soft-NMSÈÅ©Áî®
        final_detections = []
        classes = set(det['class_id'].item() for det in detections)
        
        for class_id in classes:
            class_detections = [det for det in detections if det['class_id'].item() == class_id]
            
            if len(class_detections) <= 1:
                final_detections.extend(class_detections)
                continue
            
            # „ÉÜ„É≥„ÇΩ„É´Ê∫ñÂÇô
            boxes = torch.stack([det['box'] for det in class_detections])
            scores = torch.stack([det['score'] for det in class_detections])
            class_ids = torch.stack([det['class_id'] for det in class_detections])
            
            # Soft-NMSÂÆüË°å
            keep_indices = self.soft_nms(boxes, scores, class_ids)
            
            # ‰øùÊåÅ„Åô„ÇãÊ§úÂá∫ÁµêÊûú
            for idx in keep_indices:
                final_detections.append(class_detections[idx])
        
        return final_detections
    
    def apply_standard_nms(self, detections):
        """Ê®ôÊ∫ñNMSÈÅ©Áî®Ôºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºâ"""
        # ÂÆüË£ÖÁúÅÁï•ÔºàÊ®ôÊ∫ñÁöÑ„Å™NMSÂá¶ÁêÜÔºâ
        return detections

def test_post_processing():
    """ÂæåÂá¶ÁêÜ„Ç∑„Çπ„ÉÜ„É†„ÅÆ„ÉÜ„Çπ„Éà"""
    print("üß™ Phase 4ÂæåÂá¶ÁêÜ„Ç∑„Çπ„ÉÜ„É†„ÉÜ„Çπ„Éà")
    print("-" * 50)
    
    # Soft-NMS„ÉÜ„Çπ„Éà
    print("1. Soft-NMS Test:")
    soft_nms = SoftNMS(sigma=0.5, method='gaussian')
    
    # „ÉÄ„Éü„Éº„Éú„ÉÉ„ÇØ„Çπ
    boxes = torch.tensor([
        [0.1, 0.1, 0.3, 0.3],
        [0.15, 0.15, 0.35, 0.35],  # ÈáçË§á
        [0.5, 0.5, 0.7, 0.7]       # Âà•Áâ©‰Ωì
    ])
    scores = torch.tensor([0.9, 0.8, 0.85])
    class_ids = torch.tensor([0, 0, 1])
    
    try:
        keep_indices = soft_nms(boxes, scores, class_ids)
        print(f"   ‚úÖ Soft-NMSÊàêÂäü: ‰øùÊåÅ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ {keep_indices}")
    except Exception as e:
        print(f"   ‚ùå Soft-NMS„Ç®„É©„Éº: {e}")
    
    # TTA„ÉÜ„Çπ„Éà
    print("2. TTA Test:")
    tta = TestTimeAugmentation(scales=[1.0], flips=[False, True])
    
    # „ÉÄ„Éü„Éº„É¢„Éá„É´
    class DummyModel:
        def eval(self): pass
        def __call__(self, x):
            return {'small': torch.randn(1, 100, 20)}
    
    dummy_model = DummyModel()
    dummy_image = torch.randn(1, 1, 416, 416)
    
    try:
        tta_result = tta(dummy_model, dummy_image)
        print(f"   ‚úÖ TTAÊàêÂäü: Âá∫ÂäõÂΩ¢Áä∂ {tta_result['small'].shape}")
    except Exception as e:
        print(f"   ‚ùå TTA„Ç®„É©„Éº: {e}")
    
    # Áµ±Âêà„Ç∑„Çπ„ÉÜ„É†„ÉÜ„Çπ„Éà
    print("3. Integrated System Test:")
    post_processor = AdvancedPostProcessor(
        use_soft_nms=True,
        use_tta=False,  # ÊôÇÈñìÂäπÁéáÈáçË¶ñ
        use_multiscale=False
    )
    
    try:
        # „ÉÄ„Éü„Éº‰∫àÊ∏¨„Åß„ÉÜ„Çπ„Éà
        dummy_predictions = {'small': torch.randn(1, 100, 20)}
        result = post_processor.process_predictions(
            dummy_model, dummy_image, dummy_predictions
        )
        print(f"   ‚úÖ Áµ±Âêà„Ç∑„Çπ„ÉÜ„É†ÊàêÂäü: {len(result)} detections")
    except Exception as e:
        print(f"   ‚ùå Áµ±Âêà„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº: {e}")
    
    print("\nüîß Phase 4ÂæåÂá¶ÁêÜ„Ç∑„Çπ„ÉÜ„É†„ÉÜ„Çπ„ÉàÂÆå‰∫Ü!")
    return True

if __name__ == "__main__":
    # „ÉÜ„Çπ„ÉàÂÆüË°å
    success = test_post_processing()
    
    if success:
        print("üéâ Phase 4 Step 7 Ê∫ñÂÇôÂÆå‰∫Ü!")
        print("   Soft-NMS, TTA, Multi-scale TestingÂÆüË£ÖÊ∏à„Åø")
        print("   Êé®Ë´ñÁ≤æÂ∫¶„ÅÆÂ§ßÂπÖÊîπÂñÑÊúüÂæÖ")
        print("   Ê¨°: train.py„Å®„ÅÆÁµ±Âêà")
    else:
        print("‚ùå „ÉÜ„Çπ„ÉàÂ§±Êïó - ‰øÆÊ≠£„ÅåÂøÖË¶Å")
