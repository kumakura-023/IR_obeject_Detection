# improved_augmentation.py - ã‚µãƒ¼ãƒãƒ«ç”»åƒæœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ

import torch
import cv2
import numpy as np
import random
import os  # â˜…â˜…â˜… è¿½åŠ : DataLoaderã‚¨ãƒ©ãƒ¼ä¿®æ­£ â˜…â˜…â˜…
from torch.utils.data import Dataset
import torch.nn.functional as F

class ThermalImageAugmentation:
    """ã‚µãƒ¼ãƒãƒ«ç”»åƒã«ç‰¹åŒ–ã—ãŸè»½é‡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ"""
    
    def __init__(self, 
                 brightness_range=0.5,
                 contrast_range=0.4,
                 noise_level=0.03,
                 gaussian_blur_prob=0.3,
                 mixup_prob=0.6):
        
        self.brightness_range = brightness_range
        self.contrast_range = contrast_range
        self.noise_level = noise_level
        self.gaussian_blur_prob = gaussian_blur_prob
        self.mixup_prob = mixup_prob
        
        print(f"ğŸ¨ ThermalImageAugmentationåˆæœŸåŒ–")
        print(f"   æ˜åº¦ç¯„å›²: Â±{brightness_range}")
        print(f"   ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ: Â±{contrast_range}")
        print(f"   ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_level}")
        print(f"   ãƒ–ãƒ©ãƒ¼ç¢ºç‡: {gaussian_blur_prob}")
        print(f"   MixUpç¢ºç‡: {mixup_prob}")
    
    def apply_brightness_contrast(self, img):
        """æ˜åº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆã‚µãƒ¼ãƒãƒ«ç”»åƒç‰¹æ€§è€ƒæ…®ï¼‰"""
        if random.random() > 0.7:  # 70%ã®ç¢ºç‡ã§é©ç”¨
            return img
        
        # æ˜åº¦èª¿æ•´
        brightness_factor = 1 + random.uniform(-self.brightness_range, self.brightness_range)
        img = img * brightness_factor
        
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆã‚µãƒ¼ãƒãƒ«ç”»åƒã§ã¯é‡è¦ï¼‰
        contrast_factor = 1 + random.uniform(-self.contrast_range, self.contrast_range)
        mean_val = img.mean()
        img = mean_val + contrast_factor * (img - mean_val)
        
        # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        img = torch.clamp(img, 0, 1)
        
        return img
    
    def apply_gaussian_noise(self, img):
        """ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºï¼ˆã‚»ãƒ³ã‚µãƒ¼ãƒã‚¤ã‚ºæ¨¡æ“¬ï¼‰"""
        if random.random() > 0.4:  # 40%ã®ç¢ºç‡ã§é©ç”¨
            return img
        
        noise = torch.randn_like(img) * self.noise_level
        img = img + noise
        img = torch.clamp(img, 0, 1)
        
        return img
    
    def apply_gaussian_blur(self, img):
        """ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ï¼ˆå¤§æ°—åŠ¹æœæ¨¡æ“¬ï¼‰"""
        if random.random() > self.gaussian_blur_prob:
            return img
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã‚’numpyé…åˆ—ã«å¤‰æ›
        img_np = img.squeeze().cpu().numpy()
        
        # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        kernel_size = random.choice([3, 5])
        sigma = random.uniform(0.5, 1.5)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼é©ç”¨
        blurred = cv2.GaussianBlur(img_np, (kernel_size, kernel_size), sigma)
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã«æˆ»ã™
        img_blurred = torch.from_numpy(blurred).unsqueeze(0).float()
        
        return img_blurred
    
    def apply_thermal_specific_augment(self, img):
        """ã‚µãƒ¼ãƒãƒ«ç”»åƒç‰¹æœ‰ã®æ‹¡å¼µ"""
        # 1. æ¸©åº¦ãƒ¬ãƒ³ã‚¸ã‚·ãƒ•ãƒˆï¼ˆã‚µãƒ¼ãƒãƒ«ç”»åƒã®ç‰¹æ€§ï¼‰
        if random.random() < 0.3:
            shift = random.uniform(-0.1, 0.1)
            img = img + shift
            img = torch.clamp(img, 0, 1)
        
        # 2. ã‚¨ãƒƒã‚¸å¼·èª¿ï¼ˆã‚µãƒ¼ãƒãƒ«ç”»åƒã§ã¯ç‰©ä½“å¢ƒç•ŒãŒé‡è¦ï¼‰
        if random.random() < 0.2:
            img = self._enhance_edges(img)
        
        return img
    
    def _enhance_edges(self, img):
        """ã‚¨ãƒƒã‚¸å¼·èª¿å‡¦ç†"""
        # Sobelãƒ•ã‚£ãƒ«ã‚¿ã§ã‚¨ãƒƒã‚¸æ¤œå‡º
        img_np = img.squeeze().cpu().numpy()
        
        # Sobelãƒ•ã‚£ãƒ«ã‚¿
        sobel_x = cv2.Sobel(img_np, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(img_np, cv2.CV_64F, 0, 1, ksize=3)
        sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)
        
        # æ­£è¦åŒ–
        sobel_combined = sobel_combined / sobel_combined.max()
        
        # å…ƒç”»åƒã«ã‚¨ãƒƒã‚¸ã‚’è»½ãåŠ ç®—
        enhanced = img_np + 0.1 * sobel_combined
        enhanced = np.clip(enhanced, 0, 1)
        
        return torch.from_numpy(enhanced).unsqueeze(0).float()
    
    def __call__(self, img):
        """å…¨æ‹¡å¼µã‚’é©ç”¨"""
        # åŸºæœ¬æ‹¡å¼µ
        img = self.apply_brightness_contrast(img)
        img = self.apply_gaussian_noise(img)
        
        # é‡ã„å‡¦ç†ã¯ç¢ºç‡ã‚’ä¸‹ã’ã‚‹
        try:
            img = self.apply_gaussian_blur(img)
        except:
            pass  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # ã‚µãƒ¼ãƒãƒ«ç‰¹åŒ–æ‹¡å¼µ
        img = self.apply_thermal_specific_augment(img)
        
        return img

class LightweightMixUp:
    """è»½é‡åŒ–ã•ã‚ŒãŸMixUpå®Ÿè£…"""
    
    def __init__(self, alpha=0.4, prob=0.6):
        self.alpha = alpha
        self.prob = prob
    
    def __call__(self, batch_images, batch_targets):
        """è»½é‡MixUpé©ç”¨"""
        if random.random() > self.prob:
            return batch_images, batch_targets
        
        batch_size = batch_images.size(0)
        if batch_size < 2:
            return batch_images, batch_targets
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒšã‚¢ã‚’ä½œæˆ
        indices = torch.randperm(batch_size)
        
        # Lambdaå€¤ç”Ÿæˆï¼ˆBetaã®è¿‘ä¼¼ã¨ã—ã¦å˜ç´”ãªä¹±æ•°ä½¿ç”¨ï¼‰
        lam = np.random.uniform(0.3, 0.7)  # 0.3-0.7ã®ç¯„å›²ã§å›ºå®š
        
        # ç”»åƒæ··åˆ
        mixed_images = lam * batch_images + (1 - lam) * batch_images[indices]
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‡¦ç†ã¯ç°¡ç•¥åŒ–ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰
        mixed_targets = []
        for i in range(batch_size):
            # ãƒ¡ã‚¤ãƒ³ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ã¿ä½¿ç”¨ï¼ˆè¨ˆç®—ç°¡ç•¥åŒ–ï¼‰
            if len(batch_targets[i]) > 0:
                mixed_targets.append(batch_targets[i])
            else:
                mixed_targets.append(torch.zeros((0, 5)))
        
        return mixed_images, mixed_targets

class ImprovedFLIRDataset(Dataset):
    """æ”¹è‰¯ç‰ˆFLIRãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè»½é‡æ‹¡å¼µå¯¾å¿œï¼‰"""
    
    def __init__(self, img_dir, label_dir, img_size=416, 
                 use_improved_augment=True, mixup_in_dataset=False):
        
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_size = img_size
        self.use_improved_augment = use_improved_augment
        self.mixup_in_dataset = mixup_in_dataset
        
        import os
        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
        
        # æ”¹è‰¯ç‰ˆæ‹¡å¼µå™¨
        if use_improved_augment:
            self.augmenter = ThermalImageAugmentation()
        
        # è»½é‡MixUp
        if mixup_in_dataset:
            self.mixup = LightweightMixUp()
        
        print(f"ğŸ“Š ImprovedFLIRDatasetåˆæœŸåŒ–å®Œäº†")
        print(f"   ç”»åƒæ•°: {len(self.img_files)}")
        print(f"   æ”¹è‰¯æ‹¡å¼µ: {'ON' if use_improved_augment else 'OFF'}")
        print(f"   MixUp: {'ON' if mixup_in_dataset else 'OFF'}")
    
    def __len__(self):
        return len(self.img_files)
    
    def __getitem__(self, idx):
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
        img_path = os.path.join(self.img_dir, self.img_files[idx])
        img = cv2.imread(img_path, 0)
        img = cv2.resize(img, (self.img_size, self.img_size))
        img = img.astype(np.float32) / 255.0
        
        # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
        img = torch.from_numpy(img).float().unsqueeze(0)
        
        # æ”¹è‰¯ç‰ˆæ‹¡å¼µé©ç”¨
        if self.use_improved_augment:
            img = self.augmenter(img)
        
        # ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
        label_path = os.path.join(self.label_dir, 
                                 self.img_files[idx].replace('.jpg', '.txt'))
        targets = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        targets.append(list(map(float, parts)))
        
        targets = torch.tensor(targets) if targets else torch.zeros((0, 5))
        
        return img, targets

def create_improved_dataloader(dataset, batch_size, use_mixup=True, **kwargs):
    """æ”¹è‰¯ç‰ˆDataLoaderä½œæˆ"""
    
    # è»½é‡MixUpç”¨ã®collateé–¢æ•°
    def improved_collate_fn(batch):
        images, targets = zip(*batch)
        images = torch.stack(images, 0)
        
        # MixUpé©ç”¨
        if use_mixup and random.random() < 0.6:
            mixup = LightweightMixUp()
            images, targets = mixup(images, list(targets))
        
        return images, list(targets)
    
    from torch.utils.data import DataLoader
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=kwargs.get('shuffle', True),
        collate_fn=improved_collate_fn,
        num_workers=kwargs.get('num_workers', 4),
        pin_memory=kwargs.get('pin_memory', True),
        persistent_workers=kwargs.get('persistent_workers', True),
        prefetch_factor=kwargs.get('prefetch_factor', 2)
    )
    
    return dataloader

def test_improved_augmentation():
    """æ”¹è‰¯ç‰ˆæ‹¡å¼µã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    # 1. ã‚µãƒ¼ãƒãƒ«æ‹¡å¼µãƒ†ã‚¹ãƒˆ
    print("1. ThermalImageAugmentation Test:")
    augmenter = ThermalImageAugmentation()
    
    # ãƒ€ãƒŸãƒ¼ç”»åƒ
    dummy_img = torch.rand(1, 416, 416)
    
    try:
        augmented = augmenter(dummy_img)
        print(f"   âœ… ã‚µãƒ¼ãƒãƒ«æ‹¡å¼µæˆåŠŸ: {augmented.shape}")
        print(f"   å€¤ç¯„å›²: {augmented.min():.3f} - {augmented.max():.3f}")
    except Exception as e:
        print(f"   âŒ ã‚µãƒ¼ãƒãƒ«æ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. è»½é‡MixUpãƒ†ã‚¹ãƒˆ
    print("2. LightweightMixUp Test:")
    mixup = LightweightMixUp()
    
    batch_images = torch.rand(4, 1, 416, 416)
    batch_targets = [
        torch.tensor([[0, 0.5, 0.5, 0.1, 0.1]]),
        torch.tensor([[1, 0.3, 0.7, 0.2, 0.3]]),
        torch.tensor([[2, 0.8, 0.2, 0.4, 0.6]]),
        torch.zeros((0, 5))
    ]
    
    try:
        mixed_images, mixed_targets = mixup(batch_images, batch_targets)
        print(f"   âœ… MixUpæˆåŠŸ: {mixed_images.shape}")
        print(f"   ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°: {[len(t) for t in mixed_targets]}")
    except Exception as e:
        print(f"   âŒ MixUpã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\nğŸ¨ æ”¹è‰¯ç‰ˆæ‹¡å¼µãƒ†ã‚¹ãƒˆå®Œäº†!")
    return True

def integration_example():
    """çµ±åˆä¾‹ã‚’è¡¨ç¤º"""
    integration_code = '''
# dataset.pyã‚’æ”¹è‰¯ç‰ˆã«ç½®ãæ›ãˆã‚‹ä¾‹

from improved_augmentation import ImprovedFLIRDataset, create_improved_dataloader

# æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
improved_dataset = ImprovedFLIRDataset(
    cfg.train_img_dir, 
    cfg.train_label_dir, 
    cfg.img_size,
    use_improved_augment=True,
    mixup_in_dataset=False  # DataLoaderãƒ¬ãƒ™ãƒ«ã§å®Ÿè¡Œ
)

# æ”¹è‰¯ç‰ˆDataLoader
train_dataloader = create_improved_dataloader(
    improved_dataset,
    batch_size=cfg.batch_size,
    use_mixup=True,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)

# å­¦ç¿’æ™‚é–“ã®å¤§å¹…çŸ­ç¸®ãŒæœŸå¾…ã•ã‚Œã‚‹
# - Mosaicåœæ­¢: -8åˆ†/ã‚¨ãƒãƒƒã‚¯
# - è»½é‡MixUp: å‡¦ç†æ™‚é–“åŠæ¸›
# - ã‚µãƒ¼ãƒãƒ«ç‰¹åŒ–æ‹¡å¼µ: åŠ¹æœçš„ãªå­¦ç¿’ä¿ƒé€²
'''
    
    print("ğŸ”— çµ±åˆä¾‹:")
    print(integration_code)
    return integration_code

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success = test_improved_augmentation()
    
    if success:
        print("ğŸ‰ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæº–å‚™å®Œäº†!")
        print("   ã‚µãƒ¼ãƒãƒ«ç”»åƒç‰¹åŒ–ãƒ»è»½é‡åŒ–ãƒ»åŠ¹æœçš„")
        print("   æ¬¡: config_improved.py + diagnostic_training.py ã¨çµ±åˆ")
        
        # çµ±åˆä¾‹è¡¨ç¤º
        integration_example()
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•— - ä¿®æ­£ãŒå¿…è¦")